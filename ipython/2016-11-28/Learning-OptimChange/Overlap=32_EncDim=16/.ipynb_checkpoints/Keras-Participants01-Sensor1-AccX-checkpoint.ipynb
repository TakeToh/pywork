{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここに学習で必要なパラメータを定義する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "import copy\n",
    "\n",
    "# Parametor about Sensor\n",
    "SensorNum=1 # Sensor number\n",
    "#SensorAxis='AccX' # Axis\n",
    "\n",
    "# Parametor about  \" Sliding Window \" \n",
    "WindowWidth =np.array([128,256,512,1024,2048,4096]) # Window Width\n",
    "SlidingWidth =WindowWidth/4 #sliding window\n",
    "\n",
    "# Parametor about Neural Network\n",
    "AEDimention = 16\n",
    "\n",
    "# Define Data Name\n",
    "DATE= str( datetime.date.today() )+'/'\n",
    "TITLE=\"Participants01_First_1/\"\n",
    "Label = ['LeftHand','RightHand','LeftLeg','Rightleg','West','Chest']\n",
    "\n",
    "# Parametor about \" Data Path\"\n",
    "DataPath = \"/media/takeyama/Transfer/02_ActivityResearch/Paticipants01/01_First/20161018-105301/mem/\"\n",
    "StorePath = \"/home/takeyama/Documents/\"\n",
    "\n",
    "if not os.path.exists(StorePath+TITLE+'dictionary/'): \n",
    "    os.makedirs(StorePath+TITLE+'dictionary/')\n",
    "DictionaryDataPath=StorePath+TITLE+'dictionary/'\n",
    "\n",
    "if not os.path.exists(StorePath+TITLE+DATE+'window/'): \n",
    "    os.makedirs(StorePath+TITLE+DATE+'window/')\n",
    "WindowDataPath=StorePath+TITLE+DATE+'window/'\n",
    "\n",
    "if not os.path.exists(StorePath+TITLE+DATE+'studyOutput/'): \n",
    "    os.makedirs(StorePath+TITLE+DATE+'studyOutput/')\n",
    "StudyOutputPath=StorePath+TITLE+DATE+'studyOutput/'\n",
    "\n",
    "if not os.path.exists(StorePath+TITLE+DATE+'parametor/'): \n",
    "    os.makedirs(StorePath+TITLE+DATE+'parametor/')\n",
    "ParametorPath=StorePath+TITLE+DATE+'parametor/'\n",
    "\n",
    "if not os.path.exists(StorePath+TITLE+DATE+'result/'): \n",
    "    os.makedirs(StorePath++TITLE+DATE+'result/')\n",
    "ResultPath=StorePath+TITLE+DATE+'result/'\n",
    "\n",
    "if not os.path.exists(StorePath+TITLE+DATE+'graph/'): \n",
    "    os.makedirs(StorePath+TITLE+DATE+'graph/')\n",
    "GraphPath=StorePath+TITLE+DATE+'graph/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**センサデータの読み込み**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# センサデータのcsvファイル名をリストに集約する関数\n",
    "def SensorDataFileNameList(path):\n",
    "    l = os.listdir(DataPath)\n",
    "    FilePath =[]\n",
    "    SensorName = []\n",
    "    \n",
    "    for n in range(len(l)):\n",
    "        if (l[n][:4].find('mem-') != -1):\n",
    "            FilePath.append(l[n])\n",
    "            SensorName.append(l[n][4:15])\n",
    "    \n",
    "    return FilePath,SensorName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSVを読み込んで，CSVの中身を辞書型で表現する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ImportCSV(csv_file,SensorName,mode='Round'):\n",
    "    import pandas as pd\n",
    "    '''\n",
    "    ~Argument~\n",
    "    csv_file -> ファイル名 \n",
    "    mode Round -> 四捨五入\n",
    "         Roundup -> 切り上げ\n",
    "         Rounddown -> 切り捨て\n",
    "    \n",
    "    ~Conversion~\n",
    "    Acc Data  [0.1mG]=>[G]\n",
    "    Gyr Data  [0.01dps]=>[dps]   ...dps=degree per second\n",
    "    '''\n",
    "    # data dictionary \n",
    "    RawData={}   \n",
    "    AccConversion = 0.1 * 0.001\n",
    "    GyrConversion = 0.01\n",
    "    \n",
    "    # design dataframe and import csv\n",
    "    data = pd.read_csv(csv_file)\n",
    "    data.columns=[u'Type',u'Time',u'AccX',u'AccY',u'AccZ',u'GyrX',u'GyrY',u'GyrZ']\n",
    "    data = data[ data['Type']=='ags']\n",
    "\n",
    "    # convert numpy.darray \n",
    "\n",
    "    AccX=data.AccX.values*AccConversion\n",
    "    AccY=data.AccY.values*AccConversion\n",
    "    AccZ=data.AccZ.values*AccConversion\n",
    "    \n",
    "    GyrX=data.GyrX.values*GyrConversion\n",
    "    GyrY=data.GyrY.values*GyrConversion\n",
    "    GyrZ=data.GyrZ.values*GyrConversion\n",
    "\n",
    "    # regist each raw data \n",
    "    RawData['AccX'] = AccX\n",
    "    RawData['AccY'] = AccY\n",
    "    RawData['AccZ'] = AccZ\n",
    "    RawData['GyrX'] = GyrX\n",
    "    RawData['GyrY'] = GyrY\n",
    "    RawData['GyrZ'] = GyrZ\n",
    "    RawData['Name'] = SensorName\n",
    "\n",
    "    RawData['Time'] = data.Time.values\n",
    "\n",
    "    return RawData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import processing\n",
    "import window\n",
    "\n",
    "Label = ['LeftHand','RightHand','LeftLeg','Rightleg','West','Chest']\n",
    "\n",
    "DataFileNameList,SensorName=SensorDataFileNameList(DataPath)\n",
    "l=[]\n",
    "for i in range( len(DataFileNameList) ):\n",
    "    l.append( ImportCSV(DataPath+DataFileNameList[i],Label[i]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**出力チェック**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AccX': array([-1.0102, -0.9973, -0.9951, ..., -0.1794, -0.1789, -0.1792]),\n",
       " 'AccY': array([ 0.0828,  0.0782,  0.0765, ...,  0.3201,  0.3221,  0.3238]),\n",
       " 'AccZ': array([-0.2692, -0.269 , -0.2661, ...,  0.8967,  0.8938,  0.883 ]),\n",
       " 'GyrX': array([ 82.15,  81.2 ,  80.26, ...,   0.39,   0.54,   0.6 ]),\n",
       " 'GyrY': array([ 13.45,  13.8 ,  14.  , ...,   5.57,   6.14,   6.49]),\n",
       " 'GyrZ': array([ 12.8 ,  12.84,  12.7 , ...,   1.38,   1.65,   1.96]),\n",
       " 'Name': 'LeftHand',\n",
       " 'Time': array([36290378, 36290379, 36290380, ..., 37394180, 37394181, 37394182])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AccX': array([-0.9539, -0.9524, -0.9473, ..., -0.1909, -0.2337, -0.2002]),\n",
       " 'AccY': array([ 0.1487,  0.1496,  0.1555, ...,  0.103 ,  0.1623,  0.2256]),\n",
       " 'AccZ': array([-0.1474, -0.1401, -0.1452, ...,  0.9062,  0.9697,  0.9928]),\n",
       " 'GyrX': array([-25.06, -24.22, -23.33, ...,  -5.12,  -5.44,  -6.07]),\n",
       " 'GyrY': array([ 31.23,  30.85,  30.3 , ...,  -4.62,  -7.02, -13.01]),\n",
       " 'GyrZ': array([-9.67, -9.76, -9.65, ...,  3.3 ,  3.5 ,  7.44]),\n",
       " 'Name': 'RightHand',\n",
       " 'Time': array([36290413, 36290414, 36290415, ..., 37400598, 37400599, 37400600])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AccX': array([ 0.974 ,  0.9793,  0.9776, ..., -0.3304, -0.3338, -0.3377]),\n",
       " 'AccY': array([-0.0664, -0.0639, -0.0654, ...,  0.6701,  0.664 ,  0.6625]),\n",
       " 'AccZ': array([-0.2318, -0.2291, -0.2279, ...,  0.6841,  0.6787,  0.6878]),\n",
       " 'GyrX': array([ 1.42,  1.44,  1.36, ...,  1.03,  1.32,  1.35]),\n",
       " 'GyrY': array([-1.57, -1.62, -1.8 , ...,  6.48,  6.54,  6.54]),\n",
       " 'GyrZ': array([ 0.6 ,  0.61,  0.61, ...,  6.14,  6.1 ,  5.9 ]),\n",
       " 'Name': 'LeftLeg',\n",
       " 'Time': array([36289454, 36289455, 36289456, ..., 37383543, 37383544, 37383545])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AccX': array([ 0.9239,  0.9266,  0.9291, ..., -0.3042, -0.3091, -0.3069]),\n",
       " 'AccY': array([-0.1819, -0.1841, -0.1831, ...,  0.204 ,  0.2096,  0.2074]),\n",
       " 'AccZ': array([-0.3983, -0.409 , -0.4095, ...,  0.8953,  0.8936,  0.8948]),\n",
       " 'GyrX': array([-0.23, -0.11, -0.17, ...,  0.24,  0.13, -0.02]),\n",
       " 'GyrY': array([-1.4 , -1.39, -1.51, ..., -1.13, -1.05, -1.22]),\n",
       " 'GyrZ': array([-0.09, -0.08,  0.11, ...,  2.23,  2.3 ,  2.4 ]),\n",
       " 'Name': 'Rightleg',\n",
       " 'Time': array([36289502, 36289503, 36289504, ..., 37375672, 37375673, 37375674])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AccX': array([ 0.8437,  0.8496,  0.8493, ..., -0.0044, -0.0108, -0.0078]),\n",
       " 'AccY': array([-0.0334, -0.0337, -0.0364, ...,  0.0795,  0.0849,  0.089 ]),\n",
       " 'AccZ': array([-0.5486, -0.542 , -0.5413, ...,  0.9938,  0.9762,  0.9752]),\n",
       " 'GyrX': array([-3.27, -3.26, -3.18, ..., -0.66, -0.6 , -0.81]),\n",
       " 'GyrY': array([ 2.89,  2.78,  2.73, ...,  0.41,  0.45,  0.32]),\n",
       " 'GyrZ': array([ 2.35,  2.15,  2.16, ..., -0.19, -0.09, -0.04]),\n",
       " 'Name': 'West',\n",
       " 'Time': array([36289542, 36289543, 36289544, ..., 37399101, 37399102, 37399103])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "読み込んだセンサデータの時系列を整理する．\n",
    "→具体的には，センサデータのスタート時間とゴール時間を整える．\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MakeCommonSection(inputDataArray):\n",
    "    # 共通区間のスタート時間、ゴール時間を求める\n",
    "    # スタート時間を求める\n",
    "    startTime = min(inputDataArray[0]['Time'])\n",
    "    \n",
    "    for i in range(len(inputDataArray)):\n",
    "        if startTime < min(inputDataArray[i]['Time']):\n",
    "            startTime = min(inputDataArray[i]['Time'])\n",
    "    \n",
    "    # ゴール時間を求める\n",
    "    goalTime = max(inputDataArray[0]['Time'])\n",
    "    \n",
    "    for i in range(len(inputDataArray)):\n",
    "        if goalTime > max(inputDataArray[i]['Time']):\n",
    "            goalTime = max(inputDataArray[i]['Time'])\n",
    "\n",
    "    # 共通区間のスタート時間のインデックス、ゴール時間のインデックスを探索する\n",
    "    def CalcSearchIndexFromTime(data, keyTime):\n",
    "        \"\"\"\n",
    "        data　辞書型\n",
    "        keyTime data['Time']の中の探す値\n",
    "        \"\"\"\n",
    "        count = 0\n",
    "        for i in range(0, len(data['Time'])):\n",
    "            if keyTime == data['Time'][i]:\n",
    "                print str(keyTime)+' is much in the index  whose number is '+str(i)\n",
    "                return i\n",
    "            \n",
    "    startIndex = np.array([])\n",
    "    goalIndex = np.array([])\n",
    "    for obj in inputDataArray:\n",
    "        print 'start'\n",
    "        startIndex = np.append(startIndex, CalcSearchIndexFromTime(obj, startTime) ).astype(int)\n",
    "        print 'goal'\n",
    "        goalIndex = np.append(goalIndex, CalcSearchIndexFromTime(obj, goalTime) ).astype(int)\n",
    "\n",
    "    tmp={}\n",
    "    comDataArray =[]\n",
    "    key={}\n",
    "\n",
    "    # センサデータすべて（時刻、加速度、角速度）に対して共通区間のみのデータを抽出\n",
    "    for number,iDA in enumerate( inputDataArray ):\n",
    "\n",
    "        tmp['AccX'] = copy.deepcopy( iDA['AccX'][startIndex[number]:goalIndex[number]] )\n",
    "        tmp['AccY'] = copy.deepcopy( iDA['AccY'][startIndex[number]:goalIndex[number]] )\n",
    "        tmp['AccZ'] = copy.deepcopy( iDA['AccZ'][startIndex[number]:goalIndex[number]] )\n",
    "        tmp['GyrX'] = copy.deepcopy( iDA['GyrX'][startIndex[number]:goalIndex[number]] )\n",
    "        tmp['GyrY'] = copy.deepcopy( iDA['GyrY'][startIndex[number]:goalIndex[number]] )\n",
    "        tmp['GyrZ'] = copy.deepcopy( iDA['GyrZ'][startIndex[number]:goalIndex[number]] )\n",
    "        tmp['Time'] = copy.deepcopy( iDA['Time'][startIndex[number]:goalIndex[number]] )\n",
    "        tmp['Name'] = copy.deepcopy( iDA['Name'] )\n",
    "        comDataArray.append(copy.deepcopy(tmp) )    \n",
    "        key[ tmp['Name'] ] = number\n",
    "       \n",
    "    return key,comDataArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "36290413 is much in the index  whose number is 35\n",
      "goal\n",
      "37368283 is much in the index  whose number is 1077905\n",
      "start\n",
      "36290413 is much in the index  whose number is 0\n",
      "goal\n",
      "37368283 is much in the index  whose number is 1077870\n",
      "start\n",
      "36290413 is much in the index  whose number is 959\n",
      "goal\n",
      "37368283 is much in the index  whose number is 1078829\n",
      "start\n",
      "36290413 is much in the index  whose number is 911\n",
      "goal\n",
      "37368283 is much in the index  whose number is 1078781\n",
      "start\n",
      "36290413 is much in the index  whose number is 871\n",
      "goal\n",
      "37368283 is much in the index  whose number is 1078741\n",
      "start\n",
      "36290413 is much in the index  whose number is 834\n",
      "goal\n",
      "37368283 is much in the index  whose number is 1078704\n"
     ]
    }
   ],
   "source": [
    "TrimKey,TrimData = MakeCommonSection(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type( TrimData[0] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "辞書型に変換したデータをnp.savez関数でnpz型に圧縮し，保存する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(6):\n",
    "    np.savez(DictionaryDataPath+TrimData[i]['Name'],data=TrimData[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ライブラリをimportする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# FFT library\n",
    "from scipy import fftpack\n",
    "from scipy import signal\n",
    "\n",
    "# Graph Plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate WindowFrame Function\n",
    "from mymodule import window\n",
    "\n",
    "# timer\n",
    "import time\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 1080 (CNMeM is disabled, cuDNN 5005)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.datasets import cifar10\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.optimizers import SGD, Adadelta, Adagrad, Adam, Adamax, RMSprop, Nadam\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.utils.visualize_util import model_to_dot, plot\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import matplotlib.image as mpimg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Phase1 計測データの取得**\n",
    "\n",
    "ここで行うことは，学習に用いるnpzファイルを読み込む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'LeftHand' in Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['West.npz', 'Rightleg.npz', 'Chest.npz', 'RightHand.npz', 'LeftHand.npz', 'LeftLeg.npz']\n"
     ]
    }
   ],
   "source": [
    "l = os.listdir(DictionaryDataPath)\n",
    "print l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def LoadDataFromNPZ(Path,DataName):\n",
    "    \"\"\"\n",
    "    Path 　　NPZファイルがあるパス\n",
    "    DataName 名前，ここでは装着した部位を指す\n",
    "    \"\"\"\n",
    "    Label = ['LeftHand','RightHand','LeftLeg','RightLeg','West','Chest']\n",
    "    \n",
    "    # check which DataName is wrong\n",
    "    if not DataName in Label: return -1\n",
    "    \n",
    "    for i in range( len(Label) ):\n",
    "        if DataName == Label[i]:\n",
    "            return np.load(Path+DataName+'.npz')['data'][()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Phase2 window flame 作成 & Learning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizers = [SGD, Adadelta, Adamax, Adam, Adagrad,  RMSprop, Nadam]\n",
    "optimArray = [\"SGD\", \"Adadelta\",\"Adamax\", \"Adam\", \"Adagrad\",  \"RMSprop\", \"Nadam\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回は，テストとして加速度Ｘのデータを使って学習する\n",
    "ウィンドウ幅，スライド幅は最小に定義したベクトルの値\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def AutoEncoder(TrainWindow,TestWindow,dim,opt,cname,batchSize=32):\n",
    "    input_img = Input(shape=( TrainWindow.shape[1] ,))\n",
    "    encoded = Dense(dim, activation='tanh')(input_img)\n",
    "    decoded = Dense( TrainWindow.shape[1] , activation='linear')(encoded)\n",
    "    autoencoder = Model(input=input_img, output=decoded)\n",
    "    encoder = Model(input=input_img, output=encoded)\n",
    "    encoded_input = Input(shape=(dim,))\n",
    "    decoder_layer = autoencoder.layers[-1]\n",
    "    decoder = Model(input=encoded_input, output=decoder_layer(encoded_input))\n",
    "    autoencoder.compile(optimizer=opt, loss='mse')\n",
    "\n",
    "    #plot(autoencoder,  to_file=StudyDataModelPicPath+SaveFileNameNet+'.png')\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "    hist = autoencoder.fit(TrainWindow, TestWindow,\n",
    "                    nb_epoch=50,\n",
    "                    verbose=2,\n",
    "                    batch_size=batchSize,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(TrainWindow, TestWindow),\n",
    "                    callbacks=[early_stopping])\n",
    "    time.sleep(0.1)\n",
    "\n",
    "    encoded_imgs = encoder.predict(TrainWindow,batch_size=batchSize,verbose=1)\n",
    "    decoded_imgs = decoder.predict(encoded_imgs,batch_size=batchSize,verbose=1)\n",
    "\n",
    "    np.savez(StudyOutputPath+cname+'_Encoded',data=encoded_imgs)\n",
    "    np.savez(StudyOutputPath+cname+'_Decoded',data=decoded_imgs)\n",
    "\n",
    "    # save model and wights\n",
    "    json_string = encoder.to_json()\n",
    "    open(StudyOutputPath+cname+'_Encoded'+'.json', 'w').write(json_string)\n",
    "    encoder.save_weights(ParametorPath+cname+'Encode_weights.h5',overwrite=True)\n",
    "\n",
    "    json_string = decoder.to_json()\n",
    "    open(StudyOutputPath+cname+'_Decoded'+'.json', 'w').write(json_string)\n",
    "    decoder.save_weights(ParametorPath+cname+'Decord_weights.h5',overwrite=True)\n",
    "\n",
    "    json_string = autoencoder.to_json()\n",
    "    open(StudyOutputPath+cname+'_Net'+'.json', 'w').write(json_string)\n",
    "    autoencoder.save_weights(ParametorPath+cname+'Net_weights.h5',overwrite=True)\n",
    "\n",
    "    # plot loss\n",
    "    loss = hist.history['loss']\n",
    "    val_loss = hist.history['val_loss']\n",
    "\n",
    "    nb_epoch = len(loss)\n",
    "    plt.plot(range(nb_epoch), loss, marker='.', label='loss')\n",
    "    plt.plot(range(nb_epoch), val_loss, marker='.', label='val_loss')\n",
    "    plt.legend(loc='best', fontsize=10)\n",
    "    plt.grid()\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.savefig(ResultPath+cname+'.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AccX is registed now\n",
      "Build Complete\n",
      "(1077870,)\n",
      "windowData's num =33680\n",
      "SourceData's aborting data = 14\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-5c97414f6f15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWindow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSetData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'AccX'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTrimData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'AccX'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mwind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindowWidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mWindowNum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moverlapNum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSlidingNum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mwindoW\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/takeyama/pywork/ipython/2016-11-11/Learning-OptimChange/Overlap=32_EncDim=16/window.pyc\u001b[0m in \u001b[0;36mCompile\u001b[0;34m(self, windowWidth, overlapNum)\u001b[0m\n",
      "\u001b[0;32m/home/takeyama/.pyenv/versions/2.7.11/envs/takeyama/lib/python2.7/site-packages/numpy/lib/shape_base.pyc\u001b[0m in \u001b[0;36mdstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m     \"\"\"\n\u001b[0;32m--> 368\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0matleast_3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_replace_zero_by_x_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_arys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# loop windowWidth\n",
    "for WindowNum,SlidingNum in zip(WindowWidth,SlidingWidth):\n",
    "    w=window.Window()\n",
    "    w.SetData('AccX',TrimData[0]['AccX'])\n",
    "    wind=w.Compile(windowWidth=WindowNum,overlapNum=SlidingNum)\n",
    "    windoW=wind.reshape((len(wind),np.prod(wind.shape[1:])))\n",
    "    \n",
    "    for opt,optName in zip(optimizers,optimArray):\n",
    "        print \"hiden node = \"+str(AEDimention)\n",
    "        CommonName='_dim='+str(AEDimention).zfill(4)+'_Win='+str(WindowNum).zfill(4)+'_Sld='+str(SlidingNum).zfill(4)+'_'+optName\n",
    "        print CommonName\n",
    "        \n",
    "        np.savez(WindowDataPath+CommonName+'_Test',data=windoW)\n",
    "        np.savez(WindowDataPath+CommonName+'_Train',data=windoW)\n",
    "        \n",
    "        AutoEncoder(windoW,windoW,AEDimention,optName,CommonName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'finish'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''This script demonstrates how to build a variational autoencoder with Keras.\n",
    "Reference: \"Auto-Encoding Variational Bayes\" https://arxiv.org/abs/1312.6114\n",
    "'''\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.layers import Input, Dense, Lambda\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import objectives\n",
    "from keras.datasets import mnist\n",
    "\n",
    "batch_size = 100\n",
    "original_dim = 784\n",
    "latent_dim = 2\n",
    "intermediate_dim = 256\n",
    "nb_epoch = 50\n",
    "epsilon_std = 1.0\n",
    "\n",
    "x = Input(batch_shape=(batch_size, original_dim))\n",
    "h = Dense(intermediate_dim, activation='relu')(x)\n",
    "z_mean = Dense(latent_dim)(h)\n",
    "z_log_var = Dense(latent_dim)(h)\n",
    "\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(batch_size, latent_dim), mean=0.,\n",
    "                              std=epsilon_std)\n",
    "    return z_mean + K.exp(z_log_var / 2) * epsilon\n",
    "\n",
    "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
    "\n",
    "# we instantiate these layers separately so as to reuse them later\n",
    "decoder_h = Dense(intermediate_dim, activation='relu')\n",
    "decoder_mean = Dense(original_dim, activation='sigmoid')\n",
    "h_decoded = decoder_h(z)\n",
    "x_decoded_mean = decoder_mean(h_decoded)\n",
    "\n",
    "\n",
    "def vae_loss(x, x_decoded_mean):\n",
    "    xent_loss = original_dim * objectives.binary_crossentropy(x, x_decoded_mean)\n",
    "    kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "    return xent_loss + kl_loss\n",
    "\n",
    "vae = Model(x, x_decoded_mean)\n",
    "vae.compile(optimizer='rmsprop', loss=vae_loss)\n",
    "\n",
    "# train the VAE on MNIST digits\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "\n",
    "plot(vae,  to_file='vae_network_image.png')\n",
    "\n",
    "vae.fit(x_train, x_train,\n",
    "        shuffle=True,\n",
    "        nb_epoch=nb_epoch,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_test, x_test))\n",
    "\n",
    "# build a model to project inputs on the latent space\n",
    "encoder = Model(x, z_mean)\n",
    "\n",
    "# display a 2D plot of the digit classes in the latent space\n",
    "x_test_encoded = encoder.predict(x_test, batch_size=batch_size)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], c=y_test)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# build a digit generator that can sample from the learned distribution\n",
    "decoder_input = Input(shape=(latent_dim,))\n",
    "_h_decoded = decoder_h(decoder_input)\n",
    "_x_decoded_mean = decoder_mean(_h_decoded)\n",
    "generator = Model(decoder_input, _x_decoded_mean)\n",
    "\n",
    "# display a 2D manifold of the digits\n",
    "n = 15  # figure with 15x15 digits\n",
    "digit_size = 28\n",
    "figure = np.zeros((digit_size * n, digit_size * n))\n",
    "# we will sample n points within [-15, 15] standard deviations\n",
    "grid_x = np.linspace(-15, 15, n)\n",
    "grid_y = np.linspace(-15, 15, n)\n",
    "\n",
    "for i, yi in enumerate(grid_x):\n",
    "    for j, xi in enumerate(grid_y):\n",
    "        z_sample = np.array([[xi, yi]])\n",
    "        x_decoded = generator.predict(z_sample)\n",
    "        digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "        figure[i * digit_size: (i + 1) * digit_size,\n",
    "               j * digit_size: (j + 1) * digit_size] = digit\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(figure)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_test_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Seed['AccX'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " windoW.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
