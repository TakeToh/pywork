{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "幅広くデータを見ていく\n",
    "* 加速度の波形を並べていみる\n",
    "* ウィンドウフレームごとの平均，分散の変化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 表示用\n",
    "from tqdm import tqdm\n",
    "from tqdm import tnrange, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import zeros, newaxis\n",
    "import datetime\n",
    "import os\n",
    "import copy\n",
    "import time\n",
    "\n",
    "# Parametor about Sensor\n",
    "SensorNum=1 # Sensor number\n",
    "#SensorAxis='AccX' # Axis\n",
    "\n",
    "# Parametor about  \" Sliding Window \" \n",
    "WindowWidth =np.array([128,256,512,1024,2048,4096]) # Window Width\n",
    "SlidingWidth =WindowWidth/4 #sliding window\n",
    "\n",
    "# Parametor about Neural Network\n",
    "AEDimention = 16\n",
    "\n",
    "# Define Data Name\n",
    "DATE= str( datetime.date.today() )+'/'\n",
    "TITLE=\"Participants01_First_1/\"\n",
    "\n",
    "# Parametor about \" Data Path\"\n",
    "DataPath = \"/media/takeyama/Transfer/02_ActivityResearch/Paticipants01/01_First/20161018-105301/mem/\"\n",
    "\n",
    "#chopin\n",
    "#StorePath = \"/home/takeyama/Documents/\"\n",
    "#mozart\n",
    "StorePath =\"/media/takeyama/HD-PNFU3/01_ActivityResearchData/\"\n",
    "if not os.path.exists(StorePath+TITLE+'dictionary/'): \n",
    "    os.makedirs(StorePath+TITLE+'dictionary/')\n",
    "DictionaryDataPath=StorePath+TITLE+'dictionary/'\n",
    "\n",
    "if not os.path.exists(StorePath+TITLE+'window/'): \n",
    "    os.makedirs(StorePath+TITLE+'window/')\n",
    "WindowDataPath=StorePath+TITLE+'window/'\n",
    "\n",
    "if not os.path.exists(StorePath+TITLE+DATE+'studyOutput/'): \n",
    "    os.makedirs(StorePath+TITLE+DATE+'studyOutput/')\n",
    "StudyOutputPath=StorePath+TITLE+DATE+'studyOutput/'\n",
    "\n",
    "if not os.path.exists(StorePath+TITLE+DATE+'parametor/'): \n",
    "    os.makedirs(StorePath+TITLE+DATE+'parametor/')\n",
    "ParametorPath=StorePath+TITLE+DATE+'parametor/'\n",
    "\n",
    "if not os.path.exists(StorePath+TITLE+DATE+'result/'): \n",
    "    os.makedirs(StorePath+TITLE+DATE+'result/')\n",
    "ResultPath=StorePath+TITLE+DATE+'result/'\n",
    "\n",
    "if not os.path.exists(StorePath+'/'+TITLE+DATE+'graph/'): \n",
    "    os.makedirs(StorePath+'/'+TITLE+DATE+'graph/')\n",
    "GraphPath=StorePath+'/'+TITLE+DATE+'graph/'\n",
    "\n",
    "if not os.path.exists(StorePath+'/'+TITLE+DATE+'graph/corrMap/'): \n",
    "    os.makedirs(StorePath+'/'+TITLE+DATE+'graph/corrMap/')\n",
    "CorrMapGraphPath=StorePath+'/'+TITLE+DATE+'graph/corrMap/'\n",
    "\n",
    "if not os.path.exists(StorePath+'/'+TITLE+'feature/'): \n",
    "    os.makedirs(StorePath+'/'+TITLE+'feature/')\n",
    "FeaturePath=StorePath+'/'+TITLE+'feature/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "センサデータの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# センサデータのcsvファイル名をリストに集約する関数\n",
    "def SensorDataFileNameList(path):\n",
    "    l = os.listdir(DataPath)\n",
    "    FilePath =[]\n",
    "    SensorName = []\n",
    "    \n",
    "    for n in range(len(l)):\n",
    "        if (l[n][:4].find('mem-') != -1):\n",
    "            FilePath.append(l[n])\n",
    "            SensorName.append(l[n][4:15])\n",
    "    \n",
    "    return FilePath,SensorName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSVを読み込んで，CSVの中身を辞書型で表現する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# FFT library\n",
    "from scipy import fftpack\n",
    "from scipy import signal\n",
    "\n",
    "# Graph Plot\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "\n",
    "# Generate WindowFrame Function\n",
    "from mymodule import window\n",
    "\n",
    "# timer\n",
    "import time\n",
    "\n",
    "# temp file \n",
    "import tempfile\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Chest.npz', 'LeftHand.npz', 'LeftLeg.npz', 'RightHand.npz', 'Rightleg.npz', 'West.npz']\n"
     ]
    }
   ],
   "source": [
    "DictName = os.listdir(DictionaryDataPath)\n",
    "print DictName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Sensor5 = np.load(DictionaryDataPath+DictName[0])['data'][()]\n",
    "Sensor1 = np.load(DictionaryDataPath+DictName[1])['data'][()]\n",
    "Sensor3 = np.load(DictionaryDataPath+DictName[2])['data'][()]\n",
    "Sensor2 = np.load(DictionaryDataPath+DictName[3])['data'][()]\n",
    "Sensor4 = np.load(DictionaryDataPath+DictName[4])['data'][()]\n",
    "Sensor6 = np.load(DictionaryDataPath+DictName[5])['data'][()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def GetWindowFrame(windowName, dataRaw, wWidth, sWidth, PATH):\n",
    "    \"\"\"\n",
    "    data　ウィンドウフレームに変換するデータ\n",
    "    registName　ウィンドウフレームに登録するデータの名前\n",
    "    windowWidth　ウィンドウ幅\n",
    "    slidingWidth　スライド幅\n",
    "    PATH ウィドウフレームを保存するディレクトリ\n",
    "    \n",
    "    \n",
    "    About Function:\n",
    "        与えられたdataからウィンドウ幅windowWidth,スライド幅slidingWidthにしたがって\n",
    "        registNameのウィドウフレームを返す．\n",
    "        また，与えれたPATH内に同様なパラメータ( WindowWidth, slidingWidth)かつ同様な\n",
    "        windowNameのものがある場合，そのデータを返す．\n",
    "        この関数が登録，ウィンドウフレームに変換できるデータは１つとする\n",
    "    \"\"\"\n",
    "    storedName = windowName+'_Win='+str(wWidth).zfill(4)+'_Sld='+str(sWidth).zfill(4)+'.npz'\n",
    "    l = os.listdir(PATH)\n",
    "    \n",
    "    if storedName in l:\n",
    "        print \"this data had finished making\"\n",
    "        return np.load(PATH+storedName)['data'][()]\n",
    "    \n",
    "    w=window()\n",
    "    w.SetData(windowName,dataRaw)    \n",
    "    wind=w.Compile(wWidth,sWidth)\n",
    "    windoW=wind.reshape((len(wind),np.prod(wind.shape[1:])))\n",
    "    \n",
    "    np.savez(PATH+storedName,data=wind)\n",
    "\n",
    "    return wind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methematical/Statistical Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean, Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FastVector_Mean(windowName, dataRaw, wWidth, sWidth, PATH):\n",
    "    # get windowFrame\n",
    "    wind=GetWindowFrame(windowName, dataRaw, wWidth, sWidth, PATH)\n",
    "    Output = np.array( [wind[i,:].mean() for i in range(wind.shape[0]) ] )\n",
    "    print '===========finished Making Vector of Mean==========='\n",
    "    return Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FastVector_Median(windowName, dataRaw, wWidth, sWidth, PATH):\n",
    "    # get windowFrame\n",
    "    wind=GetWindowFrame(windowName, dataRaw, wWidth, sWidth, PATH)\n",
    "    Output = np.array( [np.median(wind[i,:]) for i in range(wind.shape[0]) ] )\n",
    "    print '===========finished Making Vector of Median==========='\n",
    "    return Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance, Std Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FastVector_Var(windowName, dataRaw, wWidth, sWidth, PATH):\n",
    "    # get windowFrame\n",
    "    wind=GetWindowFrame(windowName, dataRaw, wWidth, sWidth, PATH)\n",
    "    Output = np.array( [wind[i,:].var() for i in range(wind.shape[0]) ] )\n",
    "    print '===========finished Making Vector of Variance==========='\n",
    "    return Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FastVector_StdDev(windowName, dataRaw, wWidth, sWidth, PATH):\n",
    "    # get windowFrame\n",
    "    wind=GetWindowFrame(windowName, dataRaw, wWidth, sWidth, PATH)  \n",
    "    Output = np.array( [wind[i,:].var()**0.5 for i in range(wind.shape[0]) ] )\n",
    "    print '===========finished Making Vector of standard Deviation==========='\n",
    "    return Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Min, Max, Range\n",
    "Range = the difference between maximum and minimum sample values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FastVector_Max(windowName, dataRaw, wWidth, sWidth, PATH):\n",
    "    # get windowFrame\n",
    "    wind=GetWindowFrame(windowName, dataRaw, wWidth, sWidth, PATH)\n",
    "    Output = np.array( [wind[i,:].max() for i in range(wind.shape[0]) ] )\n",
    "    print '===========finished Making Vector of Max==========='\n",
    "    return Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def FastVector_Min(windowName, dataRaw, wWidth, sWidth, PATH):\n",
    "    # get windowFrame\n",
    "    wind=GetWindowFrame(windowName, dataRaw, wWidth, sWidth, PATH)\n",
    "    Output = np.array( [wind[i,:].min() for i in range(wind.shape[0]) ] )\n",
    "    print '===========finished Making Vector of Min==========='\n",
    "    return Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def FastVector_Range(windowName, dataRaw, wWidth, sWidth, PATH):\n",
    "    # get windowFrame\n",
    "    wind=GetWindowFrame(windowName, dataRaw, wWidth, sWidth, PATH)\n",
    "    Output = np.array( [(wind[i,:].max()-wind[i,:].min())\\\n",
    "                        for i in range(wind.shape[0]) ] )\n",
    "    print '===========finished Making Vector of Range==========='\n",
    "    return Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FastVector_RMS(windowName, dataRaw, wWidth, sWidth, PATH):\n",
    "    # get windowFrame\n",
    "    wind=GetWindowFrame(windowName, dataRaw, wWidth, sWidth, PATH)\n",
    "    Output = np.array( [((np.sum( wind[i,:]**2)/wind[i,:].size)**0.5)\\\n",
    "                        for i in range(wind.shape[0]) ] )\n",
    "    print '===========finished Making Vector of Root Means Square==========='\n",
    "    return Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation, Cross-Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def FastVector_Corr(windowNameX, dataRawX, windowNameY, dataRawY, wWidth, sWidth, PATH):\n",
    "    # get windowFrame\n",
    "    windX=GetWindowFrame(windowNameX, dataRawX, wWidth, sWidth, PATH)\n",
    "    windY=GetWindowFrame(windowNameY, dataRawY, wWidth, sWidth, PATH)\n",
    "    Output = np.array( [( np.corrcoef(windX[i,:],windY[i,:]) )\\\n",
    "                    for i in range(windX.shape[0]) ] )\n",
    "    print '===========finished Making Vector of Correlation==========='\n",
    "    return Output[:,0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Signal magnitude area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FastVector_SMA(windowName, dataRawX, dataRawY, dataRawZ, wWidth, sWidth, PATH):\n",
    "    # get windowFrame\n",
    "    windX=GetWindowFrame(windowName, dataRawX, wWidth, sWidth, PATH)\n",
    "    windY=GetWindowFrame(windowName, dataRawY, wWidth, sWidth, PATH)\n",
    "    windZ=GetWindowFrame(windowName, dataRawZ, wWidth, sWidth, PATH)\n",
    "    Output = np.array( [(np.sum((windX[i,:]**2+windY[i,:]**2+windZ[i,:]**2)**0.5))\\\n",
    "                for i in range(windX.shape[0]) ] )\n",
    "    print '===========finished Making Vector of Signal Magnitude Area==========='\n",
    "    return Output  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 各センサの相関を求める"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label_Sensor1.npz\r\n",
      "LeftHand_AccX_Win=0256_Sld=0008_Corr.npz\r\n",
      "LeftHand_AccX_Win=0256_Sld=0008_Energy.npz\r\n",
      "LeftHand_AccX_Win=0256_Sld=0008_Entropy.npz\r\n",
      "LeftHand_AccX_Win=0256_Sld=0008_Frequency.npz\r\n",
      "LeftHand_AccX_Win=0256_Sld=0008_Max.npz\r\n",
      "LeftHand_AccX_Win=0256_Sld=0008_Mean.npz\r\n",
      "LeftHand_AccX_Win=0256_Sld=0008_Median.npz\r\n",
      "LeftHand_AccX_Win=0256_Sld=0008_Min.npz\r\n",
      "LeftHand_AccX_Win=0256_Sld=0008_RMS.npz\r\n",
      "LeftHand_AccX_Win=0256_Sld=0008_SMA.npz\r\n",
      "LeftHand_AccX_Win=0256_Sld=0008_StdDev.npz\r\n",
      "w=0256_s=0032_CorrelationMapAccX.npz\r\n",
      "w=0256_s=0032_JSDMapAccX.npz\r\n",
      "w=0256_s=0032_KLDMapAccX.npz\r\n"
     ]
    }
   ],
   "source": [
    "ls /media/takeyama/HD-PNFU3/01_ActivityResearchData/Participants01_First_1/feature/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LabelAndData = np.load('/media/takeyama/HD-PNFU3/01_ActivityResearchData/Participants01_First_1/feature/'+'Label_Sensor1.npz')['data'][()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.0156, -1.0073, -1.0041, ..., -0.07390000000000001, -0.0747,\n",
       "        -0.0742],\n",
       "       [-0.042300000000000004, -0.0516, -0.0577, ...,\n",
       "        -0.024800000000000003, -0.0275, -0.024800000000000003],\n",
       "       [-0.2341, -0.2341, -0.2409, ..., 0.9472, 0.9514, 0.9502],\n",
       "       ..., \n",
       "       [nan, nan, nan, ..., u'\\u306a\\u3057', u'\\u306a\\u3057',\n",
       "        u'\\u306a\\u3057'],\n",
       "       [nan, nan, nan, ..., u'\\u76f4\\u7acb', u'\\u76f4\\u7acb',\n",
       "        u'\\u76f4\\u7acb'],\n",
       "       [nan, nan, nan, ..., 114.0, 114.0, 114.0]], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LabelAndData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[u'\\u505c\\u6b62', u'\\u505c\\u6b62', u'\\u505c\\u6b62', ...,\n",
       "        u'\\u306a\\u3057', u'\\u306a\\u3057', u'\\u306a\\u3057'],\n",
       "       [nan, nan, nan, ..., u'\\u306a\\u3057', u'\\u306a\\u3057',\n",
       "        u'\\u306a\\u3057'],\n",
       "       [nan, nan, nan, ..., u'\\u306a\\u3057', u'\\u306a\\u3057',\n",
       "        u'\\u306a\\u3057'],\n",
       "       ..., \n",
       "       [nan, nan, nan, ..., u'\\u306a\\u3057', u'\\u306a\\u3057',\n",
       "        u'\\u306a\\u3057'],\n",
       "       [nan, nan, nan, ..., u'\\u76f4\\u7acb', u'\\u76f4\\u7acb',\n",
       "        u'\\u76f4\\u7acb'],\n",
       "       [nan, nan, nan, ..., 114.0, 114.0, 114.0]], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LabelAndData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
