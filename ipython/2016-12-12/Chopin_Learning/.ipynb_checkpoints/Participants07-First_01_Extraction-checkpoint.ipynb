{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "import copy\n",
    "# Generate WindowFrame Function\n",
    "from mymodule import window\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Parametor about Sensor\n",
    "SensorNum=1 # Sensor number\n",
    "#SensorAxis='AccX' # Axis\n",
    "\n",
    "# Define Data Name\n",
    "DATE= str( datetime.date.today() )+'/'\n",
    "\n",
    "# Parametor about \" Data Path\"\n",
    "StorePath = \"/media/takeyama/Transfer/02_ActivityResearch/\"\n",
    "\n",
    "ParticipantsNum=\"Participants07/\"\n",
    "Version = \"01_First/\"\n",
    "Time = \"01_First/\"\n",
    "LabelName = 'Participants07-First-01.csv'\n",
    "\n",
    "TITLE = ParticipantsNum+Version\n",
    "\n",
    "DataPath = StorePath+ParticipantsNum+Version+\"RawData/\"+Time\n",
    "\n",
    "if not os.path.exists(StorePath+TITLE+'LabelData/'+Time): \n",
    "    os.makedirs(StorePath+TITLE+'LabelData/'+Time)\n",
    "LabelDataPath=StorePath+TITLE+'LabelData/'+Time\n",
    "\n",
    "if not os.path.exists(StorePath+TITLE+'dictionary/'+Time): \n",
    "    os.makedirs(StorePath+TITLE+'dictionary/'+Time)\n",
    "DictionaryDataPath=StorePath+TITLE+'dictionary/'+Time\n",
    "\n",
    "if not os.path.exists(StorePath+TITLE+'feature/'+Time): \n",
    "    os.makedirs(StorePath+TITLE+'feature/'+Time)\n",
    "FeaturePath=StorePath+TITLE+'feature/'+Time\n",
    "\n",
    "if not os.path.exists(StorePath+TITLE+'window/'+Time): \n",
    "    os.makedirs(StorePath+TITLE+'window/'+Time)\n",
    "WindowDataPath=StorePath+TITLE+'window/'+Time\n",
    "\n",
    "if not os.path.exists(StorePath+TITLE+DATE+'studyOutput/'+Time): \n",
    "    os.makedirs(StorePath+TITLE+DATE+'studyOutput/'+Time)\n",
    "StudyOutputPath=StorePath+TITLE+DATE+'studyOutput/'+Time\n",
    "\n",
    "if not os.path.exists(StorePath+TITLE+DATE+'parametor/'+Time): \n",
    "    os.makedirs(StorePath+TITLE+DATE+'parametor/'+Time)\n",
    "ParametorPath=StorePath+TITLE+DATE+'parametor/'+Time\n",
    "\n",
    "if not os.path.exists(StorePath+TITLE+DATE+'result/'+Time): \n",
    "    os.makedirs(StorePath+TITLE+DATE+'result/'+Time)\n",
    "ResultPath=StorePath+TITLE+DATE+'result/'+Time\n",
    "\n",
    "if not os.path.exists(StorePath+TITLE+DATE+'graph/'+Time): \n",
    "    os.makedirs(StorePath+TITLE+DATE+'graph/'+Time)\n",
    "GraphPath=StorePath+TITLE+DATE+'graph/'+Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Read SensorData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# センサデータのcsvファイル名をリストに集約する関数\n",
    "def SensorDataFileNameList(path):\n",
    "    l = os.listdir(DataPath)\n",
    "    FilePath =[]\n",
    "    SensorName = []\n",
    "    \n",
    "    for n in range(len(l)):\n",
    "        if (l[n][:4].find('mem-') != -1):\n",
    "            FilePath.append(l[n])\n",
    "            SensorName.append(l[n][4:15])\n",
    "    \n",
    "    return FilePath,SensorName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FFT library\n",
    "from scipy import fftpack\n",
    "from scipy import signal\n",
    "\n",
    "# Graph Plot\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "\n",
    "# Generate WindowFrame Function\n",
    "from mymodule import window\n",
    "\n",
    "# timer\n",
    "import time\n",
    "\n",
    "# temp file \n",
    "import tempfile\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['01_LeftHand.npz', '02_RightHand.npz', '03_LeftLeg.npz', '04_Rightleg.npz', '05_West.npz', '06_Chest.npz', '07_LabelData.npz']\n"
     ]
    }
   ],
   "source": [
    "DictName = os.listdir(DictionaryDataPath)\n",
    "print DictName\n",
    "Sensor1 = np.load(DictionaryDataPath+DictName[0])['data'][()]\n",
    "Sensor2 = np.load(DictionaryDataPath+DictName[1])['data'][()]\n",
    "Sensor3 = np.load(DictionaryDataPath+DictName[2])['data'][()]\n",
    "Sensor4 = np.load(DictionaryDataPath+DictName[3])['data'][()]\n",
    "Sensor5 = np.load(DictionaryDataPath+DictName[4])['data'][()]\n",
    "Sensor6 = np.load(DictionaryDataPath+DictName[5])['data'][()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetWindowFrame(windowName, dataRaw, wWidth, sWidth, storedName, PATH):\n",
    "    \"\"\"\n",
    "    data　ウィンドウフレームに変換するデータ\n",
    "    registName　ウィンドウフレームに登録するデータの名前\n",
    "    windowWidth　ウィンドウ幅\n",
    "    slidingWidth　スライド幅\n",
    "    PATH ウィドウフレームを保存するディレクトリ\n",
    "    \n",
    "    \n",
    "    About Function:\n",
    "        与えられたdataからウィンドウ幅windowWidth,スライド幅slidingWidthにしたがって\n",
    "        registNameのウィドウフレームを返す．\n",
    "        また，与えれたPATH内に同様なパラメータ( WindowWidth, slidingWidth)かつ同様な\n",
    "        windowNameのものがある場合，そのデータを返す．\n",
    "        この関数が登録，ウィンドウフレームに変換できるデータは１つとする\n",
    "    \"\"\"\n",
    "    l = os.listdir(PATH)\n",
    "    \n",
    "    if storedName in l:\n",
    "        print \"this data had finished making\"\n",
    "        return np.load(PATH+storedName)['data'][()]\n",
    "    \n",
    "    w=window()\n",
    "    w.SetData(windowName,dataRaw)    \n",
    "    wind=w.Compile(wWidth,sWidth)\n",
    "    windoW=wind.reshape((len(wind),np.prod(wind.shape[1:])))\n",
    "    \n",
    "    np.savez(PATH+storedName,data=wind)\n",
    "\n",
    "    return wind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Extraction Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequency Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FastVector_Energy(windowName, dataRaw, wWidth, sWidth, PATH):\n",
    "    # get windowFrame\n",
    "    wind=GetWindowFrame(windowName, dataRaw, wWidth, sWidth, PATH)\n",
    "    \n",
    "    fftwind = np.fft.fft(wind)  # calcurate fast fourier Transfromation\n",
    "    fftwind = fftwind[:,1:fftwind.shape[1]/2-1] # Orthogonal and Colossus removed\n",
    "    \n",
    "    # calcurate eq\n",
    "    f = lambda x: np.real(x)**2+np.imag(x)**2\n",
    "        \n",
    "    # windowFrame(raw wave) 2d -> windowFrame(power) 1d\n",
    "    SqrF=np.array([\n",
    "            np.real(fftwind[i,l])**2+np.imag(fftwind[i,l])**2\n",
    "            for i in range( fftwind.shape[0] )\n",
    "            for l in range( fftwind.shape[1] )\n",
    "        ])\n",
    "    SqrF = SqrF.reshape(fftwind.shape)    \n",
    "    # calcurate Squared Energy\n",
    "    SqrF=SqrF/SqrF[0,:].size\n",
    "    Output = SqrF**0.5\n",
    "    return Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FastVector_Frequency(windowName, dataRaw, wWidth, sWidth, fName,PATH):\n",
    "    # get windowFrame\n",
    "    wind=GetWindowFrame(windowName, dataRaw, wWidth, sWidth, fName,PATH)\n",
    "    print wind.shape\n",
    "    \n",
    "    fftwind = np.fft.fft(wind)  # calcurate fast fourier Transfromation\n",
    "    print fftwind.shape\n",
    "\n",
    "    fftwind = fftwind[:,1:fftwind.shape[1]/2-1] # Orthogonal and Colossus removed\n",
    "    print fftwind.shape\n",
    "    freq = np.array([np.arctan2(np.imag(fftwind[i,l]),np.real(fftwind[i,l]))\n",
    "                     for i in range( fftwind.shape[0] ) \n",
    "                     for l in range( fftwind.shape[1] ) ])\n",
    "    freq = freq.reshape(fftwind.shape)    \n",
    "    return freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FastVector_Entropy(windowName, dataRaw, wWidth, sWidth, fName,PATH):\n",
    "    # get windowFrame\n",
    "    wind=GetWindowFrame(windowName, dataRaw, wWidth, sWidth, fName,PATH)\n",
    "    \n",
    "    ###########################\n",
    "    ###    calcurate FFT    ###\n",
    "    ###########################\n",
    "    fftwind = np.fft.fft(wind)  # calcurate fast fourier Transfromation\n",
    "    fftwind = fftwind[:,1:fftwind.shape[1]/2-1] # Orthogonal and Colossus removed\n",
    "    \n",
    "    # calcurate eq\n",
    "    f = lambda x: np.real(x)**2+np.imag(x)**2\n",
    "        \n",
    "    # windowFrame(raw wave) 2d -> windowFrame(power) 1d\n",
    "    SqrF=np.array([\n",
    "            np.real(fftwind[i,l])**2+np.imag(fftwind[i,l])**2\n",
    "            for i in range( fftwind.shape[0] )\n",
    "            for l in range( fftwind.shape[1] )\n",
    "        ])\n",
    "    SqrF = SqrF.reshape(fftwind.shape)\n",
    "    \n",
    "    # calcurate Squared Energy\n",
    "    SqrF=SqrF/SqrF[0,:].size\n",
    "    print SqrF.shape\n",
    "    \n",
    "    ##############################\n",
    "    ###    calcurate Entropy   ###\n",
    "    ##############################\n",
    "    P = np.array([SqrF[i]/SqrF[i,:].sum() for i in range(SqrF.shape[0])])\n",
    "    print P.shape\n",
    "    P = P.reshape(SqrF.shape)\n",
    "    \n",
    "    P_logP = np.array([ P[i,l]*np.log(P[i,l]) \\\n",
    "                      for i in range(P.shape[0]) for l in range(P.shape[1])])\n",
    "    print P_logP.shape\n",
    "    P_logP = P_logP.reshape(P.shape)\n",
    "    \n",
    "    Entropy = np.array([\n",
    "            -1*np.sum( P_logP[i,:] ) for i in range(P.shape[0])])\n",
    "    \n",
    "    return Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FastVector_KLD(dataName, dataX, dataY, wWidth, sWidth, fName,PATH):\n",
    "    \"\"\"\n",
    "        Calculates Kullback–Leibler divergence\n",
    "        input dataX dataY -> 1d Vector\n",
    "    \"\"\"\n",
    "    func_kld =lambda p,q: np.sum(p * np.log(p / q))\n",
    "    \n",
    "    KLD = np.array([ func_kld(dataX[i,:],dataY[i,:])\\\n",
    "                    for i in range(dataX.shape[0])])\n",
    "    return KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FastVector_JSD(dataName, dataX, dataNameY, dataY, wWidth, sWidth,fName, PATH):\n",
    "    \n",
    "    func_kld =lambda p,q: np.sum(p * np.log(p / q))\n",
    "    func_jsd =lambda p,q: 0.5 * func_kld(p, (p+q)/2) + 0.5 * func_kld(q, (p+q)/2)\n",
    "\n",
    "    JSD = np.array([ func_jsd(dataX[i,:],dataY[i,:])\\\n",
    "                    for i in range(dataX.shape[0])])\n",
    "    return JSD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methematical/Statistical Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Vector_Mean(windowName, dataRaw, wWidth, sWidth, fName,PATH):\n",
    "    # get windowFrame\n",
    "    wind=GetWindowFrame(windowName, dataRaw, wWidth, sWidth, fName,PATH)\n",
    "    \n",
    "    Output = np.array([])\n",
    "    for i in tqdm_notebook( range( wind.shape[0] ),desc='Mean' ):\n",
    "        Output = np.append(Output, wind[i,:].mean())\n",
    "    return Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Vector_Median(windowName, dataRaw, wWidth, sWidth, fName,PATH):\n",
    "    # get windowFrame\n",
    "    wind=GetWindowFrame(windowName, dataRaw, wWidth, sWidth, fName,PATH)\n",
    "    \n",
    "    Output = np.array([])\n",
    "    for i in tqdm_notebook( range( wind.shape[0] ) ,desc='Median'):\n",
    "        Output = np.append(Output, np.median(wind[i,:].mean()) )\n",
    "    return Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Vector_Var(windowName, dataRaw, wWidth, sWidth, fName,PATH):\n",
    "    # get windowFrame\n",
    "    wind=GetWindowFrame(windowName, dataRaw, wWidth, sWidth, fName,PATH)\n",
    "    \n",
    "    Output = np.array([])\n",
    "    for i in tqdm_notebook( range( wind.shape[0] ) ,desc='Var' ):\n",
    "        Output = np.append(Output, wind[i,:].var())\n",
    "    return Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Vector_StdDev(windowName, dataRaw, wWidth, sWidth, fName,PATH):\n",
    "    # get windowFrame\n",
    "    wind=GetWindowFrame(windowName, dataRaw, wWidth, sWidth, fName,PATH)\n",
    "    \n",
    "    Output = np.array([])\n",
    "    for i in tqdm_notebook( range( wind.shape[0] ),desc='StdDev' ):\n",
    "        Output = np.append(Output, wind[i,:].var()**0.5)\n",
    "    return Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Vector_Max(windowName, dataRaw, wWidth, sWidth, fName,PATH):\n",
    "    # get windowFrame\n",
    "    wind=GetWindowFrame(windowName, dataRaw, wWidth, sWidth, fName,PATH)\n",
    "    \n",
    "    Output = np.array([])\n",
    "    for i in tqdm_notebook( range( wind.shape[0] ) ,desc='Max'):\n",
    "        Output = np.append(Output, wind[i,:].max())\n",
    "    return Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Vector_Min(windowName, dataRaw, wWidth, sWidth, fName, PATH):\n",
    "    # get windowFrame\n",
    "    wind=GetWindowFrame(windowName, dataRaw, wWidth, sWidth, fName, PATH)\n",
    "    \n",
    "    Output = np.array([])\n",
    "    for i in tqdm_notebook( range( wind.shape[0] ) ,desc='Min'):\n",
    "        Output = np.append(Output, wind[i,:].min())\n",
    "    return Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Vector_Range(windowName, dataRaw, wWidth, sWidth, fName, PATH):\n",
    "    # get windowFrame\n",
    "    wind=GetWindowFrame(windowName, dataRaw, wWidth, sWidth, fName, PATH)\n",
    "    \n",
    "    Output = np.array([])\n",
    "    for i in tqdm_notebook( range( wind.shape[0] ) ,desc='Range'):\n",
    "        Output = np.append(Output, wind[i,:].max()-wind[i,:].min())\n",
    "    return Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Vector_RMS(windowName, dataRaw, wWidth, sWidth, fName, PATH):\n",
    "    # get windowFrame\n",
    "    wind=GetWindowFrame(windowName, dataRaw, wWidth, sWidth, fName, PATH)\n",
    "    \n",
    "    Output = np.array([])\n",
    "    for i in tqdm_notebook( range( wind.shape[0] ) ,desc='RMS'):\n",
    "        Output = np.append(Output, (np.sum( wind[i,:]**2)/wind[i,:].size)**0.5 )\n",
    "    return Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Vector_Corr(windowNameX, dataRawX, windowNameY, dataRawY, wWidth, sWidth, fName, PATH):\n",
    "    # get windowFrame\n",
    "    windX=GetWindowFrame(windowNameX, dataRawX, wWidth, sWidth, fName, PATH)\n",
    "    windY=GetWindowFrame(windowNameY, dataRawY, wWidth, sWidth, fName, PATH)\n",
    "\n",
    "    Output = np.array([])\n",
    "    tmpArray = np.array([])\n",
    "    \n",
    "    for i in tqdm_notebook( range( windX.shape[0] ) ):\n",
    "        tmpArray = np.append(tmpArray, np.corrcoef(windX[i,:],windY[i,:]) )\n",
    "        Output = np.append(Output, tmpArray, axis=0)\n",
    "    return Output  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Vector_SMA(windowName, dataRawX, dataRawY, dataRawZ, wWidth, sWidth, fName, PATH):\n",
    "    # get windowFrame\n",
    "    windX=GetWindowFrame(windowName, dataRawX, wWidth, sWidth, fName, PATH)\n",
    "    windY=GetWindowFrame(windowName, dataRawY, wWidth, sWidth, fName, PATH)\n",
    "    windZ=GetWindowFrame(windowName, dataRawZ, wWidth, sWidth, fName, PATH)\n",
    "    \n",
    "    # windowFrame roop\n",
    "    for i in tqdm_notebook( range( windX.shape[0] ) ,desc='SMA'):\n",
    "        SqrMag = windX[i,:]**2+windY[i,:]**2+windZ[i,:]**2\n",
    "        Mag = np.sum( SqrMag**0.5 )\n",
    "\n",
    "        Output = np.append(Output, Mag)\n",
    "    return Output  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Extraction(Sensor,axis,wNum,sNum,FileName):\n",
    "        np.savez(FeaturePath+FileName+'_Mean',data=\\\n",
    "             Vector_Mean(axis, Sensor[axis], wNum,sNum, FileName, WindowDataPath) )\n",
    "        \n",
    "        np.savez(FeaturePath+FileName+'_Median',data=\\\n",
    "            Vector_Median(axis, Sensor[axis], wNum,sNum, FileName, WindowDataPath) )\n",
    "        \n",
    "        np.savez(FeaturePath+FileName+'_Median',data=\\\n",
    "             Vector_Var(axis, Sensor[axis], wNum,sNum, FileName, WindowDataPath) )\n",
    "        \n",
    "        np.savez(FeaturePath+FileName+'_Median',data=\\\n",
    "             Vector_StdDev(axis, Sensor[axis], wNum,sNum, FileName, WindowDataPath)\n",
    "        )\n",
    "        np.savez(FeaturePath+FileName+'_Median',data=\\\n",
    "             Vector_Max(axis, Sensor[axis], wNum,sNum, FileName, WindowDataPath) )\n",
    "        \n",
    "        np.savez(FeaturePath+FileName+'_Median',data=\\\n",
    "            Vector_Min(axis, Sensor[axis], wNum,sNum, FileName, WindowDataPath) )\n",
    "        \n",
    "        np.savez(FeaturePath+FileName+'_Median',data=\\\n",
    "            Vector_Range(axis, Sensor[axis], wNum,sNum, FileName, WindowDataPath) )\n",
    "        \n",
    "        np.savez(FeaturePath+FileName+'_Median',data=\\\n",
    "             Vector_RMS(axis, Sensor[axis], windowNum, slidingNum, FileName, WindowDataPath) )\n",
    "        \n",
    "        np.savez(FeaturePath+FileName+'_Energy',data=\\\n",
    "             FastVector_Energy(axis, Sensor[axis], wNum,sNum, FileName, WindowDataPath) )\n",
    "\n",
    "        np.savez(FeaturePath+FileName+'_Entropy',data=\\\n",
    "             FastVector_Entropy(axis, Sensor[axis], wNum,sNum, FileName, WindowDataPath) )\n",
    "\n",
    "        np.savez(FeaturePath+FileName+'_Frequency',data=\\\n",
    "             FastVector_Frequency(axis, Sensor[axis], wNum,sNum, FileName, WindowDataPath) )\n",
    "        \n",
    "        np.savez(FeaturePath+SaveFileName+'_Median',data=\\\n",
    "        Vector_Corr(axis, Sensor[axis],axis, Sensor[axis], wNum,sNum, FileName, WindowDataPath) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 表示用\n",
    "from tqdm import tqdm\n",
    "from tqdm import tnrange, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AccX is registed now\n",
      "Build Complete\n",
      "Source shape is(826837, 1)\n",
      "window frames num =103323\n",
      "offset=5\n",
      "(103323, 256, 1)\n",
      "AccX is registed now\n",
      "Build Complete\n",
      "Source shape is(826837, 1)"
     ]
    }
   ],
   "source": [
    "windowNum = 256\n",
    "slidingNum = windowNum/32\n",
    "\n",
    "for s in tqdm_notebook( [Sensor1,Sensor2,Sensor3,Sensor4,Sensor5,Sensor6] ):\n",
    "    for axis in tqdm_notebook( ['AccX','AccY','AccZ'] ):\n",
    "        SaveFileName=s['Name']+'_'+axis+'_Win='+str(windowNum).zfill(4)+'_Sld='+str(slidingNum).zfill(4)\n",
    "        Extraction(s,axis,windowNum, slidingNum, SaveFileName)\n",
    "        time.sleep(10)\n",
    "        \n",
    "    np.savez(FeaturePath+SaveFileName+'_Median',data=\\\n",
    "        Vector_SMA(axis, s['AccZ'], s['AccY'], s['AccZ'], windowNum, slidingNum, WindowDataPath) )\n",
    "    \n",
    "    np.savez(FeaturePath+SaveFileName+'_Median',data=\\\n",
    "        Vector_Corr('AccX', s['AccX'],'AccY', s['AccY'], windowNum, slidingNum, WindowDataPath) )\n",
    "   \n",
    "    np.savez(FeaturePath+SaveFileName+'_Median',data=\\\n",
    "        Vector_Corr('AccX', s['AccX'],'AccZ', s['AccZ'], windowNum, slidingNum, WindowDataPath) )\n",
    "    \n",
    "    np.savez(FeaturePath+SaveFileName+'_Median',data=\\\n",
    "        Vector_Corr('AccY', s['AccY'],'AccZ', s['AccZ'], windowNum, slidingNum, WindowDataPath) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "widgets": {
   "state": {
    "189f9e16534e41c5b3e6c9fd5304cae3": {
     "views": [
      {
       "cell_index": 27
      }
     ]
    },
    "1ad82b4bcb3a4891b1129172fe405a75": {
     "views": [
      {
       "cell_index": 27
      }
     ]
    },
    "27b762e9bd804753be6c8610f6deae26": {
     "views": [
      {
       "cell_index": 27
      }
     ]
    },
    "4941f86f6c724567bc8d7a7732f2d45c": {
     "views": [
      {
       "cell_index": 27
      }
     ]
    },
    "7099ad8d953f4d75842f2bc3ae2483a9": {
     "views": [
      {
       "cell_index": 27
      }
     ]
    },
    "762db64bf54f44228c038a4e1384c2bb": {
     "views": [
      {
       "cell_index": 27
      }
     ]
    },
    "896ebf96f83646febbdbb146b638ce10": {
     "views": [
      {
       "cell_index": 27
      }
     ]
    },
    "a9616cf5d9ba45709e3d466fa1b43411": {
     "views": [
      {
       "cell_index": 27
      }
     ]
    },
    "b5f7344ad0e843368409da8635d98d54": {
     "views": [
      {
       "cell_index": 27
      }
     ]
    },
    "dc84300bb719454f92b923d7e96eacee": {
     "views": [
      {
       "cell_index": 27
      }
     ]
    },
    "e0ac6b0b72da438aafe4ceb7712e5d6d": {
     "views": [
      {
       "cell_index": 27
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
