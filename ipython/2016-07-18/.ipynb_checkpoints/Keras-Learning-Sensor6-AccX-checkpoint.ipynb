{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import fftpack\n",
    "from scipy import signal\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import pickle\n",
    "import copy\n",
    "import processing\n",
    "import matplotlib.animation as animation\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 970 (CNMeM is disabled, cuDNN 4007)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.datasets import cifar10\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.utils.visualize_util import model_to_dot, plot\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import matplotlib.image as mpimg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "共通変数をここに定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DataName='sensor2_AccX'\n",
    "SensorName='sensor2'\n",
    "width=3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "WORKSPACE_PATH = '/home/takeyama/pywork/ipython/2016-07-04'\n",
    "\n",
    "    \n",
    "if not os.path.exists(WORKSPACE_PATH+'/'+DataName+'/study/'): os.makedirs(WORKSPACE_PATH+'/'+DataName+'/study/')\n",
    "StudyDataPath=WORKSPACE_PATH+'/'+DataName+'/study/'\n",
    "\n",
    "if not os.path.exists(WORKSPACE_PATH+'/'+DataName+'/glaph/'): os.makedirs(WORKSPACE_PATH+'/'+DataName+'/glaph/')\n",
    "GlaphDataPath=WORKSPACE_PATH+'/'+DataName+'/glaph/'\n",
    "\n",
    "if not os.path.exists(WORKSPACE_PATH+'/'+DataName+'/modelPic/'): os.makedirs(WORKSPACE_PATH+'/'+DataName+'/modelPic/')\n",
    "StudyDataModelPicPath=WORKSPACE_PATH+'/'+DataName+'/modelPic/'\n",
    "\n",
    "WindowDataPath=WORKSPACE_PATH+'/window/'\n",
    "RawDataPath=WORKSPACE_PATH+'/raw/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    encordData,decordData\n",
    "    firstNum:\n",
    "    goalNum:\n",
    "    commonLabel:共通名前\n",
    "\"\"\"\n",
    "def MakeGlaph(encordData,decordData,firstNum,goalNum,commonLabel):\n",
    "    eRow, eCol=encordData.shape\n",
    "    dRow, dCol=decordData.shape\n",
    "    if (eRow!=dRow) | (eCol!=dCol):\n",
    "        print 'check encordData & decordData'\n",
    "        return -1\n",
    "        \n",
    "    start = firstNum\n",
    "    goal=goalNum\n",
    "    print str(start)+' is start '+str(goal)+' is goal'\n",
    "    dataE = encordData.reshape(eRow*eCol,1)[start:goal]\n",
    "    dataD = decordData.reshape(dRow*dCol,1)[start:goal]\n",
    "    plt.figure(figsize=(160,90))\n",
    "    plt.plot(range(0,len(dataE)),dataE,'--r',label=\"Encoded\")\n",
    "    plt.plot(range(0,len(dataD)),dataD,'b',label=\"Decoded\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.title(str(start)+\"-\"+str(goal))\n",
    "    plt.savefig(commonLabel+'-'+str(start)+\"-\"+str(goal)+'-'+'glaph')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Phase1 計測データの取得**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dic1=processing.LoadDicDataFromFileNPZ(RawDataPath+\"MemSensor1\")\n",
    "dic2=processing.LoadDicDataFromFileNPZ(RawDataPath+\"MemSensor2\")\n",
    "dic3=processing.LoadDicDataFromFileNPZ(RawDataPath+\"MemSensor3\")\n",
    "dic4=processing.LoadDicDataFromFileNPZ(RawDataPath+\"MemSensor4\")\n",
    "dic5=processing.LoadDicDataFromFileNPZ(RawDataPath+\"MemSensor5\")\n",
    "dic6=processing.LoadDicDataFromFileNPZ(RawDataPath+\"MemSensor6\")\n",
    "dic7=processing.LoadDicDataFromFileNPZ(RawDataPath+\"MemSensor7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Phase2 window flame 作成**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "windoW = processing.LoadDicDataFromFileNPZ(\"window/\"+str(SensorName)+\"_AccX_test.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15921, 16)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "windoW.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**前回やった学習をもう１度やってみる**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15921 samples, validate on 15921 samples\n",
      "Epoch 1/50\n",
      "15921/15921 [==============================] - 72s - loss: 0.0305 - val_loss: 0.0024\n",
      "Epoch 2/50\n",
      "15921/15921 [==============================] - 99s - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 3/50\n",
      "15921/15921 [==============================] - 124s - loss: 0.0012 - val_loss: 9.7683e-04\n",
      "Epoch 4/50\n",
      "15921/15921 [==============================] - 129s - loss: 8.1074e-04 - val_loss: 6.4915e-04\n",
      "Epoch 5/50\n",
      "15921/15921 [==============================] - 128s - loss: 5.8957e-04 - val_loss: 5.4244e-04\n",
      "Epoch 6/50\n",
      "15921/15921 [==============================] - 128s - loss: 4.6868e-04 - val_loss: 4.0986e-04\n",
      "Epoch 7/50\n",
      "15921/15921 [==============================] - 129s - loss: 4.0431e-04 - val_loss: 3.5684e-04\n",
      "Epoch 8/50\n",
      "15921/15921 [==============================] - 128s - loss: 3.5874e-04 - val_loss: 3.1992e-04\n",
      "Epoch 9/50\n",
      "15921/15921 [==============================] - 129s - loss: 3.2508e-04 - val_loss: 2.7258e-04\n",
      "Epoch 10/50\n",
      "15921/15921 [==============================] - 127s - loss: 3.0019e-04 - val_loss: 4.1996e-04\n",
      "Epoch 11/50\n",
      "15921/15921 [==============================] - 129s - loss: 2.7735e-04 - val_loss: 2.3911e-04\n",
      "Epoch 12/50\n",
      "15921/15921 [==============================] - 129s - loss: 2.5653e-04 - val_loss: 2.0994e-04\n",
      "Epoch 13/50\n",
      "15921/15921 [==============================] - 128s - loss: 2.3834e-04 - val_loss: 2.5159e-04\n",
      "Epoch 14/50\n",
      "15921/15921 [==============================] - 129s - loss: 2.2266e-04 - val_loss: 3.3550e-04\n",
      "Epoch 15/50\n",
      "15921/15921 [==============================] - 128s - loss: 2.1212e-04 - val_loss: 2.1004e-04\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEPCAYAAACHuClZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/w8DVt7CglyLMwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8bac1238d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define SaveFileName\n",
    "encoding_dim = 8  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "SaveFileNameEncord=DataName+'_encoded'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameDecord=DataName+'_decoded'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameNet=DataName+'_net'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameTrain=DataName+'_train'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameTest=DataName+'_test'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameGlaph=GlaphDataPath+DataName+'_edim='+str(encoding_dim)+'_loss_val_loss.png'\n",
    "\n",
    "window_test=windoW\n",
    "window_train=windoW\n",
    "\n",
    "shapeNum=windoW.shape[1]\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(shapeNum,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='tanh')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(shapeNum, activation='linear')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input=input_img, output=decoded)\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input=input_img, output=encoded)\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(input=encoded_input, output=decoder_layer(encoded_input))\n",
    "\n",
    "autoencoder.compile(optimizer='adadelta', loss='mse')\n",
    "plot(autoencoder,  to_file=StudyDataModelPicPath+SaveFileNameNet+'.png')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "hist = autoencoder.fit(window_train, window_train,\n",
    "                nb_epoch=50,\n",
    "                batch_size=shapeNum/4,\n",
    "                shuffle=True,\n",
    "                validation_data=(window_test, window_test),\n",
    "                callbacks=[early_stopping])\n",
    "\n",
    "encoded_imgs = encoder.predict(window_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameEncord,encoded_imgs)\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameDecord,decoded_imgs)\n",
    "\n",
    "# save model and wights\n",
    "json_string = encoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameEncord+'.json', 'w').write(json_string)\n",
    "encoder.save_weights(StudyDataPath+SaveFileNameEncord+'_weights.h5')\n",
    "\n",
    "json_string = decoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameDecord+'.json', 'w').write(json_string)\n",
    "decoder.save_weights(StudyDataPath+SaveFileNameDecord+'_weights.h5')\n",
    "\n",
    "json_string = autoencoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameNet+'.json', 'w').write(json_string)\n",
    "autoencoder.save_weights(StudyDataPath+SaveFileNameNet+'_weights.h5')\n",
    "\n",
    "# plot loss\n",
    "loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "nb_epoch = len(loss)\n",
    "plt.plot(range(nb_epoch), loss, marker='.', label='loss')\n",
    "plt.plot(range(nb_epoch), val_loss, marker='.', label='val_loss')\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.savefig(SaveFileNameGlaph)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number=0\n",
      "0 is start 3000 is goal\n",
      "number=3000\n",
      "3000 is start 6000 is goal\n",
      "number=6000\n",
      "6000 is start 9000 is goal\n",
      "number=9000\n",
      "9000 is start 12000 is goal\n",
      "number=12000\n",
      "12000 is start 15000 is goal\n",
      "number=15000\n",
      "15000 is start 18000 is goal\n",
      "number=18000\n",
      "18000 is start 21000 is goal\n",
      "number=21000\n",
      "21000 is start 24000 is goal\n",
      "number=24000\n",
      "24000 is start 27000 is goal\n",
      "number=27000\n",
      "27000 is start 30000 is goal\n",
      "number=30000\n",
      "30000 is start 33000 is goal\n"
     ]
    }
   ],
   "source": [
    "rawData = windoW.reshape(windoW.size,1)\n",
    "reconstructed = decoded_imgs.reshape(decoded_imgs.size,1)\n",
    "for n in range(0,rawData.size,width):\n",
    "    print 'number='+str(n)\n",
    "    MakeGlaph(rawData, reconstructed, n, n+width,\n",
    "              GlaphDataPath+DataName+'_edim='+str(encoding_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次元数を減らしてみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define SaveFileName\n",
    "encoding_dim = 4  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "SaveFileNameEncord=DataName+'_encoded'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameDecord=DataName+'_decoded'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameNet=DataName+'_net'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameTrain=DataName+'_train'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameTest=DataName+'_test'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameGlaph=GlaphDataPath+DataName+'_edim='+str(encoding_dim)+'_loss_val_loss.png'\n",
    "\n",
    "window_test=windoW\n",
    "window_train=windoW\n",
    "\n",
    "shapeNum=windoW.shape[1]\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(shapeNum,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='tanh')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(shapeNum, activation='linear')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input=input_img, output=decoded)\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input=input_img, output=encoded)\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(input=encoded_input, output=decoder_layer(encoded_input))\n",
    "autoencoder.compile(optimizer='adadelta', loss='mse')\n",
    "plot(autoencoder,  to_file=StudyDataModelPicPath+SaveFileNameNet+'.png')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "hist = autoencoder.fit(window_train, window_train,\n",
    "                nb_epoch=50,\n",
    "                batch_size=shapeNum/4,\n",
    "                shuffle=True,\n",
    "                validation_data=(window_test, window_test),\n",
    "                callbacks=[early_stopping])\n",
    "\n",
    "encoded_imgs = encoder.predict(window_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameEncord,encoded_imgs)\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameDecord,decoded_imgs)\n",
    "\n",
    "# save model and wights\n",
    "json_string = encoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameEncord+'.json', 'w').write(json_string)\n",
    "encoder.save_weights(StudyDataPath+SaveFileNameEncord+'_weights.h5')\n",
    "\n",
    "json_string = decoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameDecord+'.json', 'w').write(json_string)\n",
    "decoder.save_weights(StudyDataPath+SaveFileNameDecord+'_weights.h5')\n",
    "\n",
    "json_string = autoencoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameNet+'.json', 'w').write(json_string)\n",
    "autoencoder.save_weights(StudyDataPath+SaveFileNameNet+'_weights.h5')\n",
    "\n",
    "# plot loss\n",
    "loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "nb_epoch = len(loss)\n",
    "plt.plot(range(nb_epoch), loss, marker='.', label='loss')\n",
    "plt.plot(range(nb_epoch), val_loss, marker='.', label='val_loss')\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.savefig(SaveFileNameGlaph)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rawData = windoW.reshape(windoW.size,1)\n",
    "reconstructed = decoded_imgs.reshape(decoded_imgs.size,1)\n",
    "for n in range(0,rawData.size,width):\n",
    "    print 'number='+str(n)\n",
    "    MakeGlaph(rawData, reconstructed, n, n+width,\n",
    "              GlaphDataPath+DataName+'_edim='+str(encoding_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次元数を増やしてみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define SaveFileName\n",
    "encoding_dim = 12  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "SaveFileNameEncord=DataName+'_encoded'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameDecord=DataName+'_decoded'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameNet=DataName+'_net'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameTrain=DataName+'_train'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameTest=DataName+'_test'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameGlaph=GlaphDataPath+DataName+'_edim='+str(encoding_dim)+'_loss_val_loss.png'\n",
    "\n",
    "window_test=windoW\n",
    "window_train=windoW\n",
    "\n",
    "shapeNum=windoW.shape[1]\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(shapeNum,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='tanh')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(shapeNum, activation='linear')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input=input_img, output=decoded)\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input=input_img, output=encoded)\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(input=encoded_input, output=decoder_layer(encoded_input))\n",
    "\n",
    "autoencoder.compile(optimizer='adadelta', loss='mse')\n",
    "plot(autoencoder,  to_file=StudyDataModelPicPath+SaveFileNameNet+'.png')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "hist = autoencoder.fit(window_train, window_train,\n",
    "                nb_epoch=50,\n",
    "                batch_size=shapeNum/4,\n",
    "                shuffle=True,\n",
    "                validation_data=(window_test, window_test),\n",
    "                callbacks=[early_stopping])\n",
    "\n",
    "encoded_imgs = encoder.predict(window_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameEncord,encoded_imgs)\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameDecord,decoded_imgs)\n",
    "\n",
    "# save model and wights\n",
    "json_string = encoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameEncord+'.json', 'w').write(json_string)\n",
    "encoder.save_weights(StudyDataPath+SaveFileNameEncord+'_weights.h5')\n",
    "\n",
    "json_string = decoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameDecord+'.json', 'w').write(json_string)\n",
    "decoder.save_weights(StudyDataPath+SaveFileNameDecord+'_weights.h5')\n",
    "\n",
    "json_string = autoencoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameNet+'.json', 'w').write(json_string)\n",
    "autoencoder.save_weights(StudyDataPath+SaveFileNameNet+'_weights.h5')\n",
    "\n",
    "# plot loss\n",
    "loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "nb_epoch = len(loss)\n",
    "plt.plot(range(nb_epoch), loss, marker='.', label='loss')\n",
    "plt.plot(range(nb_epoch), val_loss, marker='.', label='val_loss')\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.savefig(SaveFileNameGlaph)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rawData = windoW.reshape(windoW.size,1)\n",
    "reconstructed = decoded_imgs.reshape(decoded_imgs.size,1)\n",
    "for n in range(0,rawData.size,width):\n",
    "    print 'number='+str(n)\n",
    "    MakeGlaph(rawData, reconstructed, n, n+width,\n",
    "              GlaphDataPath+DataName+'_edim='+str(encoding_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次元数を入力創と同じ大きさにしてみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define SaveFileName\n",
    "encoding_dim = 16  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "SaveFileNameEncord=DataName+'_encoded'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameDecord=DataName+'_decoded'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameNet=DataName+'_net'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameTrain=DataName+'_train'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameTest=DataName+'_test'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameGlaph=GlaphDataPath+DataName+'_edim='+str(encoding_dim)+'_loss_val_loss.png'\n",
    "\n",
    "window_test=windoW\n",
    "window_train=windoW\n",
    "\n",
    "shapeNum=windoW.shape[1]\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(shapeNum,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='tanh')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(shapeNum, activation='linear')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input=input_img, output=decoded)\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input=input_img, output=encoded)\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(input=encoded_input, output=decoder_layer(encoded_input))\n",
    "\n",
    "autoencoder.compile(optimizer='adadelta', loss='mse')\n",
    "plot(autoencoder,  to_file=StudyDataModelPicPath+SaveFileNameNet+'.png')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "hist = autoencoder.fit(window_train, window_train,\n",
    "                nb_epoch=50,\n",
    "                batch_size=shapeNum/4,\n",
    "                shuffle=True,\n",
    "                validation_data=(window_test, window_test),\n",
    "                callbacks=[early_stopping])\n",
    "\n",
    "encoded_imgs = encoder.predict(window_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameEncord,encoded_imgs)\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameDecord,decoded_imgs)\n",
    "\n",
    "# save model and wights\n",
    "json_string = encoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameEncord+'.json', 'w').write(json_string)\n",
    "encoder.save_weights(StudyDataPath+SaveFileNameEncord+'_weights.h5')\n",
    "\n",
    "json_string = decoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameDecord+'.json', 'w').write(json_string)\n",
    "decoder.save_weights(StudyDataPath+SaveFileNameDecord+'_weights.h5')\n",
    "\n",
    "json_string = autoencoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameNet+'.json', 'w').write(json_string)\n",
    "autoencoder.save_weights(StudyDataPath+SaveFileNameNet+'_weights.h5')\n",
    "\n",
    "# plot loss\n",
    "loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "nb_epoch = len(loss)\n",
    "plt.plot(range(nb_epoch), loss, marker='.', label='loss')\n",
    "plt.plot(range(nb_epoch), val_loss, marker='.', label='val_loss')\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.savefig(SaveFileNameGlaph)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rawData = windoW.reshape(windoW.size,1)\n",
    "reconstructed = decoded_imgs.reshape(decoded_imgs.size,1)\n",
    "for n in range(0,rawData.size,width):\n",
    "    print 'number='+str(n)\n",
    "    MakeGlaph(rawData, reconstructed, n, n+width,\n",
    "              GlaphDataPath+DataName+'_edim='+str(encoding_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "入力層の大きさの２倍のノード数を隠れそうにする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define SaveFileName\n",
    "encoding_dim = 32  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "SaveFileNameEncord=DataName+'_encoded'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameDecord=DataName+'_decoded'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameNet=DataName+'_net'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameTrain=DataName+'_train'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameTest=DataName+'_test'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameGlaph=GlaphDataPath+DataName+'_edim='+str(encoding_dim)+'_loss_val_loss.png'\n",
    "\n",
    "window_test=windoW\n",
    "window_train=windoW\n",
    "\n",
    "shapeNum=windoW.shape[1]\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(shapeNum,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='tanh')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(shapeNum, activation='linear')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input=input_img, output=decoded)\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input=input_img, output=encoded)\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(input=encoded_input, output=decoder_layer(encoded_input))\n",
    "\n",
    "autoencoder.compile(optimizer='adadelta', loss='mse')\n",
    "plot(autoencoder,  to_file=StudyDataModelPicPath+SaveFileNameNet+'.png')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "hist = autoencoder.fit(window_train, window_train,\n",
    "                nb_epoch=50,\n",
    "                batch_size=shapeNum/4,\n",
    "                shuffle=True,\n",
    "                validation_data=(window_test, window_test),\n",
    "                callbacks=[early_stopping])\n",
    "\n",
    "encoded_imgs = encoder.predict(window_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameEncord,encoded_imgs)\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameDecord,decoded_imgs)\n",
    "\n",
    "# save model and wights\n",
    "json_string = encoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameEncord+'.json', 'w').write(json_string)\n",
    "encoder.save_weights(StudyDataPath+SaveFileNameEncord+'_weights.h5')\n",
    "\n",
    "json_string = decoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameDecord+'.json', 'w').write(json_string)\n",
    "decoder.save_weights(StudyDataPath+SaveFileNameDecord+'_weights.h5')\n",
    "\n",
    "json_string = autoencoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameNet+'.json', 'w').write(json_string)\n",
    "autoencoder.save_weights(StudyDataPath+SaveFileNameNet+'_weights.h5')\n",
    "\n",
    "# plot loss\n",
    "loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "nb_epoch = len(loss)\n",
    "plt.plot(range(nb_epoch), loss, marker='.', label='loss')\n",
    "plt.plot(range(nb_epoch), val_loss, marker='.', label='val_loss')\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.savefig(SaveFileNameGlaph)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rawData = windoW.reshape(windoW.size,1)\n",
    "reconstructed = decoded_imgs.reshape(decoded_imgs.size,1)\n",
    "for n in range(0,rawData.size,width):\n",
    "    print 'number='+str(n)\n",
    "    MakeGlaph(rawData, reconstructed, n, n+width,\n",
    "              GlaphDataPath+DataName+'_edim='+str(encoding_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "入力層の大きさの4倍のノード数を隠れそうにする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define SaveFileName\n",
    "encoding_dim = 64  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "SaveFileNameEncord=DataName+'_encoded'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameDecord=DataName+'_decoded'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameNet=DataName+'_net'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameTrain=DataName+'_train'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameTest=DataName+'_test'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameGlaph=GlaphDataPath+DataName+'_edim='+str(encoding_dim)+'_loss_val_loss.png'\n",
    "\n",
    "window_test=windoW\n",
    "window_train=windoW\n",
    "\n",
    "shapeNum=windoW.shape[1]\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(shapeNum,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='tanh')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(shapeNum, activation='linear')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input=input_img, output=decoded)\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input=input_img, output=encoded)\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(input=encoded_input, output=decoder_layer(encoded_input))\n",
    "\n",
    "autoencoder.compile(optimizer='adadelta', loss='mse')\n",
    "plot(autoencoder,  to_file=StudyDataModelPicPath+SaveFileNameNet+'.png')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "hist = autoencoder.fit(window_train, window_train,\n",
    "                nb_epoch=50,\n",
    "                batch_size=shapeNum/4,\n",
    "                shuffle=True,\n",
    "                validation_data=(window_test, window_test),\n",
    "                callbacks=[early_stopping])\n",
    "\n",
    "encoded_imgs = encoder.predict(window_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameEncord,encoded_imgs)\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameDecord,decoded_imgs)\n",
    "\n",
    "# save model and wights\n",
    "json_string = encoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameEncord+'.json', 'w').write(json_string)\n",
    "encoder.save_weights(StudyDataPath+SaveFileNameEncord+'_weights.h5')\n",
    "\n",
    "json_string = decoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameDecord+'.json', 'w').write(json_string)\n",
    "decoder.save_weights(StudyDataPath+SaveFileNameDecord+'_weights.h5')\n",
    "\n",
    "json_string = autoencoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameNet+'.json', 'w').write(json_string)\n",
    "autoencoder.save_weights(StudyDataPath+SaveFileNameNet+'_weights.h5')\n",
    "\n",
    "# plot loss\n",
    "loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "nb_epoch = len(loss)\n",
    "plt.plot(range(nb_epoch), loss, marker='.', label='loss')\n",
    "plt.plot(range(nb_epoch), val_loss, marker='.', label='val_loss')\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.savefig(SaveFileNameGlaph)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
