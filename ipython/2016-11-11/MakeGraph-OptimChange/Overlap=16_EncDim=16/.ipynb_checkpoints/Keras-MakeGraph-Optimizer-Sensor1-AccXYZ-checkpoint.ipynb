{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SensorNum=1 # Sensor number\n",
    "WindowWidth=[128,256,512,1024,2048,4096] # Window Width\n",
    "OverlapArray=[16,16,16,16,16,16] # sliding window\n",
    "#width=1000 # graph width \n",
    "#EncodingDim=[4,8,12,16,32,64] # number of hidden layer note\n",
    "encoding_dim=16\n",
    "Axis='AccX,AccY,AccZ' # Axis\n",
    "PathAxis='AccXYZ'\n",
    "\n",
    "WORKSPACE_PATH = \"/media/takeyama/HD-PZU3/01_TAKEYAMA_WORKSPACE/02_CommonData\"\n",
    "DATE_PATH=\"/2016-08-15/\"\n",
    "TITLE_PATH=\"Optim/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import fftpack\n",
    "from scipy import signal\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import pickle\n",
    "import copy\n",
    "\n",
    "import processing\n",
    "import window\n",
    "\n",
    "import matplotlib.animation as animation\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 1080 (CNMeM is disabled, cuDNN 5005)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.datasets import cifar10\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.optimizers import SGD, Adadelta, Adagrad, Adam, Adamax, RMSprop, Nadam\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.utils.visualize_util import model_to_dot, plot\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import matplotlib.image as mpimg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DataName='sensor'+str(SensorNum)+'_'+Axis\n",
    "SensorName='sensor'+str(SensorNum)\n",
    "DicName='MemSensor'+str(SensorNum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define rawdata directory\n",
    "if not os.path.exists(WORKSPACE_PATH+\"/raw/\"):\n",
    "    os.makedirs(WORKSPACE_PATH+\"/raw/\")\n",
    "RawDataPath=WORKSPACE_PATH+\"/raw/\"\n",
    "\n",
    "# define restoring windowdata directory\n",
    "if not os.path.exists(WORKSPACE_PATH+'/window/'+TITLE_PATH+DataName+'/'): \n",
    "    os.makedirs(WORKSPACE_PATH+'/window/'+TITLE_PATH+DataName+'/')\n",
    "WindowDataPath=WORKSPACE_PATH+'/window/'+TITLE_PATH+DataName+'/'\n",
    "\n",
    "# define restoring netowrk model picture's directory\n",
    "if not os.path.exists(WORKSPACE_PATH+DATE_PATH+'/modelPic/'+TITLE_PATH+DataName+'/'): \n",
    "    os.makedirs(WORKSPACE_PATH+DATE_PATH+'/modelPic/'+TITLE_PATH+DataName+'/')\n",
    "StudyDataModelPicPath=WORKSPACE_PATH+DATE_PATH+'/modelPic/'+TITLE_PATH+DataName+'/'\n",
    "\n",
    "# define restoring graph data's directory\n",
    "if not os.path.exists(WORKSPACE_PATH+DATE_PATH+'/graph/'+TITLE_PATH+DataName+'/'): \n",
    "    os.makedirs(WORKSPACE_PATH+DATE_PATH+'/graph/'+TITLE_PATH+DataName+'/')\n",
    "GlaphDataPath=WORKSPACE_PATH+DATE_PATH+'/graph/'+TITLE_PATH+DataName+'/'\n",
    "\n",
    "# define restoring model paarmeter directory\n",
    "if not os.path.exists(WORKSPACE_PATH+DATE_PATH+'/study/'+TITLE_PATH+DataName+'/'): \n",
    "    os.makedirs(WORKSPACE_PATH+DATE_PATH+'/study/'+TITLE_PATH+DataName+'/')\n",
    "StudyDataPath=WORKSPACE_PATH+DATE_PATH+'/study/'+TITLE_PATH+DataName+'/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Phase1 計測データの取得**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dic=processing.LoadDicDataFromFileNPZ(RawDataPath+DicName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Phase2 window flame 作成**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimizers = [SGD, Adadelta, Adamax, Adam, Adagrad,  RMSprop, Nadam]\n",
    "optimArray = [\"SGD\", \"Adadelta\",\"Adamax\", \"Adam\", \"Adagrad\",  \"RMSprop\", \"Nadam\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AccX is registed now\n",
      "AccY is registed now\n",
      "AccZ is registed now\n",
      "Build Complete\n",
      "(254742, 3)\n",
      "windowData's num =15914\n",
      "SourceData's aborting data = 6\n"
     ]
    }
   ],
   "source": [
    "# loop windowWidth\n",
    "for SampleNum,Overlap in zip(WindowWidth,OverlapArray):\n",
    "    ArrayAxis = Axis.split(\",\")\n",
    "    w=window.Window()\n",
    "    for a in ArrayAxis:\n",
    "        w.SetData(a,dic[a])\n",
    "    wind=w.Compile(windowWidth=SampleNum,overlapNum=Overlap)\n",
    "    print wind.shape\n",
    "    windoW=wind.reshape((len(wind),np.prod(wind.shape[1:])))\n",
    "\n",
    "    # define SaveFileName\n",
    "    for opt,optName in zip(optimizers,optimArray):\n",
    "        for AxisName,WindowNum in zip(ArrayAxis,range(3)):\n",
    "            print \"hiden node = \"+str(encoding_dim)\n",
    "            CommonName='-edim='+str(encoding_dim)+'-Window='+str(SampleNum)+'-Overlap='+str(Overlap)+'-'+optName+'-'+AxisName\n",
    "            SaveFileNameEncord=DataName+'_encoded'+CommonName\n",
    "            SaveFileNameDecord=DataName+'_decoded'+CommonName\n",
    "            SaveFileNameNet=DataName+'_net'+CommonName\n",
    "            SaveFileNameTrain=DataName+'_train'+CommonName\n",
    "            SaveFileNameTest=DataName+'_test'+CommonName\n",
    "            SaveFileNameGlaph=GlaphDataPath+DataName+CommonName+'_loss_val_loss.png'\n",
    "\n",
    "            window_test=wind[:,:,WindowNum]\n",
    "            window_train=wind[:,:,WindowNum]\n",
    "            processing.SaveDicDataFromFileNPZ(WindowDataPath,SaveFileNameTrain,window_test)\n",
    "            processing.SaveDicDataFromFileNPZ(WindowDataPath,SaveFileNameTest,window_test)\n",
    "            shapeNum=wind.shape[1]\n",
    "\n",
    "\n",
    "            # this is our input placeholder\n",
    "            input_img = Input(shape=(shapeNum,))\n",
    "            # \"encoded\" is the encoded representation of the input\n",
    "            encoded = Dense(encoding_dim, activation='tanh',)(input_img)\n",
    "            # \"decoded\" is the lossy reconstruction of the input\n",
    "            decoded = Dense(shapeNum, activation='linear')(encoded)\n",
    "\n",
    "            # this model maps an input to its reconstruction\n",
    "            autoencoder = Model(input=input_img, output=decoded)\n",
    "\n",
    "            # this model maps an input to its encoded representation\n",
    "            encoder = Model(input=input_img, output=encoded)\n",
    "\n",
    "            # create a placeholder for an encoded (32-dimensional) input\n",
    "            encoded_input = Input(shape=(encoding_dim,))\n",
    "            # retrieve the last layer of the autoencoder model\n",
    "            decoder_layer = autoencoder.layers[-1]\n",
    "            # create the decoder model\n",
    "            decoder = Model(input=encoded_input, output=decoder_layer(encoded_input))\n",
    "\n",
    "            #autoencoder.compile(optimizer='adam', loss='mse')\n",
    "            autoencoder.compile(optimizer=opt(), loss='mse')\n",
    "            plot(autoencoder,  to_file=StudyDataModelPicPath+SaveFileNameNet+'.png')\n",
    "\n",
    "            early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "            hist = autoencoder.fit(window_train, window_train,\n",
    "                        nb_epoch=50,\n",
    "                        verbose=2,\n",
    "                        batch_size=32,\n",
    "                        shuffle=True,\n",
    "                        validation_data=(window_test, window_test),\n",
    "                        callbacks=[early_stopping])\n",
    "            time.sleep(0.1)\n",
    "            encoded_imgs = encoder.predict(window_test)\n",
    "            decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "            processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameEncord,encoded_imgs)\n",
    "            processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameDecord,decoded_imgs)\n",
    "\n",
    "            # save model and wights\n",
    "            json_string = encoder.to_json()\n",
    "            open(StudyDataPath+SaveFileNameEncord+'.json', 'w').write(json_string)\n",
    "            encoder.save_weights(StudyDataPath+SaveFileNameEncord+'_weights.h5',overwrite=True)\n",
    "\n",
    "            json_string = decoder.to_json()\n",
    "            open(StudyDataPath+SaveFileNameDecord+'.json', 'w').write(json_string)\n",
    "            decoder.save_weights(StudyDataPath+SaveFileNameDecord+'_weights.h5',overwrite=True)\n",
    "\n",
    "            json_string = autoencoder.to_json()\n",
    "            open(StudyDataPath+SaveFileNameNet+'.json', 'w').write(json_string)\n",
    "            autoencoder.save_weights(StudyDataPath+SaveFileNameNet+'_weights.h5',overwrite=True)\n",
    "\n",
    "            # plot loss\n",
    "            loss = hist.history['loss']\n",
    "            val_loss = hist.history['val_loss']\n",
    "\n",
    "            nb_epoch = len(loss)\n",
    "            plt.plot(range(nb_epoch), loss, marker='.', label='loss')\n",
    "            plt.plot(range(nb_epoch), val_loss, marker='.', label='val_loss')\n",
    "            plt.legend(loc='best', fontsize=10)\n",
    "            plt.grid()\n",
    "            plt.xlabel('epoch')\n",
    "            plt.ylabel('loss')\n",
    "            plt.savefig(SaveFileNameGlaph)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print window_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
