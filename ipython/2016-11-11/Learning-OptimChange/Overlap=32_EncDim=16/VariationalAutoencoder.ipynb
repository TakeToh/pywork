{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 表示用\n",
    "from tqdm import tqdm\n",
    "from tqdm import tnrange, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "import copy\n",
    "\n",
    "# Parametor about Sensor\n",
    "SensorNum=1 # Sensor number\n",
    "#SensorAxis='AccX' # Axis\n",
    "\n",
    "# Parametor about  \" Sliding Window \" \n",
    "WindowWidth =np.array([128,256,512,1024,2048,4096]) # Window Width\n",
    "SlidingWidth =WindowWidth/4 #sliding window\n",
    "\n",
    "# Parametor about Neural Network\n",
    "AEDimention = 16\n",
    "\n",
    "# Define Data Name\n",
    "DATE= str( datetime.date.today() )+'/'\n",
    "TITLE=\"Participants01_First_1/\"\n",
    "Label = ['LeftHand','RightHand','LeftLeg','Rightleg','West','Chest']\n",
    "\n",
    "# Parametor about \" Data Path\"\n",
    "DataPath = \"/media/takeyama/Transfer/02_ActivityResearch/Paticipants01/01_First/20161018-105301/mem/\"\n",
    "StorePath = \"/home/takeyama/Documents/\"\n",
    "\n",
    "if not os.path.exists(StorePath+TITLE+'dictionary/'): \n",
    "    os.makedirs(StorePath+TITLE+'dictionary/')\n",
    "DictionaryDataPath=StorePath+TITLE+'dictionary/'\n",
    "\n",
    "if not os.path.exists(StorePath+TITLE+DATE+'window/'): \n",
    "    os.makedirs(StorePath+TITLE+DATE+'window/')\n",
    "WindowDataPath=StorePath+TITLE+DATE+'window/'\n",
    "\n",
    "if not os.path.exists(StorePath+TITLE+DATE+'studyOutput/'): \n",
    "    os.makedirs(StorePath+TITLE+DATE+'studyOutput/')\n",
    "StudyOutputPath=StorePath+TITLE+DATE+'studyOutput/'\n",
    "\n",
    "if not os.path.exists(StorePath+TITLE+DATE+'parametor/'): \n",
    "    os.makedirs(StorePath+TITLE+DATE+'parametor/')\n",
    "ParametorPath=StorePath+TITLE+DATE+'parametor/'\n",
    "\n",
    "if not os.path.exists(StorePath+TITLE+DATE+'result/'): \n",
    "    os.makedirs(StorePath+TITLE+DATE+'result/')\n",
    "ResultPath=StorePath+TITLE+DATE+'result/'\n",
    "\n",
    "if not os.path.exists(StorePath+TITLE+DATE+'graph/'): \n",
    "    os.makedirs(StorePath+TITLE+DATE+'graph/')\n",
    "GraphPath=StorePath+TITLE+DATE+'graph/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**センサデータの読み込み**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# センサデータのcsvファイル名をリストに集約する関数\n",
    "def SensorDataFileNameList(path):\n",
    "    l = os.listdir(DataPath)\n",
    "    FilePath =[]\n",
    "    SensorName = []\n",
    "    \n",
    "    for n in range(len(l)):\n",
    "        if (l[n][:4].find('mem-') != -1):\n",
    "            FilePath.append(l[n])\n",
    "            SensorName.append(l[n][4:15])\n",
    "    \n",
    "    return FilePath,SensorName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSVを読み込んで，CSVの中身を辞書型で表現する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ImportCSV(csv_file,SensorName,mode='Round'):\n",
    "    import pandas as pd\n",
    "    '''\n",
    "    ~Argument~\n",
    "    csv_file -> ファイル名 \n",
    "    mode Round -> 四捨五入\n",
    "         Roundup -> 切り上げ\n",
    "         Rounddown -> 切り捨て\n",
    "    \n",
    "    ~Conversion~\n",
    "    Acc Data  [0.1mG]=>[G]\n",
    "    Gyr Data  [0.01dps]=>[dps]   ...dps=degree per second\n",
    "    '''\n",
    "    # data dictionary \n",
    "    RawData={}   \n",
    "    AccConversion = 0.1 * 0.001\n",
    "    GyrConversion = 0.01\n",
    "    \n",
    "    # design dataframe and import csv\n",
    "    data = pd.read_csv(csv_file)\n",
    "    data.columns=[u'Type',u'Time',u'AccX',u'AccY',u'AccZ',u'GyrX',u'GyrY',u'GyrZ']\n",
    "    data = data[ data['Type']=='ags']\n",
    "\n",
    "    # convert numpy.darray \n",
    "\n",
    "    AccX=data.AccX.values*AccConversion\n",
    "    AccY=data.AccY.values*AccConversion\n",
    "    AccZ=data.AccZ.values*AccConversion\n",
    "    \n",
    "    GyrX=data.GyrX.values*GyrConversion\n",
    "    GyrY=data.GyrY.values*GyrConversion\n",
    "    GyrZ=data.GyrZ.values*GyrConversion\n",
    "\n",
    "    # regist each raw data \n",
    "    RawData['AccX'] = AccX\n",
    "    RawData['AccY'] = AccY\n",
    "    RawData['AccZ'] = AccZ\n",
    "    RawData['GyrX'] = GyrX\n",
    "    RawData['GyrY'] = GyrY\n",
    "    RawData['GyrZ'] = GyrZ\n",
    "    RawData['Name'] = SensorName\n",
    "\n",
    "    RawData['Time'] = data.Time.values\n",
    "\n",
    "    return RawData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import processing\n",
    "import window\n",
    "\n",
    "Label = ['LeftHand','RightHand','LeftLeg','Rightleg','West','Chest']\n",
    "\n",
    "DataFileNameList,SensorName=SensorDataFileNameList(DataPath)\n",
    "l=[]\n",
    "for i in range( len(DataFileNameList) ):\n",
    "    l.append( ImportCSV(DataPath+DataFileNameList[i],Label[i]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MakeCommonSection(inputDataArray):\n",
    "    # 共通区間のスタート時間、ゴール時間を求める\n",
    "    # スタート時間を求める\n",
    "    startTime = min(inputDataArray[0]['Time'])\n",
    "    \n",
    "    for i in range(len(inputDataArray)):\n",
    "        if startTime < min(inputDataArray[i]['Time']):\n",
    "            startTime = min(inputDataArray[i]['Time'])\n",
    "    \n",
    "    # ゴール時間を求める\n",
    "    goalTime = max(inputDataArray[0]['Time'])\n",
    "    \n",
    "    for i in range(len(inputDataArray)):\n",
    "        if goalTime > max(inputDataArray[i]['Time']):\n",
    "            goalTime = max(inputDataArray[i]['Time'])\n",
    "\n",
    "    # 共通区間のスタート時間のインデックス、ゴール時間のインデックスを探索する\n",
    "    def CalcSearchIndexFromTime(data, keyTime):\n",
    "        \"\"\"\n",
    "        data　辞書型\n",
    "        keyTime data['Time']の中の探す値\n",
    "        \"\"\"\n",
    "        count = 0\n",
    "        for i in range(0, len(data['Time'])):\n",
    "            if keyTime == data['Time'][i]:\n",
    "                print str(keyTime)+' is much in the index  whose number is '+str(i)\n",
    "                return i\n",
    "            \n",
    "    startIndex = np.array([])\n",
    "    goalIndex = np.array([])\n",
    "    for obj in inputDataArray:\n",
    "        print 'start'\n",
    "        startIndex = np.append(startIndex, CalcSearchIndexFromTime(obj, startTime) ).astype(int)\n",
    "        print 'goal'\n",
    "        goalIndex = np.append(goalIndex, CalcSearchIndexFromTime(obj, goalTime) ).astype(int)\n",
    "\n",
    "    tmp={}\n",
    "    comDataArray =[]\n",
    "    key={}\n",
    "\n",
    "    # センサデータすべて（時刻、加速度、角速度）に対して共通区間のみのデータを抽出\n",
    "    for number,iDA in enumerate( inputDataArray ):\n",
    "\n",
    "        tmp['AccX'] = copy.deepcopy( iDA['AccX'][startIndex[number]:goalIndex[number]] )\n",
    "        tmp['AccY'] = copy.deepcopy( iDA['AccY'][startIndex[number]:goalIndex[number]] )\n",
    "        tmp['AccZ'] = copy.deepcopy( iDA['AccZ'][startIndex[number]:goalIndex[number]] )\n",
    "        tmp['GyrX'] = copy.deepcopy( iDA['GyrX'][startIndex[number]:goalIndex[number]] )\n",
    "        tmp['GyrY'] = copy.deepcopy( iDA['GyrY'][startIndex[number]:goalIndex[number]] )\n",
    "        tmp['GyrZ'] = copy.deepcopy( iDA['GyrZ'][startIndex[number]:goalIndex[number]] )\n",
    "        tmp['Time'] = copy.deepcopy( iDA['Time'][startIndex[number]:goalIndex[number]] )\n",
    "        tmp['Name'] = copy.deepcopy( iDA['Name'] )\n",
    "        comDataArray.append(copy.deepcopy(tmp) )    \n",
    "        key[ tmp['Name'] ] = number\n",
    "       \n",
    "    return key,comDataArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "36290413 is much in the index  whose number is 35\n",
      "goal\n",
      "37368283 is much in the index  whose number is 1077905\n",
      "start\n",
      "36290413 is much in the index  whose number is 0\n",
      "goal\n",
      "37368283 is much in the index  whose number is 1077870\n",
      "start\n",
      "36290413 is much in the index  whose number is 959\n",
      "goal\n",
      "37368283 is much in the index  whose number is 1078829\n",
      "start\n",
      "36290413 is much in the index  whose number is 911\n",
      "goal\n",
      "37368283 is much in the index  whose number is 1078781\n",
      "start\n",
      "36290413 is much in the index  whose number is 871\n",
      "goal\n",
      "37368283 is much in the index  whose number is 1078741\n",
      "start\n",
      "36290413 is much in the index  whose number is 834\n",
      "goal\n",
      "37368283 is much in the index  whose number is 1078704\n"
     ]
    }
   ],
   "source": [
    "TrimKey,TrimData = MakeCommonSection(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FFT library\n",
    "from scipy import fftpack\n",
    "from scipy import signal\n",
    "\n",
    "# Graph Plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate WindowFrame Function\n",
    "from mymodule import window\n",
    "\n",
    "# timer\n",
    "import time\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 1080 (CNMeM is disabled, cuDNN 5005)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.datasets import cifar10\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.optimizers import SGD, Adadelta, Adagrad, Adam, Adamax, RMSprop, Nadam\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.utils.visualize_util import model_to_dot, plot\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import matplotlib.image as mpimg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LoadDataFromNPZ(Path,DataName):\n",
    "    \"\"\"\n",
    "    Path 　　NPZファイルがあるパス\n",
    "    DataName 名前，ここでは装着した部位を指す\n",
    "    \"\"\"\n",
    "    Label = ['LeftHand','RightHand','LeftLeg','RightLeg','West','Chest']\n",
    "    \n",
    "    # check which DataName is wrong\n",
    "    if not DataName in Label: return -1\n",
    "    \n",
    "    for i in range( len(Label) ):\n",
    "        if DataName == Label[i]:\n",
    "            return np.load(Path+DataName+'.npz')['data'][()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variational AutoEncoderを実装してみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils import np_utils\n",
    "from keras import callbacks\n",
    "from keras import objectives\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Input, Dense, Lambda, merge\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.regularizers import activity_l2\n",
    "from keras.utils.visualize_util import plot\n",
    "from IPython.display import Image\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# パラメータ\n",
    "nb_epoch=30\n",
    "batch_size=32\n",
    "z_dim =4\n",
    "epsilon_std = 1.0 # if epsilon is about 0, VAE is closing to AutoEncoder\n",
    "latent_dim = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 1886/33682 [00:00<00:01, 18851.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AccX is registed now\n",
      "Build Complete\n",
      "Source shape is(1077870,)\n",
      "window frames num =33682\n",
      "offset=14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33682/33682 [00:17<00:00, 1947.80it/s]\n"
     ]
    }
   ],
   "source": [
    "# 訓練データ\n",
    "w=window()\n",
    "w.SetData('AccX',TrimData[0]['AccX'])\n",
    "wind=w.Compile(windowWidth=32,slidingWidth=16)\n",
    "windoW=wind.reshape((len(wind),np.prod(wind.shape[1:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binary_crossentropy(y_true, y_pred):\n",
    "    return K.sum(K.binary_crossentropy(y_pred, y_true), axis=-1)\n",
    "\n",
    "def vae_loss(x, x_decoded_mean):\n",
    "    reconst_loss = K.mean(binary_crossentropy(x, x_decoded_mean),axis=-1)\n",
    "    latent_loss =  - 0.5 * K.mean(K.sum(1 + K.log(K.square(z_sigma)) - K.square(z_mean) - K.square(z_sigma), axis=-1))\n",
    "    return reconst_loss + latent_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Encoder Layer\n",
    "#I change z_sigma_log to z_sigma from original. But it doesn't influcence the result\n",
    "x = Input(shape=(windoW.shape[1] ,))\n",
    "hidden = Dense(500, activation='tanh')(x)\n",
    "z_mean = Dense(z_dim, activation='linear')(hidden)\n",
    "z_sigma = Dense(z_dim, activation='linear')(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Sampling Function\n",
    "def sampling(args):\n",
    "    z_mean, z_sigma = args\n",
    "    epsilon = K.random_normal(shape=(z_dim,), mean=0., std=epsilon_std)\n",
    "    return z_mean + z_sigma * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Sampling\n",
    "z = Lambda(sampling, output_shape=(z_dim,))([z_mean, z_sigma])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Decoder Layer\n",
    "decoder_h = Dense(500, activation='tanh')\n",
    "decoder_mean = Dense(784, activation='sigmoid')\n",
    "h_decoded = decoder_h(z)\n",
    "x_decoded_mean = decoder_mean(h_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vae = Model(x, x_decoded_mean)\n",
    "vae.compile(optimizer='rmsprop', loss=vae_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-a16766e7f246>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m hist_vae = vae.fit(X_train, X_train,\n\u001b[0m\u001b[1;32m      2\u001b[0m         \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         validation_data=(X_test, X_test))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "hist_vae = vae.fit(X_train, X_train,\n",
    "        nb_epoch=nb_epoch,\n",
    "        batch_size=batch_size,\n",
    "        shuffle = True,              \n",
    "        validation_data=(X_test, X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
