{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 以下テンプレート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 表示用\n",
    "from tqdm import tqdm\n",
    "from tqdm import tnrange, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "import copy\n",
    "\n",
    "# Parametor about Sensor\n",
    "SensorNum=1 # Sensor number\n",
    "#SensorAxis='AccX' # Axis\n",
    "\n",
    "# Define Data Name\n",
    "DATE= str( datetime.date.today() )+'/'\n",
    "TITLE=\"Participants01_First_1/\"\n",
    "Label = ['LeftHand','RightHand','LeftLeg','Rightleg','West','Chest']\n",
    "\n",
    "# Parametor about \" Data Path\"\n",
    "DataPath = \"/media/takeyama/Transfer/02_ActivityResearch/Paticipants01/01_First/20161018-105301/mem/\"\n",
    "StorePath = \"/media/takeyama/Transfer/02_ActivityResearch/\"\n",
    "\n",
    "if not os.path.exists(StorePath+TITLE+'dictionary/'): \n",
    "    os.makedirs(StorePath+TITLE+'dictionary/')\n",
    "DictionaryDataPath=StorePath+TITLE+'dictionary/'\n",
    "\n",
    "if not os.path.exists(StorePath+TITLE+'window/'): \n",
    "    os.makedirs(StorePath+TITLE+'window/')\n",
    "WindowDataPath=StorePath+TITLE+'window/'\n",
    "\n",
    "if not os.path.exists(StorePath+TITLE+DATE+'studyOutput/'): \n",
    "    os.makedirs(StorePath+TITLE+DATE+'studyOutput/')\n",
    "StudyOutputPath=StorePath+TITLE+DATE+'studyOutput/'\n",
    "\n",
    "if not os.path.exists(StorePath+TITLE+DATE+'parametor/'): \n",
    "    os.makedirs(StorePath+TITLE+DATE+'parametor/')\n",
    "ParametorPath=StorePath+TITLE+DATE+'parametor/'\n",
    "\n",
    "if not os.path.exists(StorePath+TITLE+DATE+'result/'): \n",
    "    os.makedirs(StorePath+TITLE+DATE+'result/')\n",
    "ResultPath=StorePath+TITLE+DATE+'result/'\n",
    "\n",
    "if not os.path.exists(StorePath+TITLE+DATE+'graph/'): \n",
    "    os.makedirs(StorePath+TITLE+DATE+'graph/')\n",
    "GraphPath=StorePath+TITLE+DATE+'graph/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**センサデータの読み込み**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# センサデータのcsvファイル名をリストに集約する関数\n",
    "def SensorDataFileNameList(path):\n",
    "    l = os.listdir(DataPath)\n",
    "    FilePath =[]\n",
    "    SensorName = []\n",
    "    \n",
    "    for n in range(len(l)):\n",
    "        if (l[n][:4].find('mem-') != -1):\n",
    "            FilePath.append(l[n])\n",
    "            SensorName.append(l[n][4:15])\n",
    "    \n",
    "    return FilePath,SensorName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSVを読み込んで，CSVの中身を辞書型で表現する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ImportCSV(csv_file,SensorName,mode='Round'):\n",
    "    import pandas as pd\n",
    "    '''\n",
    "    ~Argument~\n",
    "    csv_file -> ファイル名 \n",
    "    mode Round -> 四捨五入\n",
    "         Roundup -> 切り上げ\n",
    "         Rounddown -> 切り捨て\n",
    "    \n",
    "    ~Conversion~\n",
    "    Acc Data  [0.1mG]=>[G]\n",
    "    Gyr Data  [0.01dps]=>[dps]   ...dps=degree per second\n",
    "    '''\n",
    "    # data dictionary \n",
    "    RawData={}   \n",
    "    AccConversion = 0.1 * 0.001\n",
    "    GyrConversion = 0.01\n",
    "    \n",
    "    # design dataframe and import csv\n",
    "    data = pd.read_csv(csv_file)\n",
    "    data.columns=[u'Type',u'Time',u'AccX',u'AccY',u'AccZ',u'GyrX',u'GyrY',u'GyrZ']\n",
    "    data = data[ data['Type']=='ags']\n",
    "\n",
    "    # convert numpy.darray \n",
    "\n",
    "    AccX=data.AccX.values*AccConversion\n",
    "    AccY=data.AccY.values*AccConversion\n",
    "    AccZ=data.AccZ.values*AccConversion\n",
    "    \n",
    "    GyrX=data.GyrX.values*GyrConversion\n",
    "    GyrY=data.GyrY.values*GyrConversion\n",
    "    GyrZ=data.GyrZ.values*GyrConversion\n",
    "\n",
    "    # regist each raw data \n",
    "    RawData['AccX'] = AccX\n",
    "    RawData['AccY'] = AccY\n",
    "    RawData['AccZ'] = AccZ\n",
    "    RawData['GyrX'] = GyrX\n",
    "    RawData['GyrY'] = GyrY\n",
    "    RawData['GyrZ'] = GyrZ\n",
    "    RawData['Name'] = SensorName\n",
    "\n",
    "    RawData['Time'] = data.Time.values\n",
    "\n",
    "    return RawData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# FFT library\n",
    "from scipy import fftpack\n",
    "from scipy import signal\n",
    "\n",
    "# Graph Plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate WindowFrame Function\n",
    "from mymodule import window\n",
    "\n",
    "# timer\n",
    "import time\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 1080 (CNMeM is disabled, cuDNN 5005)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.datasets import cifar10\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.optimizers import SGD, Adadelta, Adagrad, Adam, Adamax, RMSprop, Nadam\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.utils.visualize_util import model_to_dot, plot\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import matplotlib.image as mpimg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Phase1 計測データの取得**\n",
    "\n",
    "ここで行うことは，学習に用いるnpzファイルを読み込む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/takeyama/Transfer/02_ActivityResearch/Participants01_First_1/dictionary/\n"
     ]
    }
   ],
   "source": [
    "print DictionaryDataPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Chest.npz', 'LeftHand.npz', 'LeftLeg.npz', 'RightHand.npz', 'Rightleg.npz', 'West.npz']\n"
     ]
    }
   ],
   "source": [
    "DictName=os.listdir(DictionaryDataPath)\n",
    "print DictName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Sensor1 = np.load(DictionaryDataPath+DictName[0])['data'][()]\n",
    "Sensor2 = np.load(DictionaryDataPath+DictName[1])['data'][()]\n",
    "Sensor3 = np.load(DictionaryDataPath+DictName[2])['data'][()]\n",
    "Sensor4 = np.load(DictionaryDataPath+DictName[3])['data'][()]\n",
    "Sensor5 = np.load(DictionaryDataPath+DictName[4])['data'][()]\n",
    "Sensor6 = np.load(DictionaryDataPath+DictName[5])['data'][()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Phase2 window flame 作成 & Learning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-14-cb1b1d655f9c>, line 28)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-14-cb1b1d655f9c>\"\u001b[0;36m, line \u001b[0;32m28\u001b[0m\n\u001b[0;31m    decoder = Model(input=encoded_input, output=decoded)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "def DeepAutoEncoder(TrainWindow,TestWindow,dim,opt,cname,batchSize):\n",
    "    \"\"\"\n",
    "    TrainWindow: 訓練データ\n",
    "    TestWindow: テストデータ\n",
    "    dim: 中間層の次元数\n",
    "    opt: 最適化関数\n",
    "    cname: 各種データを保存する用の共通の名前\n",
    "    \"\"\"\n",
    "    input_img = Input(shape=( TrainWindow.shape[1] ,))\n",
    "    \n",
    "    #encoded = Dense(dim, activation='tanh')(input_img)\n",
    "    encoded = Dense(dim, activation='tanh')(input_img)\n",
    "    encoded = Dense(dim/2, activation='tanh')(encoded)\n",
    "    encoded = Dense(dim/4, activation='tanh')(encoded)\n",
    "\n",
    "    #decoded = Dense( TrainWindow.shape[1] , activation='linear')(encoded)\n",
    "    decoded = Dense(dim/2, activation='tanh')(encoded)\n",
    "    decoded = Dense(dim, activation='tanh')(decoded)\n",
    "    decoded = Dense(TrainWindow.shape[1], activation='linear')(decoded)\n",
    "    \n",
    "    autoencoder = Model(input=input_img, output=decoded)\n",
    "    \n",
    "    encoder = Model(input=input_img, output=encoded)\n",
    "    \n",
    "    encoded_input = Input(shape=(dim/4,))\n",
    "    #decoder_layer = autoencoder.layers[-1] \n",
    "    #decoder = Model(input=encoded_input, output=decoder_layer(encoded_input))\n",
    "    decoder = Model(input=encoded_input, output=decoded)\n",
    "\n",
    "    autoencoder.compile(optimizer=opt, loss='mse')\n",
    "\n",
    "    plot(autoencoder,  to_file=StudyDataModelPicPath+SaveFileNameNet+'.png')\n",
    "    \n",
    "    #early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "    hist = autoencoder.fit(TrainWindow, TrainWindow,\n",
    "                    nb_epoch=50,\n",
    "                    verbose=2,\n",
    "                    batch_size=batchSize,\n",
    "                    shuffle=False,\n",
    "                    validation_data=(TestWindow, TestWindow)\n",
    "                    #callbacks=[early_stopping]\n",
    "                          )\n",
    "    time.sleep(0.1)\n",
    "\n",
    "    encoded_imgs = encoder.predict(TrainWindow,batch_size=batchSize,verbose=1)\n",
    "    decoded_imgs = decoder.predict(encoded_imgs,batch_size=batchSize,verbose=1)\n",
    "\n",
    "    np.savez(StudyOutputPath+cname+'_Encoded',data=encoded_imgs)\n",
    "    np.savez(StudyOutputPath+cname+'_Decoded',data=decoded_imgs)\n",
    "\n",
    "    # save model and wights\n",
    "    json_string = encoder.to_json()\n",
    "    open(StudyOutputPath+cname+'_Encoded'+'.json', 'w').write(json_string)\n",
    "    encoder.save_weights(ParametorPath+cname+'Encode_weights.h5',overwrite=True)\n",
    "\n",
    "    json_string = decoder.to_json()\n",
    "    open(StudyOutputPath+cname+'_Decoded'+'.json', 'w').write(json_string)\n",
    "    decoder.save_weights(ParametorPath+cname+'Decord_weights.h5',overwrite=True)\n",
    "\n",
    "    json_string = autoencoder.to_json()\n",
    "    open(StudyOutputPath+cname+'_Net'+'.json', 'w').write(json_string)\n",
    "    autoencoder.save_weights(ParametorPath+cname+'Net_weights.h5',overwrite=True)\n",
    "\n",
    "    # plot loss\n",
    "    loss = hist.history['loss']\n",
    "    val_loss = hist.history['val_loss']\n",
    "\n",
    "    nb_epoch = len(loss)\n",
    "    plt.plot(range(nb_epoch), loss, marker='.', label='loss')\n",
    "    plt.plot(range(nb_epoch), val_loss, marker='.', label='val_loss')\n",
    "    plt.legend(loc='best', fontsize=10)\n",
    "    plt.grid()\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.savefig(ResultPath+cname+'.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def GetWindowFrame(windowName, dataRaw, wWidth, sWidth, PATH):\n",
    "    \"\"\"\n",
    "    data　ウィンドウフレームに変換するデータ\n",
    "    registName　ウィンドウフレームに登録するデータの名前\n",
    "    windowWidth　ウィンドウ幅\n",
    "    slidingWidth　スライド幅\n",
    "    PATH ウィドウフレームを保存するディレクトリ\n",
    "    \n",
    "    \n",
    "    About Function:\n",
    "        与えられたdataからウィンドウ幅windowWidth,スライド幅slidingWidthにしたがって\n",
    "        registNameのウィドウフレームを返す．\n",
    "        また，与えれたPATH内に同様なパラメータ( WindowWidth, slidingWidth)かつ同様な\n",
    "        windowNameのものがある場合，そのデータを返す．\n",
    "        この関数が登録，ウィンドウフレームに変換できるデータは１つとする\n",
    "    \"\"\"\n",
    "    storedName = windowName+'_Win='+str(wWidth).zfill(4)+'_Sld='+str(sWidth).zfill(4)+'.npz'\n",
    "    l = os.listdir(PATH)\n",
    "    \n",
    "    if storedName in l:\n",
    "        print \"this data had finished making\"\n",
    "        return np.load(PATH+storedName)['data'][()]\n",
    "    \n",
    "    w=window()\n",
    "    w.SetData(windowName,dataRaw)    \n",
    "    wind=w.Compile(wWidth,sWidth)\n",
    "    windoW=wind.reshape((len(wind),np.prod(wind.shape[1:])))\n",
    "    \n",
    "    np.savez(PATH+storedName,data=wind)\n",
    "\n",
    "    return wind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this data had finished making\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.8825,  0.8755,  0.8711, ...,  0.9233,  0.925 ,  0.9206],\n",
       "       [ 0.8674,  0.8728,  0.8821, ...,  0.8264,  0.824 ,  0.8271],\n",
       "       [ 0.8371,  0.8437,  0.8447, ...,  0.8532,  0.8471,  0.8498],\n",
       "       ..., \n",
       "       [-0.1003, -0.0998, -0.0912, ..., -0.0995, -0.0942, -0.0925],\n",
       "       [-0.1   , -0.1025, -0.1022, ..., -0.0939, -0.0986, -0.0966],\n",
       "       [-0.0939, -0.0978, -0.0981, ..., -0.0976, -0.1015, -0.0973]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GetWindowFrame('AccX',Sensor1['AccX'],256,256/8,WindowDataPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# スクリプトの目的\n",
    "本スクリプトの目的および学習方法を明記する\n",
    "本スクリプトの目的は，**学習パラメータを今までのと比較して大きくことから，学習にどのような影響を与えるのか確認する**\n",
    "\n",
    "パラメータ\n",
    "* window幅 256,512,1024,2048,4096\n",
    "* slidign幅 window幅/8\n",
    "* Batch_size 32\n",
    "* Optimizer Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this data had finished making\n",
      "hiden node = 16\n",
      "_AEdim=016_Win=0256_Sld=0032_Adam_DeepAE\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Input 0 is incompatible with layer dense_12: expected shape=(None, 16), found shape=(None, 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-1d21b1eab219>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m#np.savez(WindowDataPath+CommonName+'_Train',data=windoW)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mDeepAutoEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindoW\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwindoW\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mAEDimention\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mOptim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mCommonName\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mBatchSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-322d99e8db74>\u001b[0m in \u001b[0;36mDeepAutoEncoder\u001b[0;34m(TrainWindow, TestWindow, dim, opt, cname, batchSize)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mencoded_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mdecoder_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/takeyama/.pyenv/versions/2.7.11/envs/takeyama/lib/python2.7/site-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0;31m# raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[0;31m# with the input_spec set at build time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m         \u001b[0;31m# build and connect layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0minput_added\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/takeyama/.pyenv/versions/2.7.11/envs/takeyama/lib/python2.7/site-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    403\u001b[0m                                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected shape='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found shape='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m                                             str(x_shape))\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Input 0 is incompatible with layer dense_12: expected shape=(None, 16), found shape=(None, 4)"
     ]
    }
   ],
   "source": [
    "# loop windowWidth\n",
    "WindowWidth = np.array( [256,512,1024,2048,4096] )\n",
    "SlidingWidth = WindowWidth/8\n",
    "BatchSize = 32\n",
    "Optim='Adam'\n",
    "AEDimention = 16\n",
    "\n",
    "for WindowNum,SlidingNum in zip(WindowWidth,SlidingWidth):\n",
    "    windoW = GetWindowFrame('AccX',Sensor1['AccX'],WindowNum,SlidingNum,WindowDataPath)\n",
    "    \n",
    "    print \"hiden node = \"+str(AEDimention)\n",
    "    \n",
    "    CommonName='_AEdim='+str(AEDimention).zfill(3)+'_Win='+str(WindowNum).zfill(4)+\\\n",
    "    '_Sld='+str(SlidingNum).zfill(4)+'_'+Optim+'_DeepAE'\n",
    "        \n",
    "    print CommonName\n",
    "\n",
    "    #np.savez(WindowDataPath+CommonName+'_Test',data=windoW)\n",
    "    #np.savez(WindowDataPath+CommonName+'_Train',data=windoW)\n",
    "\n",
    "    DeepAutoEncoder(windoW,windoW,AEDimention,Optim,CommonName,BatchSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "windoW.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習の過程を見ると，明らかにおかしな学習をしていることがわかる．これの原因としてを列挙する\n",
    "* 学習の際に入力データをシャッフルせず，時系列順に渡しているから\n",
    "* 最適化方法が合ってない\n",
    "* バッチサイズが最適値でない  \n",
    "他にも原因あるが，とりあえず一番の内容はもう少し考える．\n",
    "まずは，最適化方法を試す．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loop windowWidth\n",
    "WindowWidth = np.array( [256,512,1024,2048,4096] )\n",
    "SlidingWidth = WindowWidth/8\n",
    "BatchSize = 32\n",
    "Optim='rmsprop'\n",
    "AEDimention = 16\n",
    "\n",
    "for WindowNum,SlidingNum in zip(WindowWidth,SlidingWidth):\n",
    "    windoW = GetWindowFrame('AccX',Sensor1['AccX'],WindowNum,SlidingNum,WindowDataPath)\n",
    "    \n",
    "    print \"hiden node = \"+str(AEDimention)\n",
    "     CommonName='_AEdim='+str(AEDimention).zfill(3)+'_Win='+str(WindowNum).zfill(4)+\\\n",
    "    '_Sld='+str(SlidingNum).zfill(4)+'_'+Optim+'_DeepAE'\n",
    "    print CommonName\n",
    "\n",
    "    #np.savez(WindowDataPath+CommonName+'_Test',data=windoW)\n",
    "    #np.savez(WindowDataPath+CommonName+'_Train',data=windoW)\n",
    "\n",
    "    DeepAutoEncoder(windoW,windoW,AEDimention,Optim,CommonName,BatchSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "バッチサイズを変更してみる，まずは試しに先ほどの半分で学習する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loop windowWidth\n",
    "WindowWidth = np.array( [256,512,1024,2048,4096] )\n",
    "SlidingWidth = WindowWidth/8\n",
    "BatchSize = 16\n",
    "Optim='rmsprop'\n",
    "AEDimention = 16\n",
    "\n",
    "for WindowNum,SlidingNum in zip(WindowWidth,SlidingWidth):\n",
    "    windoW = GetWindowFrame('AccX',Sensor1['AccX'],WindowNum,SlidingNum,WindowDataPath)\n",
    "    \n",
    "    print \"hiden node = \"+str(AEDimention)\n",
    "    \n",
    "    CommonName='_AEdim='+str(AEDimention).zfill(3)+'_Win='+str(WindowNum).zfill(4)+\\\n",
    "    '_Sld='+str(SlidingNum).zfill(4)+'_'+Optim+'_DeepAE'\n",
    "    print CommonName\n",
    "\n",
    "    #np.savez(WindowDataPath+CommonName+'_Test',data=windoW)\n",
    "    #np.savez(WindowDataPath+CommonName+'_Train',data=windoW)\n",
    "\n",
    "    DeepAutoEncoder(windoW,windoW,AEDimention,Optim,CommonName,BatchSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "電話を受けてやっていくこと  \n",
    "まず，学習方法のパラメータを変更して見ていく．  \n",
    "まず，中間層の値を変えてみるー＞入力データと同じ，２分の１，４分の１，８分の１でやる  \n",
    "次に，最適化法保をＳＧＤ試す  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loop windowWidth\n",
    "WindowWidth = np.array( [256,512,1024,2048,4096] )\n",
    "SlidingWidth = WindowWidth/8\n",
    "BatchSize = 32\n",
    "Optim='sgd'\n",
    "#AEDimention = WindowWidth, WindowWidth/2, WindowWidth/4, WindowWidth/8\n",
    "\n",
    "for WindowNum,SlidingNum in zip(WindowWidth,SlidingWidth):\n",
    "    windoW = GetWindowFrame('AccX',Sensor1['AccX'],WindowNum,SlidingNum,WindowDataPath)\n",
    "        \n",
    "    AEDimentionS=np.array([WindowNum,WindowNum/2,WindowNum/4,WindowNum/8])\n",
    "\n",
    "    #np.savez(WindowDataPath+CommonName+'_Test',data=windoW)\n",
    "    #np.savez(WindowDataPath+CommonName+'_Train',data=windoW)\n",
    "    \n",
    "    for AEDimention in AEDimentionS:\n",
    "        print \"hiden node = \"+str(AEDimention)\n",
    "            \n",
    "        CommonName='_AEdim='+str(AEDimention).zfill(3)+'_Win='+str(WindowNum).zfill(4)+\\\n",
    "        '_Sld='+str(SlidingNum).zfill(4)+'_'+Optim+'_DeepAE'\n",
    "        print CommonName\n",
    "      \n",
    "        DeepAutoEncoder(windoW,windoW,AEDimention,Optim,CommonName,BatchSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上の結果を見る限り，いい感じに学習できていることがわかった．興味として，上記の中間層の次元以外のパラメータを固定して，さらに次元を圧縮してみる．具体的には，1/8より圧縮してみる．\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# loop windowWidth\n",
    "WindowWidth = np.array( [256,512,1024,2048,4096] )\n",
    "SlidingWidth = WindowWidth/8\n",
    "BatchSize = 32\n",
    "Optim='sgd'\n",
    "#AEDimention = WindowWidth, WindowWidth/2, WindowWidth/4, WindowWidth/8\n",
    "\n",
    "for WindowNum,SlidingNum in zip(WindowWidth,SlidingWidth):\n",
    "    windoW = GetWindowFrame('AccX',Sensor1['AccX'],WindowNum,SlidingNum,WindowDataPath)\n",
    "        \n",
    "    AEDimentionS=np.array([WindowNum/8,WindowNum/16,WindowNum/32,WindowNum/64])\n",
    "\n",
    "    #np.savez(WindowDataPath+CommonName+'_Test',data=windoW)\n",
    "    #np.savez(WindowDataPath+CommonName+'_Train',data=windoW)\n",
    "    \n",
    "    for AEDimention in AEDimentionS:\n",
    "        print \"hiden node = \"+str(AEDimention)\n",
    "            \n",
    "        CommonName='_AEdim='+str(AEDimention).zfill(3)+'_Win='+str(WindowNum).zfill(4)+\\\n",
    "        '_Sld='+str(SlidingNum).zfill(4)+'_'+Optim+'_DeepAE'\n",
    "        print CommonName\n",
    "\n",
    "        DeepAutoEncoder(windoW,windoW,AEDimention,Optim,CommonName,BatchSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
