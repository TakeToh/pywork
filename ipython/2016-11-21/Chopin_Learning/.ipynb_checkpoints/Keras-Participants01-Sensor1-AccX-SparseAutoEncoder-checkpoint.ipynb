{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 以下テンプレート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 表示用\n",
    "from tqdm import tqdm\n",
    "from tqdm import tnrange, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "import copy\n",
    "\n",
    "# Parametor about Sensor\n",
    "SensorNum=1 # Sensor number\n",
    "#SensorAxis='AccX' # Axis\n",
    "\n",
    "# Define Data Name\n",
    "DATE= str( datetime.date.today() )+'/'\n",
    "TITLE=\"Participants01_First_1/\"\n",
    "Label = ['LeftHand','RightHand','LeftLeg','Rightleg','West','Chest']\n",
    "\n",
    "# Parametor about \" Data Path\"\n",
    "DataPath = \"/media/takeyama/Transfer/02_ActivityResearch/Paticipants01/01_First/20161018-105301/mem/\"\n",
    "StorePath = \"/media/takeyama/Transfer/02_ActivityResearch/\"\n",
    "\n",
    "if not os.path.exists(StorePath+TITLE+'dictionary/'): \n",
    "    os.makedirs(StorePath+TITLE+'dictionary/')\n",
    "DictionaryDataPath=StorePath+TITLE+'dictionary/'\n",
    "\n",
    "if not os.path.exists(StorePath+TITLE+'window/'): \n",
    "    os.makedirs(StorePath+TITLE+'window/')\n",
    "WindowDataPath=StorePath+TITLE+'window/'\n",
    "\n",
    "if not os.path.exists(StorePath+TITLE+DATE+'studyOutput/'): \n",
    "    os.makedirs(StorePath+TITLE+DATE+'studyOutput/')\n",
    "StudyOutputPath=StorePath+TITLE+DATE+'studyOutput/'\n",
    "\n",
    "if not os.path.exists(StorePath+TITLE+DATE+'parametor/'): \n",
    "    os.makedirs(StorePath+TITLE+DATE+'parametor/')\n",
    "ParametorPath=StorePath+TITLE+DATE+'parametor/'\n",
    "\n",
    "if not os.path.exists(StorePath+TITLE+DATE+'result/'): \n",
    "    os.makedirs(StorePath+TITLE+DATE+'result/')\n",
    "ResultPath=StorePath+TITLE+DATE+'result/'\n",
    "\n",
    "if not os.path.exists(StorePath+TITLE+DATE+'graph/'): \n",
    "    os.makedirs(StorePath+TITLE+DATE+'graph/')\n",
    "GraphPath=StorePath+TITLE+DATE+'graph/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**センサデータの読み込み**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# センサデータのcsvファイル名をリストに集約する関数\n",
    "def SensorDataFileNameList(path):\n",
    "    l = os.listdir(DataPath)\n",
    "    FilePath =[]\n",
    "    SensorName = []\n",
    "    \n",
    "    for n in range(len(l)):\n",
    "        if (l[n][:4].find('mem-') != -1):\n",
    "            FilePath.append(l[n])\n",
    "            SensorName.append(l[n][4:15])\n",
    "    \n",
    "    return FilePath,SensorName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSVを読み込んで，CSVの中身を辞書型で表現する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ImportCSV(csv_file,SensorName,mode='Round'):\n",
    "    import pandas as pd\n",
    "    '''\n",
    "    ~Argument~\n",
    "    csv_file -> ファイル名 \n",
    "    mode Round -> 四捨五入\n",
    "         Roundup -> 切り上げ\n",
    "         Rounddown -> 切り捨て\n",
    "    \n",
    "    ~Conversion~\n",
    "    Acc Data  [0.1mG]=>[G]\n",
    "    Gyr Data  [0.01dps]=>[dps]   ...dps=degree per second\n",
    "    '''\n",
    "    # data dictionary \n",
    "    RawData={}   \n",
    "    AccConversion = 0.1 * 0.001\n",
    "    GyrConversion = 0.01\n",
    "    \n",
    "    # design dataframe and import csv\n",
    "    data = pd.read_csv(csv_file)\n",
    "    data.columns=[u'Type',u'Time',u'AccX',u'AccY',u'AccZ',u'GyrX',u'GyrY',u'GyrZ']\n",
    "    data = data[ data['Type']=='ags']\n",
    "\n",
    "    # convert numpy.darray \n",
    "\n",
    "    AccX=data.AccX.values*AccConversion\n",
    "    AccY=data.AccY.values*AccConversion\n",
    "    AccZ=data.AccZ.values*AccConversion\n",
    "    \n",
    "    GyrX=data.GyrX.values*GyrConversion\n",
    "    GyrY=data.GyrY.values*GyrConversion\n",
    "    GyrZ=data.GyrZ.values*GyrConversion\n",
    "\n",
    "    # regist each raw data \n",
    "    RawData['AccX'] = AccX\n",
    "    RawData['AccY'] = AccY\n",
    "    RawData['AccZ'] = AccZ\n",
    "    RawData['GyrX'] = GyrX\n",
    "    RawData['GyrY'] = GyrY\n",
    "    RawData['GyrZ'] = GyrZ\n",
    "    RawData['Name'] = SensorName\n",
    "\n",
    "    RawData['Time'] = data.Time.values\n",
    "\n",
    "    return RawData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# FFT library\n",
    "from scipy import fftpack\n",
    "from scipy import signal\n",
    "\n",
    "# Graph Plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate WindowFrame Function\n",
    "from mymodule import window\n",
    "\n",
    "# timer\n",
    "import time\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.datasets import cifar10\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.optimizers import SGD, Adadelta, Adagrad, Adam, Adamax, RMSprop, Nadam\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.utils.visualize_util import model_to_dot, plot\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import matplotlib.image as mpimg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Phase1 計測データの取得**\n",
    "\n",
    "ここで行うことは，学習に用いるnpzファイルを読み込む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/takeyama/Transfer/02_ActivityResearch/Participants01_First_1/dictionary/\n"
     ]
    }
   ],
   "source": [
    "print DictionaryDataPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Chest.npz', 'LeftHand.npz', 'LeftLeg.npz', 'RightHand.npz', 'Rightleg.npz', 'West.npz']\n"
     ]
    }
   ],
   "source": [
    "DictName=os.listdir(DictionaryDataPath)\n",
    "print DictName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Sensor1 = np.load(DictionaryDataPath+DictName[0])['data'][()]\n",
    "Sensor2 = np.load(DictionaryDataPath+DictName[1])['data'][()]\n",
    "Sensor3 = np.load(DictionaryDataPath+DictName[2])['data'][()]\n",
    "Sensor4 = np.load(DictionaryDataPath+DictName[3])['data'][()]\n",
    "Sensor5 = np.load(DictionaryDataPath+DictName[4])['data'][()]\n",
    "Sensor6 = np.load(DictionaryDataPath+DictName[5])['data'][()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Phase2 window flame 作成 & Learning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def SparseAutoEncoder(TrainWindow,TestWindow,dim,opt,cname,batchSize):\n",
    "    \"\"\"\n",
    "    TrainWindow: 訓練データ\n",
    "    TestWindow: テストデータ\n",
    "    dim: 中間層の次元数\n",
    "    opt: 最適化関数\n",
    "    cname: 各種データを保存する用の共通の名前\n",
    "    \"\"\"\n",
    "    input_img = Input(shape=( TrainWindow.shape[1],))\n",
    "    \n",
    "    encoded = Dense(dim, activation='tanh',\\\n",
    "                   #activity_regularizer=regularizers.activity_l1(1e-4)\\\n",
    "                   )(input_img)\n",
    "    decoded = Dense( TrainWindow.shape[1] , activation='linear')(encoded)\n",
    "    autoencoder = Model(input=input_img, output=decoded)\n",
    "    \n",
    "    encoder = Model(input=input_img, output=encoded)\n",
    "    encoded_input = Input(shape=(dim,))\n",
    "    decoder_layer = autoencoder.layers[-1]\n",
    "    decoder = Model(input=encoded_input, output=decoder_layer(encoded_input))\n",
    "    autoencoder.compile(optimizer=opt, loss='mse')\n",
    "\n",
    "    #plot(autoencoder,  to_file=StudyDataModelPicPath+SaveFileNameNet+'.png')\n",
    "    \n",
    "    #early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "    hist = autoencoder.fit(TrainWindow, TrainWindow,\n",
    "                    nb_epoch=50,\n",
    "                    verbose=2,\n",
    "                    batch_size=batchSize,\n",
    "                    shuffle=False,\n",
    "                    validation_data=(TestWindow, TestWindow)\n",
    "                    #callbacks=[early_stopping]\n",
    "                          )\n",
    "    time.sleep(0.1)\n",
    "\n",
    "    encoded_imgs = encoder.predict(TrainWindow,batch_size=batchSize,verbose=1)\n",
    "    decoded_imgs = decoder.predict(encoded_imgs,batch_size=batchSize,verbose=1)\n",
    "\n",
    "    np.savez(StudyOutputPath+cname+'_Encoded',data=encoded_imgs)\n",
    "    np.savez(StudyOutputPath+cname+'_Decoded',data=decoded_imgs)\n",
    "\n",
    "    # save model and wights\n",
    "    json_string = encoder.to_json()\n",
    "    open(StudyOutputPath+cname+'_Encoded'+'.json', 'w').write(json_string)\n",
    "    encoder.save_weights(ParametorPath+cname+'Encode_weights.h5',overwrite=True)\n",
    "\n",
    "    json_string = decoder.to_json()\n",
    "    open(StudyOutputPath+cname+'_Decoded'+'.json', 'w').write(json_string)\n",
    "    decoder.save_weights(ParametorPath+cname+'Decord_weights.h5',overwrite=True)\n",
    "\n",
    "    json_string = autoencoder.to_json()\n",
    "    open(StudyOutputPath+cname+'_Net'+'.json', 'w').write(json_string)\n",
    "    autoencoder.save_weights(ParametorPath+cname+'Net_weights.h5',overwrite=True)\n",
    "\n",
    "    # plot loss\n",
    "    loss = hist.history['loss']\n",
    "    val_loss = hist.history['val_loss']\n",
    "\n",
    "    nb_epoch = len(loss)\n",
    "    plt.plot(range(nb_epoch), loss, marker='.', label='loss')\n",
    "    plt.plot(range(nb_epoch), val_loss, marker='.', label='val_loss')\n",
    "    plt.legend(loc='best', fontsize=10)\n",
    "    plt.grid()\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.savefig(ResultPath+cname+'.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def GetWindowFrame(windowName, dataRaw, wWidth, sWidth, PATH):\n",
    "    \"\"\"\n",
    "    data　ウィンドウフレームに変換するデータ\n",
    "    registName　ウィンドウフレームに登録するデータの名前\n",
    "    windowWidth　ウィンドウ幅\n",
    "    slidingWidth　スライド幅\n",
    "    PATH ウィドウフレームを保存するディレクトリ\n",
    "    \n",
    "    \n",
    "    About Function:\n",
    "        与えられたdataからウィンドウ幅windowWidth,スライド幅slidingWidthにしたがって\n",
    "        registNameのウィドウフレームを返す．\n",
    "        また，与えれたPATH内に同様なパラメータ( WindowWidth, slidingWidth)かつ同様な\n",
    "        windowNameのものがある場合，そのデータを返す．\n",
    "        この関数が登録，ウィンドウフレームに変換できるデータは１つとする\n",
    "    \"\"\"\n",
    "    storedName = windowName+'_Win='+str(wWidth).zfill(4)+'_Sld='+str(sWidth).zfill(4)+'.npz'\n",
    "    l = os.listdir(PATH)\n",
    "    \n",
    "    if storedName in l:\n",
    "        print \"this data had finished making\"\n",
    "        return np.load(PATH+storedName)['data'][()]\n",
    "    \n",
    "    w=window()\n",
    "    w.SetData(windowName,dataRaw)    \n",
    "    wind=w.Compile(wWidth,sWidth)\n",
    "    windoW=wind.reshape((len(wind),np.prod(wind.shape[1:])))\n",
    "    \n",
    "    np.savez(PATH+storedName,data=wind)\n",
    "\n",
    "    return wind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this data had finished making\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.8825,  0.8755,  0.8711, ...,  0.9233,  0.925 ,  0.9206],\n",
       "       [ 0.8674,  0.8728,  0.8821, ...,  0.8264,  0.824 ,  0.8271],\n",
       "       [ 0.8371,  0.8437,  0.8447, ...,  0.8532,  0.8471,  0.8498],\n",
       "       ..., \n",
       "       [-0.1003, -0.0998, -0.0912, ..., -0.0995, -0.0942, -0.0925],\n",
       "       [-0.1   , -0.1025, -0.1022, ..., -0.0939, -0.0986, -0.0966],\n",
       "       [-0.0939, -0.0978, -0.0981, ..., -0.0976, -0.1015, -0.0973]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GetWindowFrame('AccX',Sensor1['AccX'],256,256/8,WindowDataPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# スクリプトの目的\n",
    "本スクリプトの目的および学習方法を明記する\n",
    "目的：\n",
    "スパースAEによる学習\n",
    "また，コピー元である\"Keras-Participants01-Sensor1-AccX\"にスパースを加えた変化を見る\n",
    "\n",
    "変更点:\n",
    "* 学習はSparseAutoEncoder関数で行う\n",
    "* CommonNameの最後にSparseを付ける\n",
    "\n",
    "パラメータ\n",
    "コピー元と同様"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33676, 256)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "windoW.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this data had finished making\n",
      "_AEdim=016_Win=0256_Sld=0032_Adam_Sparse\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cost must be a scalar.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-fbddfb343e6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m#np.savez(WindowDataPath+CommonName+'_Train',data=windoW)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mSparseAutoEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindoW\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwindoW\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mAEDimention\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mOptim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mCommonName\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mBatchSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-38-8b8589c4e974>\u001b[0m in \u001b[0;36mSparseAutoEncoder\u001b[0;34m(TrainWindow, TestWindow, dim, opt, cname, batchSize)\u001b[0m\n\u001b[1;32m     27\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatchSize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                     \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTestWindow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTestWindow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m                     \u001b[0;31m#callbacks=[early_stopping]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                           )\n",
      "\u001b[0;32m/home/takeyama/.pyenv/versions/2.7.11/envs/takeyama/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight)\u001b[0m\n\u001b[1;32m   1079\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/takeyama/.pyenv/versions/2.7.11/envs/takeyama/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_make_train_function\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    696\u001b[0m             \u001b[0;31m# get trainable weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0mtrainable_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollect_trainable_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m             \u001b[0mtraining_updates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_updates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstraints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    699\u001b[0m             \u001b[0mupdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtraining_updates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/takeyama/.pyenv/versions/2.7.11/envs/takeyama/lib/python2.7/site-packages/keras/optimizers.pyc\u001b[0m in \u001b[0;36mget_updates\u001b[0;34m(self, params, constraints, loss)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_updates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterations\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/takeyama/.pyenv/versions/2.7.11/envs/takeyama/lib/python2.7/site-packages/keras/optimizers.pyc\u001b[0m in \u001b[0;36mget_gradients\u001b[0;34m(self, loss, params)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'clipnorm'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclipnorm\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mnorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/takeyama/.pyenv/versions/2.7.11/envs/takeyama/lib/python2.7/site-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36mgradients\u001b[0;34m(loss, variables)\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/takeyama/.pyenv/versions/2.7.11/envs/takeyama/lib/python2.7/site-packages/theano/gradient.pyc\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(cost, wrt, consider_constant, disconnected_inputs, add_names, known_grads, return_disconnected, null_gradients)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcost\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cost must be a scalar.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cost must be a scalar."
     ]
    }
   ],
   "source": [
    "# loop windowWidth\n",
    "WindowWidth = np.array( [256,512,1024,2048,4096] )\n",
    "SlidingWidth = WindowWidth/8\n",
    "BatchSize = 32\n",
    "Optim='Adam'\n",
    "AEDimention = 16\n",
    "\n",
    "for WindowNum,SlidingNum in zip(WindowWidth,SlidingWidth):\n",
    "    windoW = GetWindowFrame('AccX',Sensor1['AccX'],WindowNum,SlidingNum,WindowDataPath)\n",
    "    \n",
    "    CommonName='_AEdim='+str(AEDimention).zfill(3)+'_Win='+str(WindowNum).zfill(4)+\\\n",
    "        '_Sld='+str(SlidingNum).zfill(4)+'_'+Optim+'_Sparse'\n",
    "        \n",
    "    print CommonName\n",
    "\n",
    "    #np.savez(WindowDataPath+CommonName+'_Test',data=windoW)\n",
    "    #np.savez(WindowDataPath+CommonName+'_Train',data=windoW)\n",
    "\n",
    "    SparseAutoEncoder(windoW,windoW,AEDimention,Optim,CommonName,BatchSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習の過程を見ると，明らかにおかしな学習をしていることがわかる．これの原因としてを列挙する\n",
    "* 学習の際に入力データをシャッフルせず，時系列順に渡しているから\n",
    "* 最適化方法が合ってない\n",
    "* バッチサイズが最適値でない  \n",
    "他にも原因あるが，とりあえず一番の内容はもう少し考える．\n",
    "まずは，最適化方法を試す．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loop windowWidth\n",
    "WindowWidth = np.array( [256,512,1024,2048,4096] )\n",
    "SlidingWidth = WindowWidth/8\n",
    "BatchSize = 32\n",
    "Optim='rmsprop'\n",
    "AEDimention = 16\n",
    "\n",
    "for WindowNum,SlidingNum in zip(WindowWidth,SlidingWidth):\n",
    "    windoW = GetWindowFrame('AccX',Sensor1['AccX'],WindowNum,SlidingNum,WindowDataPath)\n",
    "    \n",
    "    print \"hiden node = \"+str(AEDimention)\n",
    "    CommonName='_AEdim='+str(AEDimention).zfill(3)+'_Win='+str(WindowNum).zfill(4)+\\\n",
    "    '_Sld='+str(SlidingNum).zfill(4)+'_'+Optim+'_Sparse'\n",
    "    print CommonName\n",
    "\n",
    "    #np.savez(WindowDataPath+CommonName+'_Test',data=windoW)\n",
    "    #np.savez(WindowDataPath+CommonName+'_Train',data=windoW)\n",
    "\n",
    "    SparseAutoEncoder(windoW,windoW,AEDimention,Optim,CommonName,BatchSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "バッチサイズを変更してみる，まずは試しに先ほどの半分で学習する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loop windowWidth\n",
    "WindowWidth = np.array( [256,512,1024,2048,4096] )\n",
    "SlidingWidth = WindowWidth/8\n",
    "BatchSize = 16\n",
    "Optim='rmsprop'\n",
    "AEDimention = 16\n",
    "\n",
    "for WindowNum,SlidingNum in zip(WindowWidth,SlidingWidth):\n",
    "    windoW = GetWindowFrame('AccX',Sensor1['AccX'],WindowNum,SlidingNum,WindowDataPath)\n",
    "    \n",
    "    print \"hiden node = \"+str(AEDimention)\n",
    "    \n",
    "    CommonName='_dim='+str(AEDimention)+'_Win='+str(WindowNum).zfill(4)+\\\n",
    "    '_Sld='+str(SlidingNum).zfill(4)+'_'+Optim+'_Sparse'\n",
    "    print CommonName\n",
    "\n",
    "    #np.savez(WindowDataPath+CommonName+'_Test',data=windoW)\n",
    "    #np.savez(WindowDataPath+CommonName+'_Train',data=windoW)\n",
    "\n",
    "    SparseAutoEncoder(windoW,windoW,AEDimention,Optim,CommonName,BatchSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "電話を受けてやっていくこと  \n",
    "まず，学習方法のパラメータを変更して見ていく．  \n",
    "まず，中間層の値を変えてみるー＞入力データと同じ，２分の１，４分の１，８分の１でやる  \n",
    "次に，最適化法保をＳＧＤ試す  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loop windowWidth\n",
    "WindowWidth = np.array( [256,512,1024,2048,4096] )\n",
    "SlidingWidth = WindowWidth/8\n",
    "BatchSize = 32\n",
    "Optim='sgd'\n",
    "#AEDimention = WindowWidth, WindowWidth/2, WindowWidth/4, WindowWidth/8\n",
    "\n",
    "for WindowNum,SlidingNum in zip(WindowWidth,SlidingWidth):\n",
    "    windoW = GetWindowFrame('AccX',Sensor1['AccX'],WindowNum,SlidingNum,WindowDataPath)\n",
    "        \n",
    "    AEDimentionS=np.array([WindowNum,WindowNum/2,WindowNum/4,WindowNum/8])\n",
    "\n",
    "    #np.savez(WindowDataPath+CommonName+'_Test',data=windoW)\n",
    "    #np.savez(WindowDataPath+CommonName+'_Train',data=windoW)\n",
    "    \n",
    "    for AEDimention in AEDimentionS:\n",
    "        print \"hiden node = \"+str(AEDimention)\n",
    "            \n",
    "        CommonName='_AEdim='+str(AEDimention).zfill(3)+'_Win='+str(WindowNum).zfill(4)+\\\n",
    "        '_Sld='+str(SlidingNum).zfill(4)+'_'+Optim+'_Sparse'\n",
    "        print CommonName\n",
    "      \n",
    "        SparseAutoEncoder(windoW,windoW,AEDimention,Optim,CommonName,BatchSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上の結果を見る限り，いい感じに学習できていることがわかった．興味として，上記の中間層の次元以外のパラメータを固定して，さらに次元を圧縮してみる．具体的には，1/8より圧縮してみる．\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# loop windowWidth\n",
    "WindowWidth = np.array( [256,512,1024,2048,4096] )\n",
    "SlidingWidth = WindowWidth/8\n",
    "BatchSize = 32\n",
    "Optim='sgd'\n",
    "#AEDimention = WindowWidth, WindowWidth/2, WindowWidth/4, WindowWidth/8\n",
    "\n",
    "for WindowNum,SlidingNum in zip(WindowWidth,SlidingWidth):\n",
    "    windoW = GetWindowFrame('AccX',Sensor1['AccX'],WindowNum,SlidingNum,WindowDataPath)\n",
    "        \n",
    "    AEDimentionS=np.array([WindowNum/8,WindowNum/16,WindowNum/32,WindowNum/64])\n",
    "\n",
    "    #np.savez(WindowDataPath+CommonName+'_Test',data=windoW)\n",
    "    #np.savez(WindowDataPath+CommonName+'_Train',data=windoW)\n",
    "    \n",
    "    for AEDimention in AEDimentionS:\n",
    "        print \"hiden node = \"+str(AEDimention)\n",
    "            \n",
    "        CommonName='_AEdim='+str(AEDimention).zfill(3)+'_Win='+str(WindowNum).zfill(4)+\\\n",
    "        '_Sld='+str(SlidingNum).zfill(4)+'_'+Optim+'_Sparse'\n",
    "        print CommonName\n",
    "\n",
    "        SparseAutoEncoder(windoW,windoW,AEDimention,Optim,CommonName,BatchSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variational Auto Encoderのサンプルコード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''This script demonstrates how to build a variational autoencoder with Keras.\n",
    "Reference: \"Auto-Encoding Variational Bayes\" https://arxiv.org/abs/1312.6114\n",
    "'''\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "from keras.layers import Input, Dense, Lambda\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import objectives\n",
    "from keras.datasets import mnist\n",
    "\n",
    "batch_size = 100\n",
    "original_dim = 784\n",
    "latent_dim = 2\n",
    "intermediate_dim = 256\n",
    "nb_epoch = 50\n",
    "epsilon_std = 1.0\n",
    "\n",
    "x = Input(batch_shape=(batch_size, original_dim))\n",
    "h = Dense(intermediate_dim, activation='relu')(x)\n",
    "z_mean = Dense(latent_dim)(h)\n",
    "z_log_var = Dense(latent_dim)(h)\n",
    "\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(batch_size, latent_dim), mean=0.,\n",
    "                              std=epsilon_std)\n",
    "    return z_mean + K.exp(z_log_var / 2) * epsilon\n",
    "\n",
    "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
    "\n",
    "# we instantiate these layers separately so as to reuse them later\n",
    "decoder_h = Dense(intermediate_dim, activation='relu')\n",
    "decoder_mean = Dense(original_dim, activation='sigmoid')\n",
    "h_decoded = decoder_h(z)\n",
    "x_decoded_mean = decoder_mean(h_decoded)\n",
    "\n",
    "\n",
    "def vae_loss(x, x_decoded_mean):\n",
    "    xent_loss = original_dim * objectives.binary_crossentropy(x, x_decoded_mean)\n",
    "    kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "    return xent_loss + kl_loss\n",
    "\n",
    "vae = Model(x, x_decoded_mean)\n",
    "vae.compile(optimizer='rmsprop', loss=vae_loss)\n",
    "\n",
    "# train the VAE on MNIST digits\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "\n",
    "vae.fit(x_train, x_train,\n",
    "        shuffle=True,\n",
    "        nb_epoch=nb_epoch,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_test, x_test))\n",
    "\n",
    "# build a model to project inputs on the latent space\n",
    "encoder = Model(x, z_mean)\n",
    "\n",
    "# display a 2D plot of the digit classes in the latent space\n",
    "x_test_encoded = encoder.predict(x_test, batch_size=batch_size)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], c=y_test)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# build a digit generator that can sample from the learned distribution\n",
    "decoder_input = Input(shape=(latent_dim,))\n",
    "_h_decoded = decoder_h(decoder_input)\n",
    "_x_decoded_mean = decoder_mean(_h_decoded)\n",
    "generator = Model(decoder_input, _x_decoded_mean)\n",
    "\n",
    "# display a 2D manifold of the digits\n",
    "n = 15  # figure with 15x15 digits\n",
    "digit_size = 28\n",
    "figure = np.zeros((digit_size * n, digit_size * n))\n",
    "# linearly spaced coordinates on the unit square were transformed through the inverse CDF (ppf) of the Gaussian\n",
    "# to produce values of the latent variables z, since the prior of the latent space is Gaussian\n",
    "grid_x = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "grid_y = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "\n",
    "for i, yi in enumerate(grid_x):\n",
    "    for j, xi in enumerate(grid_y):\n",
    "        z_sample = np.array([[xi, yi]])\n",
    "        x_decoded = generator.predict(z_sample)\n",
    "        digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "        figure[i * digit_size: (i + 1) * digit_size,\n",
    "               j * digit_size: (j + 1) * digit_size] = digit\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(figure, cmap='Greys_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'finish'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
