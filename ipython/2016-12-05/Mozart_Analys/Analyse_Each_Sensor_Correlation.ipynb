{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "幅広くデータを見ていく\n",
    "* 加速度の波形を並べていみる\n",
    "* ウィンドウフレームごとの平均，分散の変化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 表示用\n",
    "from tqdm import tqdm\n",
    "from tqdm import tnrange, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import zeros, newaxis\n",
    "import datetime\n",
    "import os\n",
    "import copy\n",
    "import time\n",
    "\n",
    "# Parametor about Sensor\n",
    "SensorNum=1 # Sensor number\n",
    "#SensorAxis='AccX' # Axis\n",
    "\n",
    "# Parametor about  \" Sliding Window \" \n",
    "WindowWidth =np.array([128,256,512,1024,2048,4096]) # Window Width\n",
    "SlidingWidth =WindowWidth/4 #sliding window\n",
    "\n",
    "# Parametor about Neural Network\n",
    "AEDimention = 16\n",
    "\n",
    "# Define Data Name\n",
    "DATE= str( datetime.date.today() )+'/'\n",
    "TITLE=\"Participants01_First_1/\"\n",
    "\n",
    "# Parametor about \" Data Path\"\n",
    "DataPath = \"/media/takeyama/Transfer/02_ActivityResearch/Paticipants01/01_First/20161018-105301/mem/\"\n",
    "\n",
    "#chopin\n",
    "#StorePath = \"/home/takeyama/Documents/\"\n",
    "#mozart\n",
    "StorePath =\"/media/takeyama/HD-PNFU3/01_ActivityResearchData/\"\n",
    "if not os.path.exists(StorePath+TITLE+'dictionary/'): \n",
    "    os.makedirs(StorePath+TITLE+'dictionary/')\n",
    "DictionaryDataPath=StorePath+TITLE+'dictionary/'\n",
    "\n",
    "if not os.path.exists(StorePath+TITLE+'window/'): \n",
    "    os.makedirs(StorePath+TITLE+'window/')\n",
    "WindowDataPath=StorePath+TITLE+'window/'\n",
    "\n",
    "if not os.path.exists(StorePath+TITLE+DATE+'studyOutput/'): \n",
    "    os.makedirs(StorePath+TITLE+DATE+'studyOutput/')\n",
    "StudyOutputPath=StorePath+TITLE+DATE+'studyOutput/'\n",
    "\n",
    "if not os.path.exists(StorePath+TITLE+DATE+'parametor/'): \n",
    "    os.makedirs(StorePath+TITLE+DATE+'parametor/')\n",
    "ParametorPath=StorePath+TITLE+DATE+'parametor/'\n",
    "\n",
    "if not os.path.exists(StorePath+TITLE+DATE+'result/'): \n",
    "    os.makedirs(StorePath+TITLE+DATE+'result/')\n",
    "ResultPath=StorePath+TITLE+DATE+'result/'\n",
    "\n",
    "if not os.path.exists(StorePath+'/'+TITLE+DATE+'graph/'): \n",
    "    os.makedirs(StorePath+'/'+TITLE+DATE+'graph/')\n",
    "GraphPath=StorePath+'/'+TITLE+DATE+'graph/'\n",
    "\n",
    "if not os.path.exists(StorePath+'/'+TITLE+DATE+'graph/corrMap/'): \n",
    "    os.makedirs(StorePath+'/'+TITLE+DATE+'graph/corrMap/')\n",
    "CorrMapGraphPath=StorePath+'/'+TITLE+DATE+'graph/corrMap/'\n",
    "\n",
    "if not os.path.exists(StorePath+'/'+TITLE+'feature/'): \n",
    "    os.makedirs(StorePath+'/'+TITLE+'feature/')\n",
    "FeaturePath=StorePath+'/'+TITLE+'feature/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "センサデータの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# センサデータのcsvファイル名をリストに集約する関数\n",
    "def SensorDataFileNameList(path):\n",
    "    l = os.listdir(DataPath)\n",
    "    FilePath =[]\n",
    "    SensorName = []\n",
    "    \n",
    "    for n in range(len(l)):\n",
    "        if (l[n][:4].find('mem-') != -1):\n",
    "            FilePath.append(l[n])\n",
    "            SensorName.append(l[n][4:15])\n",
    "    \n",
    "    return FilePath,SensorName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSVを読み込んで，CSVの中身を辞書型で表現する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# FFT library\n",
    "from scipy import fftpack\n",
    "from scipy import signal\n",
    "\n",
    "# Graph Plot\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "\n",
    "# Generate WindowFrame Function\n",
    "from mymodule import window\n",
    "\n",
    "# timer\n",
    "import time\n",
    "\n",
    "# temp file \n",
    "import tempfile\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Chest.npz', 'LeftHand.npz', 'LeftLeg.npz', 'RightHand.npz', 'Rightleg.npz', 'West.npz']\n"
     ]
    }
   ],
   "source": [
    "DictName = os.listdir(DictionaryDataPath)\n",
    "print DictName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Sensor5 = np.load(DictionaryDataPath+DictName[0])['data'][()]\n",
    "Sensor1 = np.load(DictionaryDataPath+DictName[1])['data'][()]\n",
    "Sensor3 = np.load(DictionaryDataPath+DictName[2])['data'][()]\n",
    "Sensor2 = np.load(DictionaryDataPath+DictName[3])['data'][()]\n",
    "Sensor4 = np.load(DictionaryDataPath+DictName[4])['data'][()]\n",
    "Sensor6 = np.load(DictionaryDataPath+DictName[5])['data'][()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def GetWindowFrame(windowName, dataRaw, wWidth, sWidth, PATH):\n",
    "    \"\"\"\n",
    "    data　ウィンドウフレームに変換するデータ\n",
    "    registName　ウィンドウフレームに登録するデータの名前\n",
    "    windowWidth　ウィンドウ幅\n",
    "    slidingWidth　スライド幅\n",
    "    PATH ウィドウフレームを保存するディレクトリ\n",
    "    \n",
    "    \n",
    "    About Function:\n",
    "        与えられたdataからウィンドウ幅windowWidth,スライド幅slidingWidthにしたがって\n",
    "        registNameのウィドウフレームを返す．\n",
    "        また，与えれたPATH内に同様なパラメータ( WindowWidth, slidingWidth)かつ同様な\n",
    "        windowNameのものがある場合，そのデータを返す．\n",
    "        この関数が登録，ウィンドウフレームに変換できるデータは１つとする\n",
    "    \"\"\"\n",
    "    storedName = windowName+'_Win='+str(wWidth).zfill(4)+'_Sld='+str(sWidth).zfill(4)+'.npz'\n",
    "    l = os.listdir(PATH)\n",
    "    \n",
    "    if storedName in l:\n",
    "        print \"this data had finished making\"\n",
    "        return np.load(PATH+storedName)['data'][()]\n",
    "    \n",
    "    w=window()\n",
    "    w.SetData(windowName,dataRaw)    \n",
    "    wind=w.Compile(wWidth,sWidth)\n",
    "    windoW=wind.reshape((len(wind),np.prod(wind.shape[1:])))\n",
    "    \n",
    "    np.savez(PATH+storedName,data=wind)\n",
    "\n",
    "    return wind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methematical/Statistical Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean, Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FastVector_Mean(windowName, dataRaw, wWidth, sWidth, PATH):\n",
    "    # get windowFrame\n",
    "    wind=GetWindowFrame(windowName, dataRaw, wWidth, sWidth, PATH)\n",
    "    Output = np.array( [wind[i,:].mean() for i in range(wind.shape[0]) ] )\n",
    "    print '===========finished Making Vector of Mean==========='\n",
    "    return Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FastVector_Median(windowName, dataRaw, wWidth, sWidth, PATH):\n",
    "    # get windowFrame\n",
    "    wind=GetWindowFrame(windowName, dataRaw, wWidth, sWidth, PATH)\n",
    "    Output = np.array( [np.median(wind[i,:]) for i in range(wind.shape[0]) ] )\n",
    "    print '===========finished Making Vector of Median==========='\n",
    "    return Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance, Std Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FastVector_Var(windowName, dataRaw, wWidth, sWidth, PATH):\n",
    "    # get windowFrame\n",
    "    wind=GetWindowFrame(windowName, dataRaw, wWidth, sWidth, PATH)\n",
    "    Output = np.array( [wind[i,:].var() for i in range(wind.shape[0]) ] )\n",
    "    print '===========finished Making Vector of Variance==========='\n",
    "    return Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FastVector_StdDev(windowName, dataRaw, wWidth, sWidth, PATH):\n",
    "    # get windowFrame\n",
    "    wind=GetWindowFrame(windowName, dataRaw, wWidth, sWidth, PATH)  \n",
    "    Output = np.array( [wind[i,:].var()**0.5 for i in range(wind.shape[0]) ] )\n",
    "    print '===========finished Making Vector of standard Deviation==========='\n",
    "    return Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Min, Max, Range\n",
    "Range = the difference between maximum and minimum sample values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FastVector_Max(windowName, dataRaw, wWidth, sWidth, PATH):\n",
    "    # get windowFrame\n",
    "    wind=GetWindowFrame(windowName, dataRaw, wWidth, sWidth, PATH)\n",
    "    Output = np.array( [wind[i,:].max() for i in range(wind.shape[0]) ] )\n",
    "    print '===========finished Making Vector of Max==========='\n",
    "    return Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def FastVector_Min(windowName, dataRaw, wWidth, sWidth, PATH):\n",
    "    # get windowFrame\n",
    "    wind=GetWindowFrame(windowName, dataRaw, wWidth, sWidth, PATH)\n",
    "    Output = np.array( [wind[i,:].min() for i in range(wind.shape[0]) ] )\n",
    "    print '===========finished Making Vector of Min==========='\n",
    "    return Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def FastVector_Range(windowName, dataRaw, wWidth, sWidth, PATH):\n",
    "    # get windowFrame\n",
    "    wind=GetWindowFrame(windowName, dataRaw, wWidth, sWidth, PATH)\n",
    "    Output = np.array( [(wind[i,:].max()-wind[i,:].min())\\\n",
    "                        for i in range(wind.shape[0]) ] )\n",
    "    print '===========finished Making Vector of Range==========='\n",
    "    return Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FastVector_RMS(windowName, dataRaw, wWidth, sWidth, PATH):\n",
    "    # get windowFrame\n",
    "    wind=GetWindowFrame(windowName, dataRaw, wWidth, sWidth, PATH)\n",
    "    Output = np.array( [((np.sum( wind[i,:]**2)/wind[i,:].size)**0.5)\\\n",
    "                        for i in range(wind.shape[0]) ] )\n",
    "    print '===========finished Making Vector of Root Means Square==========='\n",
    "    return Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation, Cross-Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def FastVector_Corr(windowNameX, dataRawX, windowNameY, dataRawY, wWidth, sWidth, PATH):\n",
    "    # get windowFrame\n",
    "    windX=GetWindowFrame(windowNameX, dataRawX, wWidth, sWidth, PATH)\n",
    "    windY=GetWindowFrame(windowNameY, dataRawY, wWidth, sWidth, PATH)\n",
    "    Output = np.array( [( np.corrcoef(windX[i,:],windY[i,:]) )\\\n",
    "                    for i in range(windX.shape[0]) ] )\n",
    "    print '===========finished Making Vector of Correlation==========='\n",
    "    return Output[:,0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Signal magnitude area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FastVector_SMA(windowName, dataRawX, dataRawY, dataRawZ, wWidth, sWidth, PATH):\n",
    "    # get windowFrame\n",
    "    windX=GetWindowFrame(windowName, dataRawX, wWidth, sWidth, PATH)\n",
    "    windY=GetWindowFrame(windowName, dataRawY, wWidth, sWidth, PATH)\n",
    "    windZ=GetWindowFrame(windowName, dataRawZ, wWidth, sWidth, PATH)\n",
    "    Output = np.array( [(np.sum((windX[i,:]**2+windY[i,:]**2+windZ[i,:]**2)**0.5))\\\n",
    "                for i in range(windX.shape[0]) ] )\n",
    "    print '===========finished Making Vector of Signal Magnitude Area==========='\n",
    "    return Output  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 各センサの相関を求める"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 1077870)\n"
     ]
    }
   ],
   "source": [
    "DataList = np.array( [x[n]\\\n",
    "            for x in [Sensor1,Sensor2,Sensor3,Sensor4,Sensor5,Sensor5]\\\n",
    "            for n in ['AccX','AccY','AccZ']])\n",
    "print DataList.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NameArray = np.array([\n",
    "         (x['Name'], y['Name']) for x in [Sensor1,Sensor2,Sensor3,Sensor4,Sensor5,Sensor6] \\\n",
    "        for y in [Sensor1,Sensor2,Sensor3,Sensor4,Sensor5,Sensor6]\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['LeftHand', 'LeftHand'],\n",
       "       ['LeftHand', 'RightHand'],\n",
       "       ['LeftHand', 'LeftLeg'],\n",
       "       ['LeftHand', 'Rightleg'],\n",
       "       ['LeftHand', 'Chest'],\n",
       "       ['LeftHand', 'West'],\n",
       "       ['RightHand', 'LeftHand'],\n",
       "       ['RightHand', 'RightHand'],\n",
       "       ['RightHand', 'LeftLeg'],\n",
       "       ['RightHand', 'Rightleg'],\n",
       "       ['RightHand', 'Chest'],\n",
       "       ['RightHand', 'West'],\n",
       "       ['LeftLeg', 'LeftHand'],\n",
       "       ['LeftLeg', 'RightHand'],\n",
       "       ['LeftLeg', 'LeftLeg'],\n",
       "       ['LeftLeg', 'Rightleg'],\n",
       "       ['LeftLeg', 'Chest'],\n",
       "       ['LeftLeg', 'West'],\n",
       "       ['Rightleg', 'LeftHand'],\n",
       "       ['Rightleg', 'RightHand'],\n",
       "       ['Rightleg', 'LeftLeg'],\n",
       "       ['Rightleg', 'Rightleg'],\n",
       "       ['Rightleg', 'Chest'],\n",
       "       ['Rightleg', 'West'],\n",
       "       ['Chest', 'LeftHand'],\n",
       "       ['Chest', 'RightHand'],\n",
       "       ['Chest', 'LeftLeg'],\n",
       "       ['Chest', 'Rightleg'],\n",
       "       ['Chest', 'Chest'],\n",
       "       ['Chest', 'West'],\n",
       "       ['West', 'LeftHand'],\n",
       "       ['West', 'RightHand'],\n",
       "       ['West', 'LeftLeg'],\n",
       "       ['West', 'Rightleg'],\n",
       "       ['West', 'Chest'],\n",
       "       ['West', 'West']], \n",
       "      dtype='|S9')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NameArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this data had finished making\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(33676, 256)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = GetWindowFrame('AccX', Sensor1['AccX'], 256, 32, WindowDataPath)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this data had finished making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Correlation===========\n",
      "this data had finished making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Correlation===========\n",
      "this data had finished making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Correlation===========\n",
      "this data had finished making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Correlation===========\n",
      "this data had finished making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Correlation===========\n",
      "this data had finished making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Correlation===========\n",
      "this data had finished making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Correlation===========\n",
      "this data had finished making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Correlation===========\n",
      "this data had finished making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Correlation===========\n",
      "this data had finished making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Correlation===========\n",
      "this data had finished making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Correlation===========\n",
      "this data had finished making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Correlation===========\n",
      "this data had finished making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Correlation===========\n",
      "this data had finished making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Correlation===========\n",
      "this data had finished making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Correlation===========\n",
      "this data had finished making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Correlation===========\n",
      "this data had finished making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Correlation===========\n",
      "this data had finished making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Correlation===========\n",
      "this data had finished making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Correlation===========\n",
      "this data had finished making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Correlation===========\n",
      "this data had finished making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Correlation===========\n",
      "this data had finished making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Correlation===========\n",
      "this data had finished making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Correlation===========\n",
      "this data had finished making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Correlation===========\n",
      "this data had finished making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Correlation===========\n",
      "this data had finished making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Correlation===========\n",
      "this data had finished making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Correlation===========\n",
      "this data had finished making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Correlation===========\n",
      "this data had finished making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Correlation===========\n",
      "this data had finished making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Correlation===========\n",
      "this data had finished making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Correlation===========\n",
      "this data had finished making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Correlation===========\n",
      "this data had finished making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Correlation===========\n",
      "this data had finished making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Correlation===========\n",
      "this data had finished making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Correlation===========\n",
      "this data had finished making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Correlation===========\n"
     ]
    }
   ],
   "source": [
    "windowNum = 256\n",
    "slidingNum = 32\n",
    "CorrelatinMapAccX = np.array([\n",
    "         FastVector_Corr(x['Name'], x['AccX'],y['Name'], y['AccX'], \\\n",
    "                         windowNum, slidingNum, WindowDataPath)\n",
    "        for x in [Sensor1,Sensor2,Sensor3,Sensor4,Sensor5,Sensor5]\n",
    "        for y in [Sensor1,Sensor2,Sensor3,Sensor4,Sensor5,Sensor5]\n",
    "    ])\n",
    "\n",
    "np.savez(FeaturePath+'w='+str(windowNum).zfill(4)+'_s='+str(slidingNum).zfill(4)\\\n",
    "         +'_CorrelationMapAccX',data=CorrelatinMapAccX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "CorrelatinMapAccX = CorrelatinMapAccX[:,:,newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36, 33676, 1)\n"
     ]
    }
   ],
   "source": [
    "print CorrelatinMapAccX.shape\n",
    "CorrelatinMapAccX = CorrelatinMapAccX.reshape(6,6,33676)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fil1 = np.array([CorrelatinMapAccX[:,:,i] for i in xrange(0,33676,9)])\n",
    "fil2 = np.array([CorrelatinMapAccX[:,:,i] for i in xrange(1,33676,9)])\n",
    "fil3 = np.array([CorrelatinMapAccX[:,:,i] for i in xrange(2,33676,9)])\n",
    "fil4 = np.array([CorrelatinMapAccX[:,:,i] for i in xrange(3,33676,9)])\n",
    "fil5 = np.array([CorrelatinMapAccX[:,:,i] for i in xrange(4,33676,9)])\n",
    "fil6 = np.array([CorrelatinMapAccX[:,:,i] for i in xrange(5,33676,9)])\n",
    "fil7 = np.array([CorrelatinMapAccX[:,:,i] for i in xrange(6,33676,9)])\n",
    "fil8 = np.array([CorrelatinMapAccX[:,:,i] for i in xrange(7,33676,9)])\n",
    "fil9 = np.array([CorrelatinMapAccX[:,:,i] for i in xrange(8,33676,9)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3742, 6, 6)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fil1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 6)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fil1[0,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f19684ace90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(15, 15))\n",
    "fig = plt.figure()\n",
    "fig.subplots_adjust(bottom = 0)\n",
    "fig.subplots_adjust(top = 1)\n",
    "fig.subplots_adjust(right = 1)\n",
    "fig.subplots_adjust(left = 0)\n",
    "\n",
    "X = xrange(6)\n",
    "Y = xrange(6)\n",
    "\n",
    "for i in tqdm_notebook( xrange(0,fil1.shape[0],9) ):\n",
    "    ax1 = fig.add_subplot(331)\n",
    "    ax1.set_title(str(i))\n",
    "    cax1=ax1.imshow(fil1[i,:,:], interpolation='nearest')\n",
    "\n",
    "    ax2 = fig.add_subplot(332)\n",
    "    ax2.set_title(str(i+1))\n",
    "    cax2=ax2.imshow(fil2[i,:,:], interpolation='nearest')\n",
    "\n",
    "    ax3 = fig.add_subplot(333)\n",
    "    ax3.set_title(str(i+2))\n",
    "    cax3=ax3.imshow(fil3[i,:,:], interpolation='nearest')\n",
    "\n",
    "    ax4 = fig.add_subplot(334)\n",
    "    ax4.set_title(str(i+3))\n",
    "    cax4=ax4.imshow(fil4[i,:,:], interpolation='nearest')\n",
    "\n",
    "    ax5 = fig.add_subplot(335)\n",
    "    ax5.set_title(str(i+4))\n",
    "    cax5=ax5.imshow(fil5[i,:,:], interpolation='nearest')\n",
    "\n",
    "    ax6 = fig.add_subplot(336)\n",
    "    ax6.set_title(str(i+5))\n",
    "    cax6=ax6.imshow(fil6[i,:,:], interpolation='nearest')\n",
    "\n",
    "    ax7 = fig.add_subplot(337)\n",
    "    ax7.set_title(str(i+6))\n",
    "    cax7=ax7.imshow(fil7[i,:,:], interpolation='nearest')\n",
    "\n",
    "    ax8 = fig.add_subplot(338)\n",
    "    ax8.set_title(str(i+7))\n",
    "    cax8=ax8.imshow(fil8[i,:,:], interpolation='nearest')\n",
    "\n",
    "    ax9 = fig.add_subplot(339)\n",
    "    ax9.set_title(str(i+8))\n",
    "    cax9=ax9.imshow(fil9[i,:,:], interpolation='nearest')\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    fig.savefig(CorrMapGraphPath+'_'+str(i).zfill(4)+'_'+str(i+8).zfill(4))\n",
    "    plt.cla()\n",
    "    plt.clf()\n",
    "    plt.close(fig)\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "widgets": {
   "state": {
    "7d2b703c3f5744318e4561e115d01c11": {
     "views": [
      {
       "cell_index": 38
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
