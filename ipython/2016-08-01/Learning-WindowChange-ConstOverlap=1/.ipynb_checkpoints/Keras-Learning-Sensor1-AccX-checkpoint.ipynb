{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SensorNum=1 # Sensor number\n",
    "WindowWidth=[16,32,64,128,256,512,1024] # Window Width\n",
    "OverlapArray=[1,1,1,1,1,1,1] # sliding window\n",
    "width=1000 # graph width \n",
    "EncodingDim=[4,8,12,16,32,64] # number of hidden layer note\n",
    "Axis='AccX' # Axis\n",
    "\n",
    "WORKSPACE_PATH = \"/media/takeyama/HD-PZU3/01_TAKEYAMA_WORKSPACE/02_CommonData/2016-07-25\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import fftpack\n",
    "from scipy import signal\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import pickle\n",
    "import copy\n",
    "\n",
    "import processing\n",
    "import window\n",
    "\n",
    "import matplotlib.animation as animation\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 1080 (CNMeM is disabled, cuDNN 5005)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.datasets import cifar10\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.utils.visualize_util import model_to_dot, plot\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import matplotlib.image as mpimg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DataName='sensor'+str(SensorNum)+'_'+Axis\n",
    "SensorName='sensor'+str(SensorNum)\n",
    "DicName='MemSensor'+str(SensorNum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(WORKSPACE_PATH+'/study/'+DataName+'/'): os.makedirs(WORKSPACE_PATH+'/study/'+DataName+'/')\n",
    "StudyDataPath=WORKSPACE_PATH+'/study/'+DataName+'/'\n",
    "\n",
    "if not os.path.exists(WORKSPACE_PATH+'/graph/'+DataName+'/loss/'): os.makedirs(WORKSPACE_PATH+'/graph/'+DataName+'/loss/')\n",
    "GlaphDataPath=WORKSPACE_PATH+'/graph/'+DataName+'/loss/'\n",
    "\n",
    "if not os.path.exists(WORKSPACE_PATH+'/graph/'+DataName+'/Time'): os.makedirs(WORKSPACE_PATH+'/graph/'+DataName+'/Time')\n",
    "GlaphDataTimePath=WORKSPACE_PATH+'/graph/'+DataName+'/Time'\n",
    "\n",
    "if not os.path.exists(WORKSPACE_PATH+'/modelPic/'+DataName+'/'): os.makedirs(WORKSPACE_PATH+'/modelPic/'+DataName+'/')\n",
    "StudyDataModelPicPath=WORKSPACE_PATH+'/modelPic/'+DataName+'/'\n",
    "\n",
    "if not os.path.exists(WORKSPACE_PATH+'/window/'+DataName+'/'): os.makedirs(WORKSPACE_PATH+'/window/'+DataName+'/')\n",
    "WindowDataPath=WORKSPACE_PATH+'/window/'+DataName+'/'\n",
    "\n",
    "RawDataPath=\"/media/takeyama/HD-PZU3/01_TAKEYAMA_WORKSPACE/02_CommonData/raw/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Phase1 計測データの取得**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dic=processing.LoadDicDataFromFileNPZ(RawDataPath+DicName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Phase2 window flame 作成 & Learning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AccY is registed now\n",
      "Build Complete\n",
      "(254742,)\n",
      "windowData's num =63682\n",
      "SourceData's aborting data = 2\n"
     ]
    }
   ],
   "source": [
    "# loop windowWidth\n",
    "for SampleNum,Overlap in zip(WindowWidth,OverlapArray):\n",
    "    w=window.Window()\n",
    "    w.SetData(Axis,dic[Axis])\n",
    "    wind=w.Compile(windowWidth=SampleNum,overlapNum=Overlap)\n",
    "    windoW=wind.reshape((len(wind),np.prod(wind.shape[1:])))\n",
    "    \n",
    "    # define SaveFileName\n",
    "    for encoding_dim in EncodingDim:\n",
    "        print \"hiden node = \"+str(encoding_dim)\n",
    "        SaveFileNameEncord=DataName+'_encoded'+'_edim='+str(encoding_dim)+'-Window='+str(SampleNum)+'-Overlap='+str(Overlap*100)\n",
    "        SaveFileNameDecord=DataName+'_decoded'+'_edim='+str(encoding_dim)+'-Window='+str(SampleNum)+'-Overlap='+str(Overlap*100)\n",
    "        SaveFileNameNet=DataName+'_net'+'_edim='+str(encoding_dim)+'-Window='+str(SampleNum)+'-Overlap='+str(Overlap*100)\n",
    "        SaveFileNameTrain=DataName+'_train'+'_edim='+str(encoding_dim)+'-Window='+str(SampleNum)+'-Overlap='+str(Overlap*100)\n",
    "        SaveFileNameTest=DataName+'_test'+'_edim='+str(encoding_dim)+'-Window='+str(SampleNum)+'-Overlap='+str(Overlap*100)\n",
    "        SaveFileNameGlaph=GlaphDataPath+DataName+'_edim='+str(encoding_dim)+'-Window='+str(SampleNum)+'-Overlap='+str(Overlap*100)+'_loss_val_loss.png'\n",
    "\n",
    "        window_test=windoW\n",
    "        window_train=windoW\n",
    "        processing.SaveDicDataFromFileNPZ(WindowDataPath,SaveFileNameTrain,window_test)\n",
    "        processing.SaveDicDataFromFileNPZ(WindowDataPath,SaveFileNameTest,window_test)\n",
    "        shapeNum=windoW.shape[1]\n",
    "\n",
    "        # this is our input placeholder\n",
    "        input_img = Input(shape=(shapeNum,))\n",
    "        # \"encoded\" is the encoded representation of the input\n",
    "        encoded = Dense(encoding_dim, activation='tanh')(input_img)\n",
    "        # \"decoded\" is the lossy reconstruction of the input\n",
    "        decoded = Dense(shapeNum, activation='linear')(encoded)\n",
    "\n",
    "        # this model maps an input to its reconstruction\n",
    "        autoencoder = Model(input=input_img, output=decoded)\n",
    "\n",
    "        # this model maps an input to its encoded representation\n",
    "        encoder = Model(input=input_img, output=encoded)\n",
    "\n",
    "        # create a placeholder for an encoded (32-dimensional) input\n",
    "        encoded_input = Input(shape=(encoding_dim,))\n",
    "        # retrieve the last layer of the autoencoder model\n",
    "        decoder_layer = autoencoder.layers[-1]\n",
    "        # create the decoder model\n",
    "        decoder = Model(input=encoded_input, output=decoder_layer(encoded_input))\n",
    "\n",
    "        autoencoder.compile(optimizer='adadelta', loss='mse')\n",
    "        plot(autoencoder,  to_file=StudyDataModelPicPath+SaveFileNameNet+'.png')\n",
    "\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "        hist = autoencoder.fit(window_train, window_train,\n",
    "                        nb_epoch=50,\n",
    "                        verbose=2,\n",
    "                        batch_size=shapeNum/4,\n",
    "                        shuffle=True,\n",
    "                        validation_data=(window_test, window_test),\n",
    "                        callbacks=[early_stopping])\n",
    "        time.sleep(0.1)\n",
    "        encoded_imgs = encoder.predict(window_test)\n",
    "        decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "        processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameEncord,encoded_imgs)\n",
    "        processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameDecord,decoded_imgs)\n",
    "\n",
    "        # save model and wights\n",
    "        json_string = encoder.to_json()\n",
    "        open(StudyDataPath+SaveFileNameEncord+'.json', 'w').write(json_string)\n",
    "        encoder.save_weights(StudyDataPath+SaveFileNameEncord+'_weights.h5',overwrite=True)\n",
    "\n",
    "        json_string = decoder.to_json()\n",
    "        open(StudyDataPath+SaveFileNameDecord+'.json', 'w').write(json_string)\n",
    "        decoder.save_weights(StudyDataPath+SaveFileNameDecord+'_weights.h5',overwrite=True)\n",
    "\n",
    "        json_string = autoencoder.to_json()\n",
    "        open(StudyDataPath+SaveFileNameNet+'.json', 'w').write(json_string)\n",
    "        autoencoder.save_weights(StudyDataPath+SaveFileNameNet+'_weights.h5',overwrite=True)\n",
    "\n",
    "        # plot loss\n",
    "        loss = hist.history['loss']\n",
    "        val_loss = hist.history['val_loss']\n",
    "\n",
    "        nb_epoch = len(loss)\n",
    "        plt.plot(range(nb_epoch), loss, marker='.', label='loss')\n",
    "        plt.plot(range(nb_epoch), val_loss, marker='.', label='val_loss')\n",
    "        plt.legend(loc='best', fontsize=10)\n",
    "        plt.grid()\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('loss')\n",
    "        plt.savefig(SaveFileNameGlaph)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
