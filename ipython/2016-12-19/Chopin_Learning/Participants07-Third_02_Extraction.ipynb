{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "import copy\n",
    "# Generate WindowFrame Function\n",
    "from mymodule import window\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "# Parametor about Sensor\n",
    "SensorNum=1 # Sensor number\n",
    "#SensorAxis='AccX' # Axis\n",
    "\n",
    "# Define Data Name\n",
    "DATE= str( datetime.date.today() )+'/'\n",
    "\n",
    "# Parametor about \" Data Path\"\n",
    "StorePath = \"/media/takeyama/Transfer/02_ActivityResearch/\"\n",
    "\n",
    "ParticipantsNum=\"Participants07/\"\n",
    "Version = \"03_Third/\"\n",
    "Time = \"02_Second/\"\n",
    "CommonName = 'Participants07-Third-02'\n",
    "LabelName = CommonName+'.csv'\n",
    "\n",
    "TITLE = ParticipantsNum+Version\n",
    "\n",
    "DataPath = StorePath+ParticipantsNum+Version+\"RawData/\"+Time\n",
    "\n",
    "if not os.path.exists(StorePath+TITLE+'LabelData/'+Time): \n",
    "    os.makedirs(StorePath+TITLE+'LabelData/'+Time)\n",
    "LabelDataPath=StorePath+TITLE+'LabelData/'+Time\n",
    "\n",
    "if not os.path.exists(StorePath+TITLE+'dictionary/'+Time): \n",
    "    os.makedirs(StorePath+TITLE+'dictionary/'+Time)\n",
    "DictionaryDataPath=StorePath+TITLE+'dictionary/'+Time\n",
    "\n",
    "if not os.path.exists(StorePath+TITLE+'feature/'+Time): \n",
    "    os.makedirs(StorePath+TITLE+'feature/'+Time)\n",
    "FeaturePath=StorePath+TITLE+'feature/'+Time\n",
    "\n",
    "if not os.path.exists(StorePath+TITLE+'window/'+Time): \n",
    "    os.makedirs(StorePath+TITLE+'window/'+Time)\n",
    "WindowDataPath=StorePath+TITLE+'window/'+Time\n",
    "\n",
    "if not os.path.exists(StorePath+TITLE+DATE+'studyOutput/'+Time): \n",
    "    os.makedirs(StorePath+TITLE+DATE+'studyOutput/'+Time)\n",
    "StudyOutputPath=StorePath+TITLE+DATE+'studyOutput/'+Time\n",
    "\n",
    "if not os.path.exists(StorePath+TITLE+DATE+'parametor/'+Time): \n",
    "    os.makedirs(StorePath+TITLE+DATE+'parametor/'+Time)\n",
    "ParametorPath=StorePath+TITLE+DATE+'parametor/'+Time\n",
    "\n",
    "if not os.path.exists(StorePath+TITLE+DATE+'result/'+Time): \n",
    "    os.makedirs(StorePath+TITLE+DATE+'result/'+Time)\n",
    "ResultPath=StorePath+TITLE+DATE+'result/'+Time\n",
    "\n",
    "if not os.path.exists(StorePath+TITLE+DATE+'graph/'+Time): \n",
    "    os.makedirs(StorePath+TITLE+DATE+'graph/'+Time)\n",
    "GraphPath=StorePath+TITLE+DATE+'graph/'+Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Read SensorData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# センサデータのcsvファイル名をリストに集約する関数\n",
    "def SensorDataFileNameList(path):\n",
    "    l = os.listdir(DataPath)\n",
    "    FilePath =[]\n",
    "    SensorName = []\n",
    "    \n",
    "    for n in range(len(l)):\n",
    "        if (l[n][:4].find('mem-') != -1):\n",
    "            FilePath.append(l[n])\n",
    "            SensorName.append(l[n][4:15])\n",
    "    \n",
    "    return FilePath,SensorName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FFT library\n",
    "from scipy import fftpack\n",
    "from scipy import signal\n",
    "\n",
    "# Graph Plot\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "\n",
    "# Generate WindowFrame Function\n",
    "from mymodule import window\n",
    "\n",
    "# timer\n",
    "import time\n",
    "\n",
    "# temp file \n",
    "import tempfile\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['01_LeftHand.npz', '02_RightHand.npz', '03_LeftLeg.npz', '04_Rightleg.npz', '05_West.npz', '06_Chest.npz', '07_LabelData.npz']\n"
     ]
    }
   ],
   "source": [
    "DictName = os.listdir(DictionaryDataPath)\n",
    "print DictName\n",
    "Sensor1 = np.load(DictionaryDataPath+DictName[0])['data'][()]\n",
    "Sensor2 = np.load(DictionaryDataPath+DictName[1])['data'][()]\n",
    "Sensor3 = np.load(DictionaryDataPath+DictName[2])['data'][()]\n",
    "Sensor4 = np.load(DictionaryDataPath+DictName[3])['data'][()]\n",
    "Sensor5 = np.load(DictionaryDataPath+DictName[4])['data'][()]\n",
    "Sensor6 = np.load(DictionaryDataPath+DictName[5])['data'][()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetWindowFrame(windowName, dataRaw, wWidth, sWidth, PATH):\n",
    "    \"\"\"\n",
    "    data　ウィンドウフレームに変換するデータ\n",
    "    registName　ウィンドウフレームに登録するデータの名前\n",
    "    windowWidth　ウィンドウ幅\n",
    "    slidingWidth　スライド幅\n",
    "    PATH ウィドウフレームを保存するディレクトリ\n",
    "    \n",
    "    \n",
    "    About Function:\n",
    "        与えられたdataからウィンドウ幅windowWidth,スライド幅slidingWidthにしたがって\n",
    "        registNameのウィドウフレームを返す．\n",
    "        また，与えれたPATH内に同様なパラメータ( WindowWidth, slidingWidth)かつ同様な\n",
    "        windowNameのものがある場合，そのデータを返す．\n",
    "        この関数が登録，ウィンドウフレームに変換できるデータは１つとする\n",
    "    \"\"\"\n",
    "    storedName = windowName+'_Win='+str(wWidth).zfill(4)+'_Sld='+str(sWidth).zfill(4)+'.npz'\n",
    "    l = os.listdir(PATH)\n",
    "    \n",
    "    if storedName in l:\n",
    "        print \"this data had finished making\"\n",
    "        return np.load(PATH+storedName)['data'][()]\n",
    "    \n",
    "    w=window()\n",
    "    w.SetData(windowName,dataRaw)    \n",
    "    wind=w.Compile(wWidth,sWidth)\n",
    "    windoW=wind.reshape((len(wind),np.prod(wind.shape[1:])))\n",
    "    \n",
    "    np.savez(PATH+storedName,data=wind)\n",
    "\n",
    "    return wind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Extraction Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequency Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Vector_FFT_Image(windowName, dataRaw, wWidth, sWidth, PATH):\n",
    "    # get windowFrame\n",
    "    try:\n",
    "        Image = joblib.load(FeaturePath+windowName+'_Image.dump')\n",
    "    except:\n",
    "        print \"Now making\"\n",
    "        wind=GetWindowFrame(windowName, dataRaw, wWidth, sWidth, PATH)\n",
    "\n",
    "        fftwind = np.fft.fft(wind)  # calcurate fast fourier Transfromation\n",
    "        fftwind = fftwind[:,1:fftwind.shape[1]/2-1] # Orthogonal and Colossus removed\n",
    "\n",
    "\n",
    "        # windowFrame(raw wave) 2d -> windowFrame(power) 1d\n",
    "        Image=np.array([ np.imag(fftwind[i,l])\n",
    "                for i in range( fftwind.shape[0] )\n",
    "                for l in range( fftwind.shape[1] ) ])\n",
    "        Image = Image.reshape(fftwind.shape)    \n",
    "        # calcurate Squared Energy\n",
    "        \n",
    "    print '===========finished Making Vector of FFT Image==========='\n",
    "    return Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Vector_FFT_Real(windowName, dataRaw, wWidth, sWidth, PATH):\n",
    "    # get windowFrame\n",
    "    try:\n",
    "        Real = joblib.load(FeaturePath+windowName+'_Real.dump')\n",
    "    except:\n",
    "        print \"Now making\"\n",
    "        wind=GetWindowFrame(windowName, dataRaw, wWidth, sWidth, PATH)\n",
    "\n",
    "        fftwind = np.fft.fft(wind)  # calcurate fast fourier Transfromation\n",
    "        fftwind = fftwind[:,1:fftwind.shape[1]/2-1] # Orthogonal and Colossus removed\n",
    "\n",
    "\n",
    "        # windowFrame(raw wave) 2d -> windowFrame(power) 1d\n",
    "        Real=np.array([ np.real(fftwind[i,l])\n",
    "                for i in range( fftwind.shape[0] )\n",
    "                for l in range( fftwind.shape[1] ) ])\n",
    "        Real = Real.reshape(fftwind.shape)    \n",
    "    # calcurate Squared Energy\n",
    "    print '===========finished Making Vector of FFT Real==========='\n",
    "    return Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Vector_Power(windowName, dataRaw, wWidth, sWidth, PATH):\n",
    "    # get windowFrame\n",
    "    try:\n",
    "        SqrF = joblib.load(FeaturePath+windowName+'_Power.dump')\n",
    "    except:\n",
    "        print \"Now making\"\n",
    "        wind=GetWindowFrame(windowName, dataRaw, wWidth, sWidth, PATH)\n",
    "\n",
    "        fftwind = np.fft.fft(wind)  # calcurate fast fourier Transfromation\n",
    "        fftwind = fftwind[:,1:fftwind.shape[1]/2-1] # Orthogonal and Colossus removed\n",
    "\n",
    "        # windowFrame(raw wave) 2d -> windowFrame(power) 1d\n",
    "        SqrF=np.array([\n",
    "                np.real(fftwind[i,l])**2+np.imag(fftwind[i,l])**2\n",
    "                for i in range( fftwind.shape[0] )\n",
    "                for l in range( fftwind.shape[1] )\n",
    "            ])\n",
    "        SqrF = SqrF.reshape(fftwind.shape) \n",
    "        \n",
    "    print '===========finished Making Vector of Energy==========='\n",
    "    return SqrF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Vector_Energy(windowName, dataRaw, wWidth, sWidth, PATH):\n",
    "    # get windowFrame\n",
    "    try:\n",
    "        RootNormSumSqrF = joblib.load(FeaturePath+windowName+'_Energy.dump')\n",
    "    except:\n",
    "        print \"Now making\"\n",
    "        wind=GetWindowFrame(windowName, dataRaw, wWidth, sWidth, PATH)\n",
    "\n",
    "        fftwind = np.fft.fft(wind)  # calcurate fast fourier Transfromation\n",
    "        fftwind = fftwind[:,1:fftwind.shape[1]/2-1] # Orthogonal and Colossus removed\n",
    "\n",
    "        # windowFrame(raw wave) 2d -> windowFrame(power) 1d\n",
    "        SqrF=np.array([\n",
    "                np.real(fftwind[i,l])**2+np.imag(fftwind[i,l])**2\n",
    "                for i in range( fftwind.shape[0] )\n",
    "                for l in range( fftwind.shape[1] )\n",
    "            ])\n",
    "        SqrF = SqrF.reshape(fftwind.shape) \n",
    "\n",
    "        # Sum each window frame\n",
    "        SumSrqF = np.array([SqrF[i,:].sum() for i in range( SqrF.shape[0])])\n",
    "\n",
    "        # normarise\n",
    "        NormSumSqrF = np.array([SumSrqF[i]/(fftwind.shape[1]/2-1)\n",
    "                               for i in range(SumSrqF.shape[0])])\n",
    "\n",
    "        # root\n",
    "        RootNormSumSqrF = NormSumSqrF**0.5\n",
    "\n",
    "    print '===========finished Making Vector of Energy==========='\n",
    "    return RootNormSumSqrF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Vector_Frequency(windowName, dataRaw, wWidth, sWidth, PATH):\n",
    "    # get windowFrame\n",
    "    try:\n",
    "        freq = joblib.load(FeaturePath+windowName+'_Frequency.dump')\n",
    "    except:\n",
    "        print \"Now making\"\n",
    "        wind=GetWindowFrame(windowName, dataRaw, wWidth, sWidth, PATH)\n",
    "        print wind.shape\n",
    "\n",
    "        fftwind = np.fft.fft(wind)  # calcurate fast fourier Transfromation\n",
    "        print fftwind.shape\n",
    "\n",
    "        fftwind = fftwind[:,1:fftwind.shape[1]/2-1] # Orthogonal and Colossus removed\n",
    "        print fftwind.shape\n",
    "        freq = np.array([np.arctan2(np.imag(fftwind[i,l]),np.real(fftwind[i,l]))\n",
    "                         for i in range( fftwind.shape[0] ) \n",
    "                         for l in range( fftwind.shape[1] ) ])\n",
    "        freq = freq.reshape(fftwind.shape)\n",
    "    print '===========finished Making Vector of Frequency==========='\n",
    "    return freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Vector_Entropy(windowName, dataRaw, wWidth, sWidth, PATH):\n",
    "    # get windowFrame\n",
    "    try:\n",
    "        Entropy = joblib.load(FeaturePath+windowName+'_Entropy.dump')\n",
    "    except:\n",
    "        print \"Now making\"\n",
    "        wind=GetWindowFrame(windowName, dataRaw, wWidth, sWidth, PATH)\n",
    "\n",
    "        ###########################\n",
    "        ###    calcurate FFT    ###\n",
    "        ###########################\n",
    "        fftwind = np.fft.fft(wind)  # calcurate fast fourier Transfromation\n",
    "        fftwind = fftwind[:,1:fftwind.shape[1]/2-1] # Orthogonal and Colossus removed\n",
    "\n",
    "        # calcurate eq\n",
    "        f = lambda x: np.real(x)**2+np.imag(x)**2\n",
    "\n",
    "        # windowFrame(raw wave) 2d -> windowFrame(power) 1d\n",
    "        SqrF=np.array([\n",
    "                np.real(fftwind[i,l])**2+np.imag(fftwind[i,l])**2\n",
    "                for i in range( fftwind.shape[0] )\n",
    "                for l in range( fftwind.shape[1] )\n",
    "            ])\n",
    "        SqrF = SqrF.reshape(fftwind.shape)\n",
    "\n",
    "        # calcurate Squared Energy\n",
    "        SqrF=SqrF/SqrF[0,:].size\n",
    "        print SqrF.shape\n",
    "\n",
    "        ##############################\n",
    "        ###    calcurate Entropy   ###\n",
    "        ##############################\n",
    "        P = np.array([SqrF[i]/SqrF[i,:].sum() for i in range(SqrF.shape[0])])\n",
    "        print P.shape\n",
    "        P = P.reshape(SqrF.shape)\n",
    "\n",
    "        P_logP = np.array([ P[i,l]*np.log(P[i,l]) \\\n",
    "                          for i in range(P.shape[0]) for l in range(P.shape[1])])\n",
    "        print P_logP.shape\n",
    "        P_logP = P_logP.reshape(P.shape)\n",
    "\n",
    "        Entropy = np.array([\n",
    "                -1*np.sum( P_logP[i,:] ) for i in range(P.shape[0])])\n",
    "    print '===========finished Making Vector of Entropy==========='\n",
    "    return Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Vector_KLD(windowNameX, dataX, windowNameY, dataY, wWidth, sWidth, PATH):\n",
    "    \"\"\"\n",
    "        Calculates Kullback–Leibler divergence\n",
    "        input dataX dataY -> 1d Vector\n",
    "    \"\"\"\n",
    "    FileNameTemp = windowNameX.split(\"-win\")[0]+windowNameY.split(CommonName+'-')[1]\n",
    "    try:\n",
    "        KLD = joblib.load(FeaturePath+FileNameTemp+'_KLD.dump')\n",
    "    except:\n",
    "        print \"Now making\"\n",
    "        PowerX=  Vector_Power(windowNameX, dataX, wWidth, sWidth, PATH)\n",
    "        PowerY=  Vector_Power(windowNameY, dataY, wWidth, sWidth, PATH)\n",
    "        \n",
    "        p = np.array([PowerX[i,:]/np.sum(PowerX[i,:]) for i in range(PowerX.shape[0])])\n",
    "        q = np.array([PowerY[i,:]/np.sum(PowerY[i,:]) for i in range(PowerY.shape[0])])\n",
    "        \n",
    "        print p\n",
    "        print q\n",
    "        \n",
    "        KLD = np.array([ np.sum(np.where(p[i,:] != 0,(p[i,:]) * np.log10(p[i,:] / q[i,:]), 0))\\\n",
    "                        for i in range(p.shape[0])])\n",
    "    print '===========finished Making Vector of KLD==========='\n",
    "    return KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Vector_JSD(windowNameX, dataX, windowNameY, dataY, wWidth, sWidth, PATH):\n",
    "    FileNameTemp = windowNameX.split(\"-win\")[0]+windowNameY.split(CommonName+'-')[1]\n",
    "    try:\n",
    "        JSD = joblib.load(FeaturePath+FileNameTemp+'_JSD.dump')\n",
    "    except:\n",
    "        print \"Now making\"\n",
    "        PowerX=  Vector_Power(windowNameX, dataX, wWidth, sWidth, PATH)\n",
    "        PowerY=  Vector_Power(windowNameY, dataY, wWidth, sWidth, PATH)\n",
    "        \n",
    "        p = np.array([PowerX[i,:]/np.sum(PowerX[i,:]) for i in range(PowerX.shape[0])])\n",
    "        q = np.array([PowerY[i,:]/np.sum(PowerY[i,:]) for i in range(PowerY.shape[0])])\n",
    "        \n",
    "        func_kld =lambda p,q: np.sum(p * np.log(p / q))\n",
    "        func_jsd =lambda p,q: 0.5 * func_kld(p, (p+q)/2) + 0.5 * func_kld(q, (p+q)/2)\n",
    "\n",
    "        JSD = np.array([ func_jsd(p[i,:],q[i,:])\\\n",
    "                        for i in range(p.shape[0])])\n",
    "    print '===========finished Making Vector of JSD==========='\n",
    "    return JSD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methematical/Statistical Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Vector_Mean(windowName, dataRaw, wWidth, sWidth, PATH):\n",
    "    # get windowFrame\n",
    "    try:\n",
    "        Output = joblib.load(FeaturePath+FileNameTemp+'_Mean.dump')\n",
    "    except:\n",
    "        print \"Now making\"\n",
    "        wind=GetWindowFrame(windowName, dataRaw, wWidth, sWidth, PATH)\n",
    "        Output = np.array( [wind[i,:].mean() for i in range(wind.shape[0]) ] )\n",
    "    print '===========finished Making Vector of Mean==========='\n",
    "    return Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Vector_Median(windowName, dataRaw, wWidth, sWidth, PATH):\n",
    "    # get windowFrame\n",
    "    try:\n",
    "        Output = joblib.load(FeaturePath+FileNameTemp+'_Median.dump')\n",
    "    except:\n",
    "        print \"Now making\"\n",
    "        wind=GetWindowFrame(windowName, dataRaw, wWidth, sWidth, PATH)\n",
    "        Output = np.array( [np.median(wind[i,:]) for i in range(wind.shape[0]) ] )\n",
    "    print '===========finished Making Vector of Median==========='\n",
    "    return Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Vector_Var(windowName, dataRaw, wWidth, sWidth, PATH):\n",
    "    # get windowFrame\n",
    "    try:\n",
    "        Output = joblib.load(FeaturePath+FileNameTemp+'_Var.dump')\n",
    "    except:\n",
    "        print \"Now making\"\n",
    "        wind=GetWindowFrame(windowName, dataRaw, wWidth, sWidth, PATH)\n",
    "        Output = np.array( [wind[i,:].var() for i in range(wind.shape[0]) ] )\n",
    "    print '===========finished Making Vector of Variance==========='\n",
    "    return Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Vector_StdDev(windowName, dataRaw, wWidth, sWidth, PATH):\n",
    "    # get windowFram\n",
    "    try:\n",
    "        Output = joblib.load(FeaturePath+FileNameTemp+'_StdDev.dump')\n",
    "    except:\n",
    "        print \"Now making\"\n",
    "        wind=GetWindowFrame(windowName, dataRaw, wWidth, sWidth, PATH)  \n",
    "        Output = np.array( [wind[i,:].var()**0.5 for i in range(wind.shape[0]) ] )\n",
    "    print '===========finished Making Vector of standard Deviation==========='\n",
    "    return Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Vector_Max(windowName, dataRaw, wWidth, sWidth, PATH):\n",
    "    # get windowFrame\n",
    "    try:\n",
    "        Output = joblib.load(FeaturePath+FileNameTemp+'_Max.dump')\n",
    "    except:\n",
    "        print \"Now making\"\n",
    "        wind=GetWindowFrame(windowName, dataRaw, wWidth, sWidth, PATH)\n",
    "        Output = np.array( [wind[i,:].max() for i in range(wind.shape[0]) ] )\n",
    "    print '===========finished Making Vector of Max==========='\n",
    "    return Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Vector_Min(windowName, dataRaw, wWidth, sWidth, PATH):\n",
    "    # get windowFrame\n",
    "    try:\n",
    "        Output = joblib.load(FeaturePath+FileNameTemp+'_Min.dump')\n",
    "    except:\n",
    "        print \"Now making\"\n",
    "        wind=GetWindowFrame(windowName, dataRaw, wWidth, sWidth, PATH)\n",
    "        Output = np.array( [wind[i,:].min() for i in range(wind.shape[0]) ] )\n",
    "    print '===========finished Making Vector of Max==========='\n",
    "    return Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Vector_Range(windowName, dataRaw, wWidth, sWidth, PATH):\n",
    "    # get windowFrame\n",
    "    try:\n",
    "        Output = joblib.load(FeaturePath+FileNameTemp+'_Range.dump')\n",
    "    except:\n",
    "        print \"Now making\"\n",
    "        wind=GetWindowFrame(windowName, dataRaw, wWidth, sWidth, PATH)\n",
    "        Output = np.array( [(wind[i,:].max()-wind[i,:].min())\\\n",
    "                            for i in range(wind.shape[0]) ] )\n",
    "    print '===========finished Making Vector of Range==========='\n",
    "    return Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Vector_RMS(windowName, dataRaw, wWidth, sWidth, PATH):\n",
    "    # get windowFrame\n",
    "    try:\n",
    "        Output = joblib.load(FeaturePath+FileNameTemp+'_RMS.dump')\n",
    "    except:\n",
    "        print \"Now making\"\n",
    "        wind=GetWindowFrame(windowName, dataRaw, wWidth, sWidth, PATH)\n",
    "        Output = np.array( [( (np.sum( wind[i,:]**2 )/wWidth))**0.5\n",
    "                            for i in range(wind.shape[0]) ] )\n",
    "    print '===========finished Making Vector of RMS==========='\n",
    "    return Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Vector_Corr(windowNameX, dataRawX, windowNameY, dataRawY, wWidth, sWidth, PATH):\n",
    "    # get windowFrame\n",
    "    FileNameTemp = windowNameX.split(\"-win\")[0]+windowNameY.split(CommonName+'-')[1]\n",
    "    try:\n",
    "        Output = joblib.load(FeaturePath+FileNameTemp+'_Corr.dump')\n",
    "    except:\n",
    "        print \"Now making\"\n",
    "        windX=GetWindowFrame(windowNameX, dataRawX, wWidth, sWidth, PATH)\n",
    "        windY=GetWindowFrame(windowNameY, dataRawY, wWidth, sWidth, PATH)\n",
    "        Output = np.array( [( np.corrcoef(windX[i,:],windY[i,:]) )\\\n",
    "                        for i in range(windX.shape[0]) ] )\n",
    "    print '===========finished Making Vector of Correlation==========='\n",
    "    return Output[:,0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Vector_SMA(windowName, dataRawX, dataRawY, dataRawZ, wWidth, sWidth, PATH):\n",
    "    # get windowFrame\n",
    "    FileNameTemp= windowName.split('AccXYZ')[0]\n",
    "    try:\n",
    "        Output = joblib.load(FeaturePath+FileNameTemp+'_SMA.dump')\n",
    "    except:\n",
    "        print \"Now making\"\n",
    "        windX=GetWindowFrame(windowName, dataRawX, wWidth, sWidth, PATH)\n",
    "        windY=GetWindowFrame(windowName, dataRawY, wWidth, sWidth, PATH)\n",
    "        windZ=GetWindowFrame(windowName, dataRawZ, wWidth, sWidth, PATH)\n",
    "        Output = np.array( [(np.sum((windX[i,:]**2+windY[i,:]**2+windZ[i,:]**2)**0.5))\\\n",
    "                    for i in range(windX.shape[0]) ] )\n",
    "    print '===========finished Making Vector of Signal Magnitude Area==========='\n",
    "    return Output  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Extraction(FileName,Sensor, axis, wNum,sNum):\n",
    "        joblib.dump(Vector_Mean(FileName, Sensor[axis], wNum,sNum, WindowDataPath),\n",
    "        FeaturePath+FileName+'_Mean.dump')\n",
    "        \n",
    "        joblib.dump(Vector_Median(FileName, Sensor[axis], wNum,sNum, WindowDataPath),\n",
    "                    FeaturePath+FileName+'_Median.dump')\n",
    "        \n",
    "        joblib.dump(Vector_Var(FileName, Sensor[axis], wNum,sNum, WindowDataPath),\n",
    "                    FeaturePath+FileName+'_Var.dump')\n",
    "        \n",
    "        joblib.dump(Vector_StdDev(FileName, Sensor[axis], wNum,sNum, WindowDataPath),\n",
    "                    FeaturePath+FileName+'_StdDev.dump')\n",
    "        \n",
    "        joblib.dump(Vector_Max(FileName, Sensor[axis], wNum,sNum, WindowDataPath),\n",
    "                    FeaturePath+FileName+'_Max.dump' )\n",
    "        \n",
    "        joblib.dump(Vector_Min(FileName, Sensor[axis], wNum,sNum, WindowDataPath),\n",
    "                    FeaturePath+FileName+'_Min.dump')\n",
    "        \n",
    "        joblib.dump(Vector_Range(FileName, Sensor[axis], wNum,sNum, WindowDataPath),\n",
    "                    FeaturePath+FileName+'_Range.dump')\n",
    "        \n",
    "        joblib.dump(Vector_RMS(FileName, Sensor[axis], wNum, sNum, WindowDataPath),\n",
    "                    FeaturePath+FileName+'_RMS.dump' )\n",
    "        \n",
    "        joblib.dump(Vector_FFT_Real(FileName, Sensor[axis], wNum,sNum, WindowDataPath),\n",
    "                    FeaturePath+FileName+'_Real.dump' )\n",
    "\n",
    "        joblib.dump(Vector_FFT_Image(FileName, Sensor[axis], wNum,sNum, WindowDataPath),\n",
    "                    FeaturePath+FileName+'_Image.dump' )\n",
    "        \n",
    "        joblib.dump(Vector_Power(FileName, Sensor[axis], wNum,sNum, WindowDataPath),\n",
    "                    FeaturePath+FileName+'_Power.dump' )\n",
    "        \n",
    "        joblib.dump(Vector_Energy(FileName, Sensor[axis], wNum,sNum, WindowDataPath),\n",
    "                    FeaturePath+FileName+'_Energy.dump' )\n",
    "\n",
    "        joblib.dump(Vector_Entropy(FileName, Sensor[axis], wNum,sNum, WindowDataPath),\n",
    "                    FeaturePath+FileName+'_Entropy.dump' )\n",
    "\n",
    "        joblib.dump(Vector_Frequency(FileName, Sensor[axis], wNum,sNum, WindowDataPath),\n",
    "                    FeaturePath+FileName+'_Frequency.dump' )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Define Function for Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def CalcurateFeature(windowNum,slidingNum):\n",
    "    for s in tqdm_notebook( [Sensor1,Sensor2,Sensor3,Sensor4,Sensor5,Sensor6],leave=False):\n",
    "        for axis in tqdm_notebook( ['AccX','AccY','AccZ'],leave=False ):\n",
    "            FileName = CommonName+'-'+s['Name']+'-'+axis+\\\n",
    "            '-win='+str(windowNum).zfill(4)+'-sld='+str(slidingNum).zfill(4)\n",
    "            Extraction(FileName, s, axis, windowNum, slidingNum)\n",
    "            time.sleep(5)\n",
    "        \n",
    "    FileNameTemp = CommonName+'-'+s['Name']+'-win='+str(windowNum).zfill(4)+'-sld='+str(slidingNum).zfill(4)\n",
    "    joblib.dump(Vector_SMA(FileNameTemp+'AccXYZ', s['AccZ'], s['AccY'], s['AccZ'], windowNum, slidingNum, WindowDataPath),\n",
    "            FeaturePath+FileNameTemp+'_SMA.dump')    \n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CalcurateCorr(windowNum,slidingNum):\n",
    "    for s in tqdm_notebook( [Sensor1,Sensor2,Sensor3,Sensor4,Sensor5,Sensor6],leave=False):\n",
    "        for saxis in tqdm_notebook( ['AccX','AccY','AccZ'],leave=False ):\n",
    "            sFileName = CommonName+'-'+s['Name']+'-'+saxis+\\\n",
    "            '-win='+str(windowNum).zfill(4)+'-sld='+str(slidingNum).zfill(4)\n",
    "            \n",
    "            for d in tqdm_notebook( [Sensor1,Sensor2,Sensor3,Sensor4,Sensor5,Sensor6],leave=False ):\n",
    "                for daxis in tqdm_notebook( ['AccX','AccY','AccZ'] ,leave=False):\n",
    "                    dFileName = CommonName+'-'+d['Name']+'-'+daxis\\\n",
    "                    +'-win='+str(windowNum).zfill(4)+'-sld='+str(slidingNum).zfill(4)\n",
    "                    \n",
    "                    FileNameTemp = CommonName+'-'+s['Name']+'-'+saxis+'-'+d['Name']+'-'+daxis\\\n",
    "                    +'-win='+str(windowNum).zfill(4)+'-sld='+str(slidingNum).zfill(4)\n",
    "                    \n",
    "                    joblib.dump(Vector_Corr(sFileName, s[saxis],dFileName, d[daxis], \n",
    "                                    windowNum, slidingNum, WindowDataPath),FeaturePath+FileNameTemp+'_Corr.dump')\n",
    "                    joblib.dump(Vector_KLD(sFileName, s[saxis],dFileName, d[daxis], \n",
    "                                    windowNum, slidingNum, WindowDataPath),FeaturePath+FileNameTemp+'_KLD.dump')\n",
    "                    joblib.dump(Vector_JSD(sFileName, s[saxis],dFileName, d[daxis], \n",
    "                                    windowNum, slidingNum, WindowDataPath),FeaturePath+FileNameTemp+'_JSD.dump')\n",
    "                    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ExtractionList=[256,512,1024,2048,4096]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Mean===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Median===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Variance===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of standard Deviation===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Max===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Max===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Range===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of RMS===========\n",
      "===========finished Making Vector of FFT Real===========\n",
      "===========finished Making Vector of FFT Image===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Energy===========\n",
      "===========finished Making Vector of Energy===========\n",
      "===========finished Making Vector of Entropy===========\n",
      "===========finished Making Vector of Frequency===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Mean===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Median===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Variance===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of standard Deviation===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Max===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Max===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Range===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of RMS===========\n",
      "===========finished Making Vector of FFT Real===========\n",
      "===========finished Making Vector of FFT Image===========\n",
      "Now making\n",
      "this data had finished making\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm_notebook(ExtractionList):\n",
    "    CalcurateFeature(i,32)\n",
    "    time.sleep(100)\n",
    "    CalcurateCorr(i,32)\n",
    "    time.sleep(100)\n",
    "    \n",
    "    CalcurateFeature(i,i/2)\n",
    "    time.sleep(100)\n",
    "    CalcurateCorr(i,i/2)\n",
    "    time.sleep(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "widgets": {
   "state": {
    "23ff84e6a46746108ea4adcbbc7b8b63": {
     "views": [
      {
       "cell_index": 33
      }
     ]
    },
    "4922651234b8492b99264c97174e41e8": {
     "views": [
      {
       "cell_index": 33
      }
     ]
    },
    "548ae18014304225b68c9c05ed16398e": {
     "views": [
      {
       "cell_index": 33
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
