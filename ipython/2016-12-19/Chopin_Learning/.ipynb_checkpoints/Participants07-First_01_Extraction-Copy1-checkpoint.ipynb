{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "import copy\n",
    "# Generate WindowFrame Function\n",
    "from mymodule import window\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "# Parametor about Sensor\n",
    "SensorNum=1 # Sensor number\n",
    "#SensorAxis='AccX' # Axis\n",
    "\n",
    "# Define Data Name\n",
    "DATE= str( datetime.date.today() )+'/'\n",
    "\n",
    "# Parametor about \" Data Path\"\n",
    "StorePath = \"/media/takeyama/Transfer/02_ActivityResearch/\"\n",
    "\n",
    "ParticipantsNum=\"Participants07/\"\n",
    "Version = \"01_First/\"\n",
    "Time = \"01_First/\"\n",
    "CommonName = 'Participants07-First-01'\n",
    "LabelName = CommonName+'.csv'\n",
    "\n",
    "TITLE = ParticipantsNum+Version\n",
    "\n",
    "DataPath = StorePath+ParticipantsNum+Version+\"RawData/\"+Time\n",
    "\n",
    "if not os.path.exists(StorePath+TITLE+'LabelData/'+Time): \n",
    "    os.makedirs(StorePath+TITLE+'LabelData/'+Time)\n",
    "LabelDataPath=StorePath+TITLE+'LabelData/'+Time\n",
    "\n",
    "if not os.path.exists(StorePath+TITLE+'dictionary/'+Time): \n",
    "    os.makedirs(StorePath+TITLE+'dictionary/'+Time)\n",
    "DictionaryDataPath=StorePath+TITLE+'dictionary/'+Time\n",
    "\n",
    "if not os.path.exists(StorePath+TITLE+'feature/'+Time): \n",
    "    os.makedirs(StorePath+TITLE+'feature/'+Time)\n",
    "FeaturePath=StorePath+TITLE+'feature/'+Time\n",
    "\n",
    "if not os.path.exists(StorePath+TITLE+'window/'+Time): \n",
    "    os.makedirs(StorePath+TITLE+'window/'+Time)\n",
    "WindowDataPath=StorePath+TITLE+'window/'+Time\n",
    "\n",
    "if not os.path.exists(StorePath+TITLE+DATE+'studyOutput/'+Time): \n",
    "    os.makedirs(StorePath+TITLE+DATE+'studyOutput/'+Time)\n",
    "StudyOutputPath=StorePath+TITLE+DATE+'studyOutput/'+Time\n",
    "\n",
    "if not os.path.exists(StorePath+TITLE+DATE+'parametor/'+Time): \n",
    "    os.makedirs(StorePath+TITLE+DATE+'parametor/'+Time)\n",
    "ParametorPath=StorePath+TITLE+DATE+'parametor/'+Time\n",
    "\n",
    "if not os.path.exists(StorePath+TITLE+DATE+'result/'+Time): \n",
    "    os.makedirs(StorePath+TITLE+DATE+'result/'+Time)\n",
    "ResultPath=StorePath+TITLE+DATE+'result/'+Time\n",
    "\n",
    "if not os.path.exists(StorePath+TITLE+DATE+'graph/'+Time): \n",
    "    os.makedirs(StorePath+TITLE+DATE+'graph/'+Time)\n",
    "GraphPath=StorePath+TITLE+DATE+'graph/'+Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Read SensorData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# センサデータのcsvファイル名をリストに集約する関数\n",
    "def SensorDataFileNameList(path):\n",
    "    l = os.listdir(DataPath)\n",
    "    FilePath =[]\n",
    "    SensorName = []\n",
    "    \n",
    "    for n in range(len(l)):\n",
    "        if (l[n][:4].find('mem-') != -1):\n",
    "            FilePath.append(l[n])\n",
    "            SensorName.append(l[n][4:15])\n",
    "    \n",
    "    return FilePath,SensorName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FFT library\n",
    "from scipy import fftpack\n",
    "from scipy import signal\n",
    "\n",
    "# Graph Plot\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "\n",
    "# Generate WindowFrame Function\n",
    "from mymodule import window\n",
    "\n",
    "# timer\n",
    "import time\n",
    "\n",
    "# temp file \n",
    "import tempfile\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['01_LeftHand.npz', '02_RightHand.npz', '03_LeftLeg.npz', '04_Rightleg.npz', '05_West.npz', '06_Chest.npz', '07_LabelData.npz']\n"
     ]
    }
   ],
   "source": [
    "DictName = os.listdir(DictionaryDataPath)\n",
    "print DictName\n",
    "Sensor1 = np.load(DictionaryDataPath+DictName[0])['data'][()]\n",
    "Sensor2 = np.load(DictionaryDataPath+DictName[1])['data'][()]\n",
    "Sensor3 = np.load(DictionaryDataPath+DictName[2])['data'][()]\n",
    "Sensor4 = np.load(DictionaryDataPath+DictName[3])['data'][()]\n",
    "Sensor5 = np.load(DictionaryDataPath+DictName[4])['data'][()]\n",
    "Sensor6 = np.load(DictionaryDataPath+DictName[5])['data'][()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetWindowFrame(windowName, dataRaw, wWidth, sWidth, PATH):\n",
    "    \"\"\"\n",
    "    data　ウィンドウフレームに変換するデータ\n",
    "    registName　ウィンドウフレームに登録するデータの名前\n",
    "    windowWidth　ウィンドウ幅\n",
    "    slidingWidth　スライド幅\n",
    "    PATH ウィドウフレームを保存するディレクトリ\n",
    "    \n",
    "    \n",
    "    About Function:\n",
    "        与えられたdataからウィンドウ幅windowWidth,スライド幅slidingWidthにしたがって\n",
    "        registNameのウィドウフレームを返す．\n",
    "        また，与えれたPATH内に同様なパラメータ( WindowWidth, slidingWidth)かつ同様な\n",
    "        windowNameのものがある場合，そのデータを返す．\n",
    "        この関数が登録，ウィンドウフレームに変換できるデータは１つとする\n",
    "    \"\"\"\n",
    "    storedName = windowName+'_Win='+str(wWidth).zfill(4)+'_Sld='+str(sWidth).zfill(4)+'.npz'\n",
    "    l = os.listdir(PATH)\n",
    "    \n",
    "    if storedName in l:\n",
    "        print \"this data had finished making\"\n",
    "        return np.load(PATH+storedName)['data'][()]\n",
    "    \n",
    "    w=window()\n",
    "    w.SetData(windowName,dataRaw)    \n",
    "    wind=w.Compile(wWidth,sWidth)\n",
    "    windoW=wind.reshape((len(wind),np.prod(wind.shape[1:])))\n",
    "    \n",
    "    np.savez(PATH+storedName,data=wind)\n",
    "\n",
    "    return wind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Extraction Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequency Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Vector_FFT_Image(windowName, dataRaw, wWidth, sWidth, PATH):\n",
    "    # get windowFrame\n",
    "    try:\n",
    "        Image = joblib.load(FeaturePath+windowName+'_Image.dump')\n",
    "    except:\n",
    "        print \"Now making\"\n",
    "        wind=GetWindowFrame(windowName, dataRaw, wWidth, sWidth, PATH)\n",
    "\n",
    "        fftwind = np.fft.fft(wind)  # calcurate fast fourier Transfromation\n",
    "        fftwind = fftwind[:,1:fftwind.shape[1]/2-1] # Orthogonal and Colossus removed\n",
    "\n",
    "\n",
    "        # windowFrame(raw wave) 2d -> windowFrame(power) 1d\n",
    "        Image=np.array([ np.imag(fftwind[i,l])\n",
    "                for i in range( fftwind.shape[0] )\n",
    "                for l in range( fftwind.shape[1] ) ])\n",
    "        Image = Image.reshape(fftwind.shape)    \n",
    "        # calcurate Squared Energy\n",
    "        \n",
    "    print '===========finished Making Vector of FFT Image==========='\n",
    "    return Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Vector_FFT_Real(windowName, dataRaw, wWidth, sWidth, PATH):\n",
    "    # get windowFrame\n",
    "    try:\n",
    "        Real = joblib.load(FeaturePath+windowName+'_Real.dump')\n",
    "    except:\n",
    "        print \"Now making\"\n",
    "        wind=GetWindowFrame(windowName, dataRaw, wWidth, sWidth, PATH)\n",
    "\n",
    "        fftwind = np.fft.fft(wind)  # calcurate fast fourier Transfromation\n",
    "        fftwind = fftwind[:,1:fftwind.shape[1]/2-1] # Orthogonal and Colossus removed\n",
    "\n",
    "\n",
    "        # windowFrame(raw wave) 2d -> windowFrame(power) 1d\n",
    "        Real=np.array([ np.real(fftwind[i,l])\n",
    "                for i in range( fftwind.shape[0] )\n",
    "                for l in range( fftwind.shape[1] ) ])\n",
    "        Real = Real.reshape(fftwind.shape)    \n",
    "    # calcurate Squared Energy\n",
    "    print '===========finished Making Vector of FFT Real==========='\n",
    "    return Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Vector_Power(windowName, dataRaw, wWidth, sWidth, PATH):\n",
    "    # get windowFrame\n",
    "    try:\n",
    "        SqrF = joblib.load(FeaturePath+windowName+'_Power.dump')\n",
    "    except:\n",
    "        print \"Now making\"\n",
    "        wind=GetWindowFrame(windowName, dataRaw, wWidth, sWidth, PATH)\n",
    "\n",
    "        fftwind = np.fft.fft(wind)  # calcurate fast fourier Transfromation\n",
    "        fftwind = fftwind[:,1:fftwind.shape[1]/2-1] # Orthogonal and Colossus removed\n",
    "\n",
    "        # windowFrame(raw wave) 2d -> windowFrame(power) 1d\n",
    "        SqrF=np.array([\n",
    "                np.real(fftwind[i,l])**2+np.imag(fftwind[i,l])**2\n",
    "                for i in range( fftwind.shape[0] )\n",
    "                for l in range( fftwind.shape[1] )\n",
    "            ])\n",
    "        SqrF = SqrF.reshape(fftwind.shape) \n",
    "        \n",
    "    print '===========finished Making Vector of Energy==========='\n",
    "    return SqrF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Vector_Energy(windowName, dataRaw, wWidth, sWidth, PATH):\n",
    "    # get windowFrame\n",
    "    try:\n",
    "        RootNormSumSqrF = joblib.load(FeaturePath+windowName+'_Energy.dump')\n",
    "    except:\n",
    "        print \"Now making\"\n",
    "        wind=GetWindowFrame(windowName, dataRaw, wWidth, sWidth, PATH)\n",
    "\n",
    "        fftwind = np.fft.fft(wind)  # calcurate fast fourier Transfromation\n",
    "        fftwind = fftwind[:,1:fftwind.shape[1]/2-1] # Orthogonal and Colossus removed\n",
    "\n",
    "        # windowFrame(raw wave) 2d -> windowFrame(power) 1d\n",
    "        SqrF=np.array([\n",
    "                np.real(fftwind[i,l])**2+np.imag(fftwind[i,l])**2\n",
    "                for i in range( fftwind.shape[0] )\n",
    "                for l in range( fftwind.shape[1] )\n",
    "            ])\n",
    "        SqrF = SqrF.reshape(fftwind.shape) \n",
    "\n",
    "        # Sum each window frame\n",
    "        SumSrqF = np.array([SqrF[i,:].sum() for i in range( SqrF.shape[0])])\n",
    "\n",
    "        # normarise\n",
    "        NormSumSqrF = np.array([SumSrqF[i]/(fftwind.shape[1]/2-1)\n",
    "                               for i in range(SumSrqF.shape[0])])\n",
    "\n",
    "        # root\n",
    "        RootNormSumSqrF = NormSumSqrF**0.5\n",
    "\n",
    "    print '===========finished Making Vector of Energy==========='\n",
    "    return RootNormSumSqrF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Vector_Frequency(windowName, dataRaw, wWidth, sWidth, PATH):\n",
    "    # get windowFrame\n",
    "    try:\n",
    "        freq = joblib.load(FeaturePath+windowName+'_Frequency.dump')\n",
    "    except:\n",
    "        print \"Now making\"\n",
    "        wind=GetWindowFrame(windowName, dataRaw, wWidth, sWidth, PATH)\n",
    "        print wind.shape\n",
    "\n",
    "        fftwind = np.fft.fft(wind)  # calcurate fast fourier Transfromation\n",
    "        print fftwind.shape\n",
    "\n",
    "        fftwind = fftwind[:,1:fftwind.shape[1]/2-1] # Orthogonal and Colossus removed\n",
    "        print fftwind.shape\n",
    "        freq = np.array([np.arctan2(np.imag(fftwind[i,l]),np.real(fftwind[i,l]))\n",
    "                         for i in range( fftwind.shape[0] ) \n",
    "                         for l in range( fftwind.shape[1] ) ])\n",
    "        freq = freq.reshape(fftwind.shape)\n",
    "    print '===========finished Making Vector of Frequency==========='\n",
    "    return freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Vector_Entropy(windowName, dataRaw, wWidth, sWidth, PATH):\n",
    "    # get windowFrame\n",
    "    try:\n",
    "        Entropy = joblib.load(FeaturePath+windowName+'_Entropy.dump')\n",
    "    except:\n",
    "        print \"Now making\"\n",
    "        wind=GetWindowFrame(windowName, dataRaw, wWidth, sWidth, PATH)\n",
    "\n",
    "        ###########################\n",
    "        ###    calcurate FFT    ###\n",
    "        ###########################\n",
    "        fftwind = np.fft.fft(wind)  # calcurate fast fourier Transfromation\n",
    "        fftwind = fftwind[:,1:fftwind.shape[1]/2-1] # Orthogonal and Colossus removed\n",
    "\n",
    "        # calcurate eq\n",
    "        f = lambda x: np.real(x)**2+np.imag(x)**2\n",
    "\n",
    "        # windowFrame(raw wave) 2d -> windowFrame(power) 1d\n",
    "        SqrF=np.array([\n",
    "                np.real(fftwind[i,l])**2+np.imag(fftwind[i,l])**2\n",
    "                for i in range( fftwind.shape[0] )\n",
    "                for l in range( fftwind.shape[1] )\n",
    "            ])\n",
    "        SqrF = SqrF.reshape(fftwind.shape)\n",
    "\n",
    "        # calcurate Squared Energy\n",
    "        SqrF=SqrF/SqrF[0,:].size\n",
    "        print SqrF.shape\n",
    "\n",
    "        ##############################\n",
    "        ###    calcurate Entropy   ###\n",
    "        ##############################\n",
    "        P = np.array([SqrF[i]/SqrF[i,:].sum() for i in range(SqrF.shape[0])])\n",
    "        print P.shape\n",
    "        P = P.reshape(SqrF.shape)\n",
    "\n",
    "        P_logP = np.array([ P[i,l]*np.log(P[i,l]) \\\n",
    "                          for i in range(P.shape[0]) for l in range(P.shape[1])])\n",
    "        print P_logP.shape\n",
    "        P_logP = P_logP.reshape(P.shape)\n",
    "\n",
    "        Entropy = np.array([\n",
    "                -1*np.sum( P_logP[i,:] ) for i in range(P.shape[0])])\n",
    "    print '===========finished Making Vector of Entropy==========='\n",
    "    return Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Vector_KLD(windowNameX, dataX, windowNameY, dataY, wWidth, sWidth, PATH):\n",
    "    \"\"\"\n",
    "        Calculates Kullback–Leibler divergence\n",
    "        input dataX dataY -> 1d Vector\n",
    "    \"\"\"\n",
    "    FileNameTemp = windowNameX.split(\"-win\")[0]+windowNameY.split(CommonName+'-')[1]\n",
    "    try:\n",
    "        KLD = joblib.load(FeaturePath+FileNameTemp+'_KLD.dump')\n",
    "    except:\n",
    "        print \"Now making\"\n",
    "        EnergyX=  Vector_Power(windowNameX, dataX, wWidth, sWidth, PATH)\n",
    "        print EnergyX.shape\n",
    "        EnergyY=  Vector_Power(windowNameY, dataY, wWidth, sWidth, PATH)\n",
    "        print EnergyX.shape\n",
    "        \n",
    "        DistX = np.array([EnergyX[i,:]/np.sum(EnergyX[i,:]) for i in range(EnergyX.shape[0])])\n",
    "        DistY = np.array([EnergyY[i,:]/np.sum(EnergyY[i,:]) for i in range(EnergyY.shape[0])])\n",
    "        \n",
    "        KLD = np.array([ np.sum(DistX[i,:]*np.log(DistX[i,:]/DistY[i,:]))\\\n",
    "                        for i in range(DistX.shape[0])])\n",
    "    print '===========finished Making Vector of KLD==========='\n",
    "    return KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s=Sensor1\n",
    "d=Sensor1\n",
    "saxis='AccX'\n",
    "daxis='AccX'\n",
    "windowNum=256\n",
    "slidingNum=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " sFileName = CommonName+'-'+s['Name']+'-'+saxis+\\\n",
    "            '-win='+str(windowNum).zfill(4)+'-sld='+str(slidingNum).zfill(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " dFileName = CommonName+'-'+s['Name']+'-'+saxis+\\\n",
    "            '-win='+str(windowNum).zfill(4)+'-sld='+str(slidingNum).zfill(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now making\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Energy===========\n",
      "(25831, 126)\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Energy===========\n",
      "(25831, 126)\n",
      "===========finished Making Vector of KLD===========\n"
     ]
    }
   ],
   "source": [
    "kld=Vector_KLD(sFileName, d[saxis],dFileName, d[daxis], \n",
    "                                    windowNum, slidingNum, WindowDataPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " ...]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[kld[i] for i in range(kld.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.73216051366246937"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p=np.array([0.1,0.2,0.3,0.4,0.5])\n",
    "q=np.array([0.3,0.4,0.5,0.6,0.7])\n",
    "np.sum(p * np.log(p / q), axis=(p.ndim - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pq' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-0945896953fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pq' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def Vector_JSD(windowNameX, dataX, windowNameY, dataY, wWidth, sWidth, PATH):\n",
    "    FileNameTemp = windowNameX.split(\"-win\")[0]+windowNameY.split(CommonName+'-')[1]\n",
    "    try:\n",
    "        KLD = joblib.load(FeaturePath+FileNameTemp+'_JSD.dump')\n",
    "    except:\n",
    "        print \"Now making\"\n",
    "        EnergyX=  Vector_Energy(windowNameX, dataX, wWidth, sWidth, PATH)\n",
    "        EnergyY=  Vector_Energy(windowNameY, dataY, wWidth, sWidth, PATH)\n",
    "\n",
    "        func_kld =lambda p,q: np.sum(p * np.log(p / q))\n",
    "        func_jsd =lambda p,q: 0.5 * func_kld(p, (p+q)/2) + 0.5 * func_kld(q, (p+q)/2)\n",
    "\n",
    "        JSD = np.array([ func_jsd(dataX[i,:],dataY[i,:])\\\n",
    "                        for i in range(dataX.shape[0])])\n",
    "    print '===========finished Making Vector of JSD==========='\n",
    "    return JSD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methematical/Statistical Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Vector_Mean(windowName, dataRaw, wWidth, sWidth, PATH):\n",
    "    # get windowFrame\n",
    "    try:\n",
    "        Output = joblib.load(FeaturePath+FileNameTemp+'_Mean.dump')\n",
    "    except:\n",
    "        print \"Now making\"\n",
    "        wind=GetWindowFrame(windowName, dataRaw, wWidth, sWidth, PATH)\n",
    "        Output = np.array( [wind[i,:].mean() for i in range(wind.shape[0]) ] )\n",
    "    print '===========finished Making Vector of Mean==========='\n",
    "    return Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Vector_Median(windowName, dataRaw, wWidth, sWidth, PATH):\n",
    "    # get windowFrame\n",
    "    try:\n",
    "        Output = joblib.load(FeaturePath+FileNameTemp+'_Median.dump')\n",
    "    except:\n",
    "        print \"Now making\"\n",
    "        wind=GetWindowFrame(windowName, dataRaw, wWidth, sWidth, PATH)\n",
    "        Output = np.array( [np.median(wind[i,:]) for i in range(wind.shape[0]) ] )\n",
    "    print '===========finished Making Vector of Median==========='\n",
    "    return Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Vector_Var(windowName, dataRaw, wWidth, sWidth, PATH):\n",
    "    # get windowFrame\n",
    "    try:\n",
    "        Output = joblib.load(FeaturePath+FileNameTemp+'_Var.dump')\n",
    "    except:\n",
    "        print \"Now making\"\n",
    "        wind=GetWindowFrame(windowName, dataRaw, wWidth, sWidth, PATH)\n",
    "        Output = np.array( [wind[i,:].var() for i in range(wind.shape[0]) ] )\n",
    "    print '===========finished Making Vector of Variance==========='\n",
    "    return Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Vector_StdDev(windowName, dataRaw, wWidth, sWidth, PATH):\n",
    "    # get windowFram\n",
    "    try:\n",
    "        Output = joblib.load(FeaturePath+FileNameTemp+'_StdDev.dump')\n",
    "    except:\n",
    "        print \"Now making\"\n",
    "        wind=GetWindowFrame(windowName, dataRaw, wWidth, sWidth, PATH)  \n",
    "        Output = np.array( [wind[i,:].var()**0.5 for i in range(wind.shape[0]) ] )\n",
    "    print '===========finished Making Vector of standard Deviation==========='\n",
    "    return Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Vector_Max(windowName, dataRaw, wWidth, sWidth, PATH):\n",
    "    # get windowFrame\n",
    "    try:\n",
    "        Output = joblib.load(FeaturePath+FileNameTemp+'_Max.dump')\n",
    "    except:\n",
    "        print \"Now making\"\n",
    "        wind=GetWindowFrame(windowName, dataRaw, wWidth, sWidth, PATH)\n",
    "        Output = np.array( [wind[i,:].max() for i in range(wind.shape[0]) ] )\n",
    "    print '===========finished Making Vector of Max==========='\n",
    "    return Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Vector_Min(windowName, dataRaw, wWidth, sWidth, PATH):\n",
    "    # get windowFrame\n",
    "    try:\n",
    "        Output = joblib.load(FeaturePath+FileNameTemp+'_Min.dump')\n",
    "    except:\n",
    "        print \"Now making\"\n",
    "        wind=GetWindowFrame(windowName, dataRaw, wWidth, sWidth, PATH)\n",
    "        Output = np.array( [wind[i,:].min() for i in range(wind.shape[0]) ] )\n",
    "    print '===========finished Making Vector of Max==========='\n",
    "    return Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Vector_Range(windowName, dataRaw, wWidth, sWidth, PATH):\n",
    "    # get windowFrame\n",
    "    try:\n",
    "        Output = joblib.load(FeaturePath+FileNameTemp+'_Range.dump')\n",
    "    except:\n",
    "        print \"Now making\"\n",
    "        wind=GetWindowFrame(windowName, dataRaw, wWidth, sWidth, PATH)\n",
    "        Output = np.array( [(wind[i,:].max()-wind[i,:].min())\\\n",
    "                            for i in range(wind.shape[0]) ] )\n",
    "    print '===========finished Making Vector of Range==========='\n",
    "    return Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Vector_RMS(windowName, dataRaw, wWidth, sWidth, PATH):\n",
    "    # get windowFrame\n",
    "    try:\n",
    "        Output = joblib.load(FeaturePath+FileNameTemp+'_RMS.dump')\n",
    "    except:\n",
    "        print \"Now making\"\n",
    "        wind=GetWindowFrame(windowName, dataRaw, wWidth, sWidth, PATH)\n",
    "        Output = np.array( [( (np.sum( wind[i,:]**2 )/wWidth))**0.5\n",
    "                            for i in range(wind.shape[0]) ] )\n",
    "    print '===========finished Making Vector of RMS==========='\n",
    "    return Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Vector_Corr(windowNameX, dataRawX, windowNameY, dataRawY, wWidth, sWidth, PATH):\n",
    "    # get windowFrame\n",
    "    FileNameTemp = windowNameX.split(\"-win\")[0]+windowNameY.split(CommonName+'-')[1]\n",
    "    try:\n",
    "        Output = joblib.load(FeaturePath+FileNameTemp+'_Corr.dump')\n",
    "    except:\n",
    "        print \"Now making\"\n",
    "        windX=GetWindowFrame(windowNameX, dataRawX, wWidth, sWidth, PATH)\n",
    "        windY=GetWindowFrame(windowNameY, dataRawY, wWidth, sWidth, PATH)\n",
    "        Output = np.array( [( np.corrcoef(windX[i,:],windY[i,:]) )\\\n",
    "                        for i in range(windX.shape[0]) ] )\n",
    "    print '===========finished Making Vector of Correlation==========='\n",
    "    return Output[:,0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Vector_SMA(windowName, dataRawX, dataRawY, dataRawZ, wWidth, sWidth, PATH):\n",
    "    # get windowFrame\n",
    "    FileNameTemp= windowName.split('AccXYZ')[0]\n",
    "    try:\n",
    "        Output = joblib.load(FeaturePath+FileNameTemp+'_SMA.dump')\n",
    "    except:\n",
    "        print \"Now making\"\n",
    "        windX=GetWindowFrame(windowName, dataRawX, wWidth, sWidth, PATH)\n",
    "        windY=GetWindowFrame(windowName, dataRawY, wWidth, sWidth, PATH)\n",
    "        windZ=GetWindowFrame(windowName, dataRawZ, wWidth, sWidth, PATH)\n",
    "        Output = np.array( [(np.sum((windX[i,:]**2+windY[i,:]**2+windZ[i,:]**2)**0.5))\\\n",
    "                    for i in range(windX.shape[0]) ] )\n",
    "    print '===========finished Making Vector of Signal Magnitude Area==========='\n",
    "    return Output  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Extraction(FileName,Sensor, axis, wNum,sNum):\n",
    "        joblib.dump(Vector_Mean(FileName, Sensor[axis], wNum,sNum, WindowDataPath),\n",
    "        FeaturePath+FileName+'_Mean.dump')\n",
    "        \n",
    "        joblib.dump(Vector_Median(FileName, Sensor[axis], wNum,sNum, WindowDataPath),\n",
    "                    FeaturePath+FileName+'_Median.dump')\n",
    "        \n",
    "        joblib.dump(Vector_Var(FileName, Sensor[axis], wNum,sNum, WindowDataPath),\n",
    "                    FeaturePath+FileName+'_Var.dump')\n",
    "        \n",
    "        joblib.dump(Vector_StdDev(FileName, Sensor[axis], wNum,sNum, WindowDataPath),\n",
    "                    FeaturePath+FileName+'_StdDev.dump')\n",
    "        \n",
    "        joblib.dump(Vector_Max(FileName, Sensor[axis], wNum,sNum, WindowDataPath),\n",
    "                    FeaturePath+FileName+'_Max.dump' )\n",
    "        \n",
    "        joblib.dump(Vector_Min(FileName, Sensor[axis], wNum,sNum, WindowDataPath),\n",
    "                    FeaturePath+FileName+'_Min.dump')\n",
    "        \n",
    "        joblib.dump(Vector_Range(FileName, Sensor[axis], wNum,sNum, WindowDataPath),\n",
    "                    FeaturePath+FileName+'_Range.dump')\n",
    "        \n",
    "        joblib.dump(Vector_RMS(FileName, Sensor[axis], wNum, sNum, WindowDataPath),\n",
    "                    FeaturePath+FileName+'_RMS.dump' )\n",
    "        \n",
    "        joblib.dump(Vector_FFT_Real(FileName, Sensor[axis], wNum,sNum, WindowDataPath),\n",
    "                    FeaturePath+FileName+'_Real.dump' )\n",
    "\n",
    "        joblib.dump(Vector_FFT_Image(FileName, Sensor[axis], wNum,sNum, WindowDataPath),\n",
    "                    FeaturePath+FileName+'_Image.dump' )\n",
    "     \n",
    "        joblib.dump(Vector_Power(FileName, Sensor[axis], wNum,sNum, WindowDataPath),\n",
    "                FeaturePath+FileName+'_Power.dump' )\n",
    "    \n",
    "        joblib.dump(Vector_Energy(FileName, Sensor[axis], wNum,sNum, WindowDataPath),\n",
    "                    FeaturePath+FileName+'_Energy.dump' )\n",
    "\n",
    "        joblib.dump(Vector_Entropy(FileName, Sensor[axis], wNum,sNum, WindowDataPath),\n",
    "                    FeaturePath+FileName+'_Entropy.dump' )\n",
    "\n",
    "        joblib.dump(Vector_Frequency(FileName, Sensor[axis], wNum,sNum, WindowDataPath),\n",
    "                    FeaturePath+FileName+'_Frequency.dump' )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Define Function for Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def CalcurateFeature(windowNum,slidingNum):\n",
    "    for s in tqdm_notebook( [Sensor1,Sensor2,Sensor3,Sensor4,Sensor5,Sensor6],leave=False):\n",
    "        for axis in tqdm_notebook( ['AccX','AccY','AccZ'],leave=False ):\n",
    "            FileName = CommonName+'-'+s['Name']+'-'+axis+\\\n",
    "            '-win='+str(windowNum).zfill(4)+'-sld='+str(slidingNum).zfill(4)\n",
    "            Extraction(FileName, s, axis, windowNum, slidingNum)\n",
    "            time.sleep(5)\n",
    "        \n",
    "    FileNameTemp = CommonName+'-'+s['Name']+'-win='+str(windowNum).zfill(4)+'-sld='+str(slidingNum).zfill(4)\n",
    "    joblib.dump(Vector_SMA(FileNameTemp+'AccXYZ', s['AccZ'], s['AccY'], s['AccZ'], windowNum, slidingNum, WindowDataPath),\n",
    "            FeaturePath+FileNameTemp+'_SMA.dump')    \n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CalcurateCorr(windowNum,slidingNum):\n",
    "    for s in tqdm_notebook( [Sensor1,Sensor2,Sensor3,Sensor4,Sensor5,Sensor6],leave=False):\n",
    "        for saxis in tqdm_notebook( ['AccX','AccY','AccZ'],leave=False ):\n",
    "            sFileName = CommonName+'-'+s['Name']+'-'+saxis+\\\n",
    "            '-win='+str(windowNum).zfill(4)+'-sld='+str(slidingNum).zfill(4)\n",
    "            \n",
    "            for d in tqdm_notebook( [Sensor1,Sensor2,Sensor3,Sensor4,Sensor5,Sensor6],leave=False ):\n",
    "                for daxis in tqdm_notebook( ['AccX','AccY','AccZ'] ,leave=False):\n",
    "                    dFileName = CommonName+'-'+d['Name']+'-'+daxis+\\\n",
    "                    '-win='+str(windowNum).zfill(4)+'-sld='+str(slidingNum).zfill(4)\n",
    "                    \n",
    "                    FileNameTemp = CommonName+'-'+s['Name']+'-'+saxis+'-'+d['Name']+'-'+daxis+\\\n",
    "                    '-win='+str(windowNum).zfill(4)+'-sld='+str(slidingNum).zfill(4)\n",
    "                    \n",
    "                    joblib.dump(Vector_Corr(sFileName, s[saxis],dFileName, d[daxis], \n",
    "                                    windowNum, slidingNum, WindowDataPath),FeaturePath+FileNameTemp+'_Corr.dump')\n",
    "                    joblib.dump(Vector_KLD(sFileName, s[saxis],dFileName, d[daxis], \n",
    "                                    windowNum, slidingNum, WindowDataPath),FeaturePath+FileNameTemp+'_KLD.dump')\n",
    "                    joblib.dump(Vector_JSD(sFileName, s[saxis],dFileName, d[daxis], \n",
    "                                    windowNum, slidingNum, WindowDataPath),FeaturePath+FileNameTemp+'_JSD.dump')\n",
    "                    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ExtractionLis=[256,512,1024,2048,4096]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Now state 256\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Mean===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Median===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Variance===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of standard Deviation===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Max===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Max===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Range===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of RMS===========\n",
      "===========finished Making Vector of FFT Real===========\n",
      "===========finished Making Vector of FFT Image===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Energy===========\n",
      "===========finished Making Vector of Energy===========\n",
      "===========finished Making Vector of Entropy===========\n",
      "===========finished Making Vector of Frequency===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Mean===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Median===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Variance===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of standard Deviation===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Max===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Max===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Range===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of RMS===========\n",
      "===========finished Making Vector of FFT Real===========\n",
      "===========finished Making Vector of FFT Image===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Energy===========\n",
      "===========finished Making Vector of Energy===========\n",
      "===========finished Making Vector of Entropy===========\n",
      "===========finished Making Vector of Frequency===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Mean===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Median===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Variance===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of standard Deviation===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Max===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Max===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Range===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of RMS===========\n",
      "===========finished Making Vector of FFT Real===========\n",
      "===========finished Making Vector of FFT Image===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Energy===========\n",
      "===========finished Making Vector of Energy===========\n",
      "===========finished Making Vector of Entropy===========\n",
      "===========finished Making Vector of Frequency===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Mean===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Median===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Variance===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of standard Deviation===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Max===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Max===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Range===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of RMS===========\n",
      "===========finished Making Vector of FFT Real===========\n",
      "===========finished Making Vector of FFT Image===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Energy===========\n",
      "===========finished Making Vector of Energy===========\n",
      "===========finished Making Vector of Entropy===========\n",
      "===========finished Making Vector of Frequency===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Mean===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Median===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Variance===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of standard Deviation===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Max===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Max===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Range===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of RMS===========\n",
      "===========finished Making Vector of FFT Real===========\n",
      "===========finished Making Vector of FFT Image===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Energy===========\n",
      "===========finished Making Vector of Energy===========\n",
      "===========finished Making Vector of Entropy===========\n",
      "===========finished Making Vector of Frequency===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Mean===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Median===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Variance===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of standard Deviation===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Max===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Max===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Range===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of RMS===========\n",
      "===========finished Making Vector of FFT Real===========\n",
      "===========finished Making Vector of FFT Image===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Energy===========\n",
      "===========finished Making Vector of Energy===========\n",
      "===========finished Making Vector of Entropy===========\n",
      "===========finished Making Vector of Frequency===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Mean===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Median===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Variance===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of standard Deviation===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Max===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Max===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Range===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of RMS===========\n",
      "===========finished Making Vector of FFT Real===========\n",
      "===========finished Making Vector of FFT Image===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Energy===========\n",
      "===========finished Making Vector of Energy===========\n",
      "===========finished Making Vector of Entropy===========\n",
      "===========finished Making Vector of Frequency===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Mean===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Median===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Variance===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of standard Deviation===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Max===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Max===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Range===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of RMS===========\n",
      "===========finished Making Vector of FFT Real===========\n",
      "===========finished Making Vector of FFT Image===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Energy===========\n",
      "===========finished Making Vector of Energy===========\n",
      "===========finished Making Vector of Entropy===========\n",
      "===========finished Making Vector of Frequency===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Mean===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Median===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Variance===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of standard Deviation===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Max===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Max===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of Range===========\n",
      "Now making\n",
      "this data had finished making\n",
      "===========finished Making Vector of RMS===========\n",
      "===========finished Making Vector of FFT Real===========\n",
      "===========finished Making Vector of FFT Image===========\n",
      "Now making\n",
      "this data had finished making\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm_notebook(ExtractionList):\n",
    "    print \" Now state \"+str(i)\n",
    "    CalcurateFeature(i,32)\n",
    "    time.sleep(100)\n",
    "    CalcurateCorr(i,32)\n",
    "    time.sleep(100)\n",
    "    \n",
    "    CalcurateFeature(i,i/2)\n",
    "    time.sleep(100)\n",
    "    CalcurateCorr(i,i/2)\n",
    "    time.sleep(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "widgets": {
   "state": {
    "073789e2feef4fc7a2ae5ad9229ce3a1": {
     "views": [
      {
       "cell_index": 40
      }
     ]
    },
    "0d4fa4f26f6e4c41ab26863e2036ffe9": {
     "views": [
      {
       "cell_index": 31
      }
     ]
    },
    "20eb49d00fe14e4f911de0b871ff8dad": {
     "views": [
      {
       "cell_index": 31
      }
     ]
    },
    "267072aa919c437198dc95ff582652d8": {
     "views": [
      {
       "cell_index": 33
      }
     ]
    },
    "28ea88745cc847349cc3e17c975f6cbc": {
     "views": [
      {
       "cell_index": 40
      }
     ]
    },
    "30b78670262f42a883f8db18f5f9a999": {
     "views": [
      {
       "cell_index": 39
      }
     ]
    },
    "4c8a14ddda264bbc952d756586cc787b": {
     "views": [
      {
       "cell_index": 31
      }
     ]
    },
    "5221b1076d524fa59c3f019b47a2ef75": {
     "views": [
      {
       "cell_index": 40
      }
     ]
    },
    "53ef7387fb0e472fb88bc0e05e6a6162": {
     "views": [
      {
       "cell_index": 40
      }
     ]
    },
    "6775c9fde01f4e96a4aafbc0f43a5125": {
     "views": [
      {
       "cell_index": 31
      }
     ]
    },
    "68c7b22dc8e244ab954b588ca81b6684": {
     "views": [
      {
       "cell_index": 31
      }
     ]
    },
    "7a8020ed5c0e4f1c938c7ddd80c5e76f": {
     "views": [
      {
       "cell_index": 40
      }
     ]
    },
    "7dac07ca971c4be18bbc973afb1dd972": {
     "views": [
      {
       "cell_index": 33
      }
     ]
    },
    "88e5569b64514222a3d8dce24a211726": {
     "views": [
      {
       "cell_index": 31
      }
     ]
    },
    "9e4d307d05f449bb9c99dd2d9e6a5b8b": {
     "views": [
      {
       "cell_index": 31
      }
     ]
    },
    "a66a1cb2f19d4c109d187523318e9bb6": {
     "views": [
      {
       "cell_index": 39
      }
     ]
    },
    "c4fd0b3a8088441a9a00de3df0157981": {
     "views": [
      {
       "cell_index": 33
      }
     ]
    },
    "d3bfae173eb6442a88ca91020ae2ca38": {
     "views": [
      {
       "cell_index": 31
      }
     ]
    },
    "ef42fbdc046f41aa8ed107cf99a2bf18": {
     "views": [
      {
       "cell_index": 33
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
