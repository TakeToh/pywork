{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "important 変数を個々に定義する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SensorNum=1 # Sensor number\n",
    "SampleNum=32 # Window Width\n",
    "Overlap=0.5 # overlap\n",
    "width=1000 # graph width \n",
    "EncodingDim=[4,8,12,16,32,64] # number of hidden layer note \n",
    "Axis='AccZ' # Axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import fftpack\n",
    "from scipy import signal\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import pickle\n",
    "import copy\n",
    "\n",
    "import processing\n",
    "import window\n",
    "\n",
    "import matplotlib.animation as animation\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 970 (CNMeM is disabled, cuDNN 4007)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.datasets import cifar10\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.utils.visualize_util import model_to_dot, plot\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import matplotlib.image as mpimg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DataName='sensor'+str(SensorNum)+'_'+Axis\n",
    "SensorName='sensor'+str(SensorNum)\n",
    "DicName='MemSensor'+str(SensorNum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "WORKSPACE_PATH = '/home/takeyama/pywork/ipython/2016-07-11'\n",
    "\n",
    "StudyDataPath=WORKSPACE_PATH+'/Study/'+DataName+'/'+'Window='+str(SampleNum)+'-Overlap='+str(Overlap*100)+'/'\n",
    "if not os.path.exists(StudyDataPath): os.makedirs(StudyDataPath)\n",
    "\n",
    "GlaphDataPath=WORKSPACE_PATH+'/Graph/'+DataName+'/Learning-Window='+str(SampleNum)+'-Overlap='+str(Overlap*100)+'/'\n",
    "if not os.path.exists(GlaphDataPath): os.makedirs(GlaphDataPath)\n",
    "\n",
    "StudyDataModelPicPath=WORKSPACE_PATH+'/Study/'+DataName+'/modelPic-Window='+str(SampleNum)+'-Overlap='+str(Overlap*100)+'/'\n",
    "if not os.path.exists(StudyDataModelPicPath): os.makedirs(StudyDataModelPicPath)\n",
    "\n",
    "WindowDataPath=WORKSPACE_PATH+'/window/'\n",
    "RawDataPath=WORKSPACE_PATH+'/raw/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Phase1 計測データの取得**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dic=processing.LoadDicDataFromFileNPZ(RawDataPath+DicName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Phase2 window flame 作成**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AccZ is registed now\n",
      "Build Complete\n",
      "(254742,)\n"
     ]
    }
   ],
   "source": [
    "w=window.Window()\n",
    "w.SetData(Axis,dic[Axis])\n",
    "wind=w.Compile(windowWidth=SampleNum,overlap=Overlap)\n",
    "windoW=wind.reshape((len(wind),np.prod(wind.shape[1:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7960, 32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "windoW.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**前回やった学習をもう１度やってみる**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7960 samples, validate on 7960 samples\n",
      "Epoch 1/50\n",
      "7960/7960 [==============================] - 1s - loss: 0.0185 - val_loss: 0.0041\n",
      "Epoch 2/50\n",
      "7960/7960 [==============================] - 1s - loss: 0.0034 - val_loss: 0.0029\n",
      "Epoch 3/50\n",
      "7960/7960 [==============================] - 3s - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 4/50\n",
      "7960/7960 [==============================] - 3s - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 5/50\n",
      "7960/7960 [==============================] - 3s - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 6/50\n",
      "7960/7960 [==============================] - 3s - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 7/50\n",
      "7960/7960 [==============================] - 3s - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 8/50\n",
      "7960/7960 [==============================] - 3s - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 9/50\n",
      "7960/7960 [==============================] - 3s - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 10/50\n",
      "7960/7960 [==============================] - 3s - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 11/50\n",
      "7960/7960 [==============================] - 3s - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 12/50\n",
      "7960/7960 [==============================] - 3s - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 13/50\n",
      "7960/7960 [==============================] - 3s - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 14/50\n",
      "7960/7960 [==============================] - 3s - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 15/50\n",
      "7960/7960 [==============================] - 3s - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 16/50\n",
      "7960/7960 [==============================] - 3s - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 17/50\n",
      "7960/7960 [==============================] - 4s - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 18/50\n",
      "7960/7960 [==============================] - 3s - loss: 0.0010 - val_loss: 9.8826e-04\n",
      "Epoch 19/50\n",
      " 448/7960 [>.............................] - ETA: 2s - loss: 9.5076e-04"
     ]
    }
   ],
   "source": [
    "# define SaveFileName\n",
    "for encoding_dim in EncodingDim:\n",
    "    SaveFileNameEncord=DataName+'_encoded'+'_edim='+str(encoding_dim)+'-Window='+str(SampleNum)+'-Overlap='+str(Overlap*100)\n",
    "    SaveFileNameDecord=DataName+'_decoded'+'_edim='+str(encoding_dim)+'-Window='+str(SampleNum)+'-Overlap='+str(Overlap*100)\n",
    "    SaveFileNameNet=DataName+'_net'+'_edim='+str(encoding_dim)+'-Window='+str(SampleNum)+'-Overlap='+str(Overlap*100)\n",
    "    SaveFileNameTrain=DataName+'_train'+'_edim='+str(encoding_dim)+'-Window='+str(SampleNum)+'-Overlap='+str(Overlap*100)\n",
    "    SaveFileNameTest=DataName+'_test'+'_edim='+str(encoding_dim)+'-Window='+str(SampleNum)+'-Overlap='+str(Overlap*100)\n",
    "    SaveFileNameGlaph=GlaphDataPath+DataName+'_edim='+str(encoding_dim)+'-Window='+str(SampleNum)+'-Overlap='+str(Overlap*100)+'_loss_val_loss.png'\n",
    "\n",
    "    window_test=windoW\n",
    "    window_train=windoW\n",
    "    processing.SaveDicDataFromFileNPZ(WindowDataPath,SaveFileNameTrain,window_test)\n",
    "    processing.SaveDicDataFromFileNPZ(WindowDataPath,SaveFileNameTest,window_test)\n",
    "    shapeNum=windoW.shape[1]\n",
    "\n",
    "    # this is our input placeholder\n",
    "    input_img = Input(shape=(shapeNum,))\n",
    "    # \"encoded\" is the encoded representation of the input\n",
    "    encoded = Dense(encoding_dim, activation='tanh')(input_img)\n",
    "    # \"decoded\" is the lossy reconstruction of the input\n",
    "    decoded = Dense(shapeNum, activation='linear')(encoded)\n",
    "\n",
    "    # this model maps an input to its reconstruction\n",
    "    autoencoder = Model(input=input_img, output=decoded)\n",
    "\n",
    "    # this model maps an input to its encoded representation\n",
    "    encoder = Model(input=input_img, output=encoded)\n",
    "\n",
    "    # create a placeholder for an encoded (32-dimensional) input\n",
    "    encoded_input = Input(shape=(encoding_dim,))\n",
    "    # retrieve the last layer of the autoencoder model\n",
    "    decoder_layer = autoencoder.layers[-1]\n",
    "    # create the decoder model\n",
    "    decoder = Model(input=encoded_input, output=decoder_layer(encoded_input))\n",
    "\n",
    "    autoencoder.compile(optimizer='adadelta', loss='mse')\n",
    "    plot(autoencoder,  to_file=StudyDataModelPicPath+SaveFileNameNet+'.png')\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "    hist = autoencoder.fit(window_train, window_train,\n",
    "                    nb_epoch=50,\n",
    "                    batch_size=shapeNum/4,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(window_test, window_test),\n",
    "                    callbacks=[early_stopping])\n",
    "\n",
    "    encoded_imgs = encoder.predict(window_test)\n",
    "    decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "    processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameEncord,encoded_imgs)\n",
    "    processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameDecord,decoded_imgs)\n",
    "\n",
    "    # save model and wights\n",
    "    json_string = encoder.to_json()\n",
    "    open(StudyDataPath+SaveFileNameEncord+'.json', 'w').write(json_string)\n",
    "    encoder.save_weights(StudyDataPath+SaveFileNameEncord+'_weights.h5')\n",
    "\n",
    "    json_string = decoder.to_json()\n",
    "    open(StudyDataPath+SaveFileNameDecord+'.json', 'w').write(json_string)\n",
    "    decoder.save_weights(StudyDataPath+SaveFileNameDecord+'_weights.h5')\n",
    "\n",
    "    json_string = autoencoder.to_json()\n",
    "    open(StudyDataPath+SaveFileNameNet+'.json', 'w').write(json_string)\n",
    "    autoencoder.save_weights(StudyDataPath+SaveFileNameNet+'_weights.h5')\n",
    "\n",
    "    # plot loss\n",
    "    loss = hist.history['loss']\n",
    "    val_loss = hist.history['val_loss']\n",
    "\n",
    "    nb_epoch = len(loss)\n",
    "    plt.plot(range(nb_epoch), loss, marker='.', label='loss')\n",
    "    plt.plot(range(nb_epoch), val_loss, marker='.', label='val_loss')\n",
    "    plt.legend(loc='best', fontsize=10)\n",
    "    plt.grid()\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.savefig(SaveFileNameGlaph)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
