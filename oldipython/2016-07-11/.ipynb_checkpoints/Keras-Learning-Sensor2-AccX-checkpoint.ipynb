{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import fftpack\n",
    "from scipy import signal\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import pickle\n",
    "import copy\n",
    "import processing\n",
    "import matplotlib.animation as animation\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.datasets import cifar10\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.utils.visualize_util import model_to_dot, plot\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import matplotlib.image as mpimg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "共通変数をここに定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DataName='sensor1_AccX'\n",
    "SensorName='sensor1'\n",
    "width=3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "WORKSPACE_PATH = '/home/takeyama/pywork/ipython/2016-07-04'\n",
    "\n",
    "    \n",
    "if not os.path.exists(WORKSPACE_PATH+'/'+DataName+'/study/'): os.makedirs(WORKSPACE_PATH+'/'+DataName+'/study/')\n",
    "StudyDataPath=WORKSPACE_PATH+'/'+DataName+'/study/'\n",
    "\n",
    "if not os.path.exists(WORKSPACE_PATH+'/'+DataName+'/glaph/'): os.makedirs(WORKSPACE_PATH+'/'+DataName+'/glaph/')\n",
    "GlaphDataPath=WORKSPACE_PATH+'/'+DataName+'/glaph/'\n",
    "\n",
    "if not os.path.exists(WORKSPACE_PATH+'/'+DataName+'/modelPic/'): os.makedirs(WORKSPACE_PATH+'/'+DataName+'/modelPic/')\n",
    "StudyDataModelPicPath=WORKSPACE_PATH+'/'+DataName+'/modelPic/'\n",
    "\n",
    "WindowDataPath=WORKSPACE_PATH+'/window/'\n",
    "RawDataPath=WORKSPACE_PATH+'/raw/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    encordData,decordData\n",
    "    firstNum:\n",
    "    goalNum:\n",
    "    commonLabel:共通名前\n",
    "\"\"\"\n",
    "def MakeGlaph(encordData,decordData,firstNum,goalNum,commonLabel):\n",
    "    eRow, eCol=encordData.shape\n",
    "    dRow, dCol=decordData.shape\n",
    "    if (eRow!=dRow) | (eCol!=dCol):\n",
    "        print 'check encordData & decordData'\n",
    "        return -1\n",
    "        \n",
    "    start = firstNum\n",
    "    goal=goalNum\n",
    "    print str(start)+' is start '+str(goal)+' is goal'\n",
    "    dataE = encordData.reshape(eRow*eCol,1)[start:goal]\n",
    "    dataD = decordData.reshape(dRow*dCol,1)[start:goal]\n",
    "    plt.figure(figsize=(160,90))\n",
    "    plt.plot(range(0,len(dataE)),dataE,'--r',label=\"Encoded\")\n",
    "    plt.plot(range(0,len(dataD)),dataD,'b',label=\"Decoded\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.title(str(start)+\"-\"+str(goal))\n",
    "    plt.savefig(commonLabel+'-'+str(start)+\"-\"+str(goal)+'-'+'glaph')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Phase1 計測データの取得**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dic1=processing.LoadDicDataFromFileNPZ(RawDataPath+\"MemSensor1\")\n",
    "dic2=processing.LoadDicDataFromFileNPZ(RawDataPath+\"MemSensor2\")\n",
    "dic3=processing.LoadDicDataFromFileNPZ(RawDataPath+\"MemSensor3\")\n",
    "dic4=processing.LoadDicDataFromFileNPZ(RawDataPath+\"MemSensor4\")\n",
    "dic5=processing.LoadDicDataFromFileNPZ(RawDataPath+\"MemSensor5\")\n",
    "dic6=processing.LoadDicDataFromFileNPZ(RawDataPath+\"MemSensor6\")\n",
    "dic7=processing.LoadDicDataFromFileNPZ(RawDataPath+\"MemSensor7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Phase2 window flame 作成**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "windoW = processing.LoadDicDataFromFileNPZ(\"window/\"+str(SensorName)+\"_AccX_test.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15921, 16)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "windoW.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**前回やった学習をもう１度やってみる**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15921 samples, validate on 15921 samples\n",
      "Epoch 1/50\n",
      "15921/15921 [==============================] - 110s - loss: 0.0242 - val_loss: 0.0024\n",
      "Epoch 2/50\n",
      "15921/15921 [==============================] - 109s - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 3/50\n",
      "15921/15921 [==============================] - 116s - loss: 0.0012 - val_loss: 9.0725e-04\n",
      "Epoch 4/50\n",
      "15921/15921 [==============================] - 115s - loss: 7.7119e-04 - val_loss: 6.0352e-04\n",
      "Epoch 5/50\n",
      "15921/15921 [==============================] - 118s - loss: 5.3500e-04 - val_loss: 4.5593e-04\n",
      "Epoch 6/50\n",
      "15921/15921 [==============================] - 118s - loss: 4.1224e-04 - val_loss: 3.1450e-04\n",
      "Epoch 7/50\n",
      "15921/15921 [==============================] - 115s - loss: 3.4368e-04 - val_loss: 2.8562e-04\n",
      "Epoch 8/50\n",
      "15921/15921 [==============================] - 117s - loss: 3.0135e-04 - val_loss: 2.3458e-04\n",
      "Epoch 9/50\n",
      "15921/15921 [==============================] - 115s - loss: 2.7791e-04 - val_loss: 2.1511e-04\n",
      "Epoch 10/50\n",
      "15921/15921 [==============================] - 118s - loss: 2.6233e-04 - val_loss: 1.9069e-04\n",
      "Epoch 11/50\n",
      "15921/15921 [==============================] - 118s - loss: 2.3861e-04 - val_loss: 1.9046e-04\n",
      "Epoch 12/50\n",
      "15921/15921 [==============================] - 115s - loss: 2.2820e-04 - val_loss: 1.7751e-04\n",
      "Epoch 13/50\n",
      "15921/15921 [==============================] - 116s - loss: 2.2619e-04 - val_loss: 1.6001e-04\n",
      "Epoch 14/50\n",
      "15921/15921 [==============================] - 115s - loss: 2.1154e-04 - val_loss: 1.6436e-04\n",
      "Epoch 15/50\n",
      "15921/15921 [==============================] - 117s - loss: 2.1053e-04 - val_loss: 1.5187e-04\n",
      "Epoch 16/50\n",
      "15921/15921 [==============================] - 119s - loss: 2.0496e-04 - val_loss: 1.4615e-04\n",
      "Epoch 17/50\n",
      "15921/15921 [==============================] - 115s - loss: 2.0007e-04 - val_loss: 1.7521e-04\n",
      "Epoch 18/50\n",
      "15921/15921 [==============================] - 116s - loss: 1.9367e-04 - val_loss: 1.4007e-04\n",
      "Epoch 19/50\n",
      "15921/15921 [==============================] - 116s - loss: 1.9036e-04 - val_loss: 1.2973e-04\n",
      "Epoch 20/50\n",
      "15921/15921 [==============================] - 116s - loss: 1.8826e-04 - val_loss: 2.2705e-04\n",
      "Epoch 21/50\n",
      "15921/15921 [==============================] - 118s - loss: 1.8774e-04 - val_loss: 1.2369e-04\n",
      "Epoch 22/50\n",
      "15921/15921 [==============================] - 115s - loss: 1.7979e-04 - val_loss: 1.4237e-04\n",
      "Epoch 23/50\n",
      "15921/15921 [==============================] - 116s - loss: 1.8013e-04 - val_loss: 2.0028e-04\n",
      "Epoch 24/50\n",
      "15921/15921 [==============================] - 116s - loss: 1.7150e-04 - val_loss: 1.3369e-04\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEPCAYAAACHuClZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSNpUTEREJG0qJiIikrb/D0pXUQVYqcgeAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fafcbbb9190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define SaveFileName\n",
    "encoding_dim = 8  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "SaveFileNameEncord=DataName+'_encoded'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameDecord=DataName+'_decoded'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameNet=DataName+'_net'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameTrain=DataName+'_train'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameTest=DataName+'_test'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameGlaph=GlaphDataPath+DataName+'_edim='+str(encoding_dim)+'_loss_val_loss.png'\n",
    "\n",
    "window_test=windoW\n",
    "window_train=windoW\n",
    "\n",
    "shapeNum=windoW.shape[1]\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(shapeNum,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='tanh')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(shapeNum, activation='linear')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input=input_img, output=decoded)\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input=input_img, output=encoded)\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(input=encoded_input, output=decoder_layer(encoded_input))\n",
    "\n",
    "autoencoder.compile(optimizer='adadelta', loss='mse')\n",
    "plot(autoencoder,  to_file=StudyDataModelPicPath+SaveFileNameNet+'.png')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "hist = autoencoder.fit(window_train, window_train,\n",
    "                nb_epoch=50,\n",
    "                batch_size=shapeNum/4,\n",
    "                shuffle=True,\n",
    "                validation_data=(window_test, window_test),\n",
    "                callbacks=[early_stopping])\n",
    "\n",
    "encoded_imgs = encoder.predict(window_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameEncord,encoded_imgs)\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameDecord,decoded_imgs)\n",
    "\n",
    "# save model and wights\n",
    "json_string = encoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameEncord+'.json', 'w').write(json_string)\n",
    "encoder.save_weights(StudyDataPath+SaveFileNameEncord+'_weights.h5')\n",
    "\n",
    "json_string = decoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameDecord+'.json', 'w').write(json_string)\n",
    "decoder.save_weights(StudyDataPath+SaveFileNameDecord+'_weights.h5')\n",
    "\n",
    "json_string = autoencoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameNet+'.json', 'w').write(json_string)\n",
    "autoencoder.save_weights(StudyDataPath+SaveFileNameNet+'_weights.h5')\n",
    "\n",
    "# plot loss\n",
    "loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "nb_epoch = len(loss)\n",
    "plt.plot(range(nb_epoch), loss, marker='.', label='loss')\n",
    "plt.plot(range(nb_epoch), val_loss, marker='.', label='val_loss')\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.savefig(SaveFileNameGlaph)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number=0\n",
      "0 is start 3000 is goal\n",
      "number=3000\n",
      "3000 is start 6000 is goal\n",
      "number=6000\n",
      "6000 is start 9000 is goal\n",
      "number=9000\n",
      "9000 is start 12000 is goal\n",
      "number=12000\n",
      "12000 is start 15000 is goal\n",
      "number=15000\n",
      "15000 is start 18000 is goal\n",
      "number=18000\n",
      "18000 is start 21000 is goal\n",
      "number=21000\n",
      "21000 is start 24000 is goal\n",
      "number=24000\n",
      "24000 is start 27000 is goal\n",
      "number=27000\n",
      "27000 is start 30000 is goal\n",
      "number=30000\n",
      "30000 is start 33000 is goal\n",
      "number=33000\n",
      "33000 is start 36000 is goal\n",
      "number=36000\n",
      "36000 is start 39000 is goal\n",
      "number=39000\n",
      "39000 is start 42000 is goal\n",
      "number=42000\n",
      "42000 is start 45000 is goal\n",
      "number=45000\n",
      "45000 is start 48000 is goal\n",
      "number=48000\n",
      "48000 is start 51000 is goal\n",
      "number=51000\n",
      "51000 is start 54000 is goal\n",
      "number=54000\n",
      "54000 is start 57000 is goal\n",
      "number=57000\n",
      "57000 is start 60000 is goal\n",
      "number=60000\n",
      "60000 is start 63000 is goal\n",
      "number=63000\n",
      "63000 is start 66000 is goal\n",
      "number=66000\n",
      "66000 is start 69000 is goal\n",
      "number=69000\n",
      "69000 is start 72000 is goal\n",
      "number=72000\n",
      "72000 is start 75000 is goal\n",
      "number=75000\n",
      "75000 is start 78000 is goal\n",
      "number=78000\n",
      "78000 is start 81000 is goal\n",
      "number=81000\n",
      "81000 is start 84000 is goal\n",
      "number=84000\n",
      "84000 is start 87000 is goal\n",
      "number=87000\n",
      "87000 is start 90000 is goal\n",
      "number=90000\n",
      "90000 is start 93000 is goal\n",
      "number=93000\n",
      "93000 is start 96000 is goal\n",
      "number=96000\n",
      "96000 is start 99000 is goal\n",
      "number=99000\n",
      "99000 is start 102000 is goal\n",
      "number=102000\n",
      "102000 is start 105000 is goal\n",
      "number=105000\n",
      "105000 is start 108000 is goal\n",
      "number=108000\n",
      "108000 is start 111000 is goal\n"
     ]
    }
   ],
   "source": [
    "rawData = windoW.reshape(windoW.size,1)\n",
    "reconstructed = decoded_imgs.reshape(decoded_imgs.size,1)\n",
    "for n in range(0,rawData.size,width):\n",
    "    print 'number='+str(n)\n",
    "    MakeGlaph(rawData, reconstructed, n, n+width,\n",
    "              GlaphDataPath+DataName+'_edim='+str(encoding_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次元数を減らしてみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define SaveFileName\n",
    "encoding_dim = 4  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "SaveFileNameEncord=DataName+'_encoded'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameDecord=DataName+'_decoded'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameNet=DataName+'_net'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameTrain=DataName+'_train'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameTest=DataName+'_test'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameGlaph=GlaphDataPath+DataName+'_edim='+str(encoding_dim)+'_loss_val_loss.png'\n",
    "\n",
    "window_test=windoW\n",
    "window_train=windoW\n",
    "\n",
    "shapeNum=windoW.shape[1]\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(shapeNum,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='tanh')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(shapeNum, activation='linear')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input=input_img, output=decoded)\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input=input_img, output=encoded)\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(input=encoded_input, output=decoder_layer(encoded_input))\n",
    "autoencoder.compile(optimizer='adadelta', loss='mse')\n",
    "plot(autoencoder,  to_file=StudyDataModelPicPath+SaveFileNameNet+'.png')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "hist = autoencoder.fit(window_train, window_train,\n",
    "                nb_epoch=50,\n",
    "                batch_size=shapeNum/4,\n",
    "                shuffle=True,\n",
    "                validation_data=(window_test, window_test),\n",
    "                callbacks=[early_stopping])\n",
    "\n",
    "encoded_imgs = encoder.predict(window_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameEncord,encoded_imgs)\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameDecord,decoded_imgs)\n",
    "\n",
    "# save model and wights\n",
    "json_string = encoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameEncord+'.json', 'w').write(json_string)\n",
    "encoder.save_weights(StudyDataPath+SaveFileNameEncord+'_weights.h5')\n",
    "\n",
    "json_string = decoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameDecord+'.json', 'w').write(json_string)\n",
    "decoder.save_weights(StudyDataPath+SaveFileNameDecord+'_weights.h5')\n",
    "\n",
    "json_string = autoencoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameNet+'.json', 'w').write(json_string)\n",
    "autoencoder.save_weights(StudyDataPath+SaveFileNameNet+'_weights.h5')\n",
    "\n",
    "# plot loss\n",
    "loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "nb_epoch = len(loss)\n",
    "plt.plot(range(nb_epoch), loss, marker='.', label='loss')\n",
    "plt.plot(range(nb_epoch), val_loss, marker='.', label='val_loss')\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.savefig(SaveFileNameGlaph)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rawData = windoW.reshape(windoW.size,1)\n",
    "reconstructed = decoded_imgs.reshape(decoded_imgs.size,1)\n",
    "for n in range(0,rawData.size,width):\n",
    "    print 'number='+str(n)\n",
    "    MakeGlaph(rawData, reconstructed, n, n+width,\n",
    "              GlaphDataPath+DataName+'_edim='+str(encoding_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次元数を増やしてみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define SaveFileName\n",
    "encoding_dim = 12  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "SaveFileNameEncord=DataName+'_encoded'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameDecord=DataName+'_decoded'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameNet=DataName+'_net'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameTrain=DataName+'_train'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameTest=DataName+'_test'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameGlaph=GlaphDataPath+DataName+'_edim='+str(encoding_dim)+'_loss_val_loss.png'\n",
    "\n",
    "window_test=windoW\n",
    "window_train=windoW\n",
    "\n",
    "shapeNum=windoW.shape[1]\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(shapeNum,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='tanh')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(shapeNum, activation='linear')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input=input_img, output=decoded)\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input=input_img, output=encoded)\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(input=encoded_input, output=decoder_layer(encoded_input))\n",
    "\n",
    "autoencoder.compile(optimizer='adadelta', loss='mse')\n",
    "plot(autoencoder,  to_file=StudyDataModelPicPath+SaveFileNameNet+'.png')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "hist = autoencoder.fit(window_train, window_train,\n",
    "                nb_epoch=50,\n",
    "                batch_size=shapeNum/4,\n",
    "                shuffle=True,\n",
    "                validation_data=(window_test, window_test),\n",
    "                callbacks=[early_stopping])\n",
    "\n",
    "encoded_imgs = encoder.predict(window_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameEncord,encoded_imgs)\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameDecord,decoded_imgs)\n",
    "\n",
    "# save model and wights\n",
    "json_string = encoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameEncord+'.json', 'w').write(json_string)\n",
    "encoder.save_weights(StudyDataPath+SaveFileNameEncord+'_weights.h5')\n",
    "\n",
    "json_string = decoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameDecord+'.json', 'w').write(json_string)\n",
    "decoder.save_weights(StudyDataPath+SaveFileNameDecord+'_weights.h5')\n",
    "\n",
    "json_string = autoencoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameNet+'.json', 'w').write(json_string)\n",
    "autoencoder.save_weights(StudyDataPath+SaveFileNameNet+'_weights.h5')\n",
    "\n",
    "# plot loss\n",
    "loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "nb_epoch = len(loss)\n",
    "plt.plot(range(nb_epoch), loss, marker='.', label='loss')\n",
    "plt.plot(range(nb_epoch), val_loss, marker='.', label='val_loss')\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.savefig(SaveFileNameGlaph)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rawData = windoW.reshape(windoW.size,1)\n",
    "reconstructed = decoded_imgs.reshape(decoded_imgs.size,1)\n",
    "for n in range(0,rawData.size,width):\n",
    "    print 'number='+str(n)\n",
    "    MakeGlaph(rawData, reconstructed, n, n+width,\n",
    "              GlaphDataPath+DataName+'_edim='+str(encoding_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次元数を入力創と同じ大きさにしてみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define SaveFileName\n",
    "encoding_dim = 16  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "SaveFileNameEncord=DataName+'_encoded'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameDecord=DataName+'_decoded'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameNet=DataName+'_net'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameTrain=DataName+'_train'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameTest=DataName+'_test'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameGlaph=GlaphDataPath+DataName+'_edim='+str(encoding_dim)+'_loss_val_loss.png'\n",
    "\n",
    "window_test=windoW\n",
    "window_train=windoW\n",
    "\n",
    "shapeNum=windoW.shape[1]\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(shapeNum,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='tanh')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(shapeNum, activation='linear')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input=input_img, output=decoded)\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input=input_img, output=encoded)\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(input=encoded_input, output=decoder_layer(encoded_input))\n",
    "\n",
    "autoencoder.compile(optimizer='adadelta', loss='mse')\n",
    "plot(autoencoder,  to_file=StudyDataModelPicPath+SaveFileNameNet+'.png')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "hist = autoencoder.fit(window_train, window_train,\n",
    "                nb_epoch=50,\n",
    "                batch_size=shapeNum/4,\n",
    "                shuffle=True,\n",
    "                validation_data=(window_test, window_test),\n",
    "                callbacks=[early_stopping])\n",
    "\n",
    "encoded_imgs = encoder.predict(window_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameEncord,encoded_imgs)\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameDecord,decoded_imgs)\n",
    "\n",
    "# save model and wights\n",
    "json_string = encoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameEncord+'.json', 'w').write(json_string)\n",
    "encoder.save_weights(StudyDataPath+SaveFileNameEncord+'_weights.h5')\n",
    "\n",
    "json_string = decoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameDecord+'.json', 'w').write(json_string)\n",
    "decoder.save_weights(StudyDataPath+SaveFileNameDecord+'_weights.h5')\n",
    "\n",
    "json_string = autoencoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameNet+'.json', 'w').write(json_string)\n",
    "autoencoder.save_weights(StudyDataPath+SaveFileNameNet+'_weights.h5')\n",
    "\n",
    "# plot loss\n",
    "loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "nb_epoch = len(loss)\n",
    "plt.plot(range(nb_epoch), loss, marker='.', label='loss')\n",
    "plt.plot(range(nb_epoch), val_loss, marker='.', label='val_loss')\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.savefig(SaveFileNameGlaph)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rawData = windoW.reshape(windoW.size,1)\n",
    "reconstructed = decoded_imgs.reshape(decoded_imgs.size,1)\n",
    "for n in range(0,rawData.size,width):\n",
    "    print 'number='+str(n)\n",
    "    MakeGlaph(rawData, reconstructed, n, n+width,\n",
    "              GlaphDataPath+DataName+'_edim='+str(encoding_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "入力層の大きさの２倍のノード数を隠れそうにする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define SaveFileName\n",
    "encoding_dim = 32  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "SaveFileNameEncord=DataName+'_encoded'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameDecord=DataName+'_decoded'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameNet=DataName+'_net'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameTrain=DataName+'_train'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameTest=DataName+'_test'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameGlaph=GlaphDataPath+DataName+'_edim='+str(encoding_dim)+'_loss_val_loss.png'\n",
    "\n",
    "window_test=windoW\n",
    "window_train=windoW\n",
    "\n",
    "shapeNum=windoW.shape[1]\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(shapeNum,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='tanh')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(shapeNum, activation='linear')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input=input_img, output=decoded)\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input=input_img, output=encoded)\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(input=encoded_input, output=decoder_layer(encoded_input))\n",
    "\n",
    "autoencoder.compile(optimizer='adadelta', loss='mse')\n",
    "plot(autoencoder,  to_file=StudyDataModelPicPath+SaveFileNameNet+'.png')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "hist = autoencoder.fit(window_train, window_train,\n",
    "                nb_epoch=50,\n",
    "                batch_size=shapeNum/4,\n",
    "                shuffle=True,\n",
    "                validation_data=(window_test, window_test),\n",
    "                callbacks=[early_stopping])\n",
    "\n",
    "encoded_imgs = encoder.predict(window_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameEncord,encoded_imgs)\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameDecord,decoded_imgs)\n",
    "\n",
    "# save model and wights\n",
    "json_string = encoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameEncord+'.json', 'w').write(json_string)\n",
    "encoder.save_weights(StudyDataPath+SaveFileNameEncord+'_weights.h5')\n",
    "\n",
    "json_string = decoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameDecord+'.json', 'w').write(json_string)\n",
    "decoder.save_weights(StudyDataPath+SaveFileNameDecord+'_weights.h5')\n",
    "\n",
    "json_string = autoencoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameNet+'.json', 'w').write(json_string)\n",
    "autoencoder.save_weights(StudyDataPath+SaveFileNameNet+'_weights.h5')\n",
    "\n",
    "# plot loss\n",
    "loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "nb_epoch = len(loss)\n",
    "plt.plot(range(nb_epoch), loss, marker='.', label='loss')\n",
    "plt.plot(range(nb_epoch), val_loss, marker='.', label='val_loss')\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.savefig(SaveFileNameGlaph)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rawData = windoW.reshape(windoW.size,1)\n",
    "reconstructed = decoded_imgs.reshape(decoded_imgs.size,1)\n",
    "for n in range(0,rawData.size,width):\n",
    "    print 'number='+str(n)\n",
    "    MakeGlaph(rawData, reconstructed, n, n+width,\n",
    "              GlaphDataPath+DataName+'_edim='+str(encoding_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "入力層の大きさの4倍のノード数を隠れそうにする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define SaveFileName\n",
    "encoding_dim = 64  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "SaveFileNameEncord=DataName+'_encoded'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameDecord=DataName+'_decoded'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameNet=DataName+'_net'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameTrain=DataName+'_train'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameTest=DataName+'_test'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameGlaph=GlaphDataPath+DataName+'_edim='+str(encoding_dim)+'_loss_val_loss.png'\n",
    "\n",
    "window_test=windoW\n",
    "window_train=windoW\n",
    "\n",
    "shapeNum=windoW.shape[1]\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(shapeNum,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='tanh')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(shapeNum, activation='linear')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input=input_img, output=decoded)\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input=input_img, output=encoded)\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(input=encoded_input, output=decoder_layer(encoded_input))\n",
    "\n",
    "autoencoder.compile(optimizer='adadelta', loss='mse')\n",
    "plot(autoencoder,  to_file=StudyDataModelPicPath+SaveFileNameNet+'.png')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "hist = autoencoder.fit(window_train, window_train,\n",
    "                nb_epoch=50,\n",
    "                batch_size=shapeNum/4,\n",
    "                shuffle=True,\n",
    "                validation_data=(window_test, window_test),\n",
    "                callbacks=[early_stopping])\n",
    "\n",
    "encoded_imgs = encoder.predict(window_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameEncord,encoded_imgs)\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameDecord,decoded_imgs)\n",
    "\n",
    "# save model and wights\n",
    "json_string = encoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameEncord+'.json', 'w').write(json_string)\n",
    "encoder.save_weights(StudyDataPath+SaveFileNameEncord+'_weights.h5')\n",
    "\n",
    "json_string = decoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameDecord+'.json', 'w').write(json_string)\n",
    "decoder.save_weights(StudyDataPath+SaveFileNameDecord+'_weights.h5')\n",
    "\n",
    "json_string = autoencoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameNet+'.json', 'w').write(json_string)\n",
    "autoencoder.save_weights(StudyDataPath+SaveFileNameNet+'_weights.h5')\n",
    "\n",
    "# plot loss\n",
    "loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "nb_epoch = len(loss)\n",
    "plt.plot(range(nb_epoch), loss, marker='.', label='loss')\n",
    "plt.plot(range(nb_epoch), val_loss, marker='.', label='val_loss')\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.savefig(SaveFileNameGlaph)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
