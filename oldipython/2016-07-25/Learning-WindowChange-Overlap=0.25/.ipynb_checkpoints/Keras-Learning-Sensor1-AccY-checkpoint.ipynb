{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SensorNum=1 # Sensor number\n",
    "WindowWidth=[16,32,64,128,256,512,1024] # Window Width\n",
    "OverlapArray=[4,8,16,32,64,128,256] # sliding window\n",
    "width=1000 # graph width \n",
    "EncodingDim=[4,8,12,16,32,64] # number of hidden layer note\n",
    "Axis='AccY' # Axis\n",
    "\n",
    "WORKSPACE_PATH = \"/media/takeyama/HD-PZU3/01_TAKEYAMA_WORKSPACE/02_CommonData/2016-07-25\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import fftpack\n",
    "from scipy import signal\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import pickle\n",
    "import copy\n",
    "\n",
    "import processing\n",
    "import window\n",
    "\n",
    "import matplotlib.animation as animation\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 1080 (CNMeM is disabled, cuDNN 5005)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.datasets import cifar10\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.utils.visualize_util import model_to_dot, plot\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import matplotlib.image as mpimg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DataName='sensor'+str(SensorNum)+'_'+Axis\n",
    "SensorName='sensor'+str(SensorNum)\n",
    "DicName='MemSensor'+str(SensorNum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(WORKSPACE_PATH+'/study/'+DataName+'/'): os.makedirs(WORKSPACE_PATH+'/study/'+DataName+'/')\n",
    "StudyDataPath=WORKSPACE_PATH+'/study/'+DataName+'/'\n",
    "\n",
    "if not os.path.exists(WORKSPACE_PATH+'/glaph/'+DataName+'/'): os.makedirs(WORKSPACE_PATH+'/glaph/'+DataName+'/')\n",
    "GlaphDataPath=WORKSPACE_PATH+'/glaph/'+DataName+'/'\n",
    "\n",
    "if not os.path.exists(WORKSPACE_PATH+'/modelPic/'+DataName+'/'): os.makedirs(WORKSPACE_PATH+'/modelPic/'+DataName+'/')\n",
    "StudyDataModelPicPath=WORKSPACE_PATH+'/modelPic/'+DataName+'/'\n",
    "\n",
    "if not os.path.exists(WORKSPACE_PATH+'/window/'+DataName+'/'): os.makedirs(WORKSPACE_PATH+'/window/'+DataName+'/')\n",
    "WindowDataPath=WORKSPACE_PATH+'/window/'+DataName+'/'\n",
    "\n",
    "RawDataPath=\"/media/takeyama/HD-PZU3/01_TAKEYAMA_WORKSPACE/02_CommonData/raw/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Phase1 計測データの取得**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dic=processing.LoadDicDataFromFileNPZ(RawDataPath+DicName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Phase2 window flame 作成 & Learning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AccY is registed now\n",
      "Build Complete\n",
      "(254742,)\n",
      "windowData's num =63682\n",
      "SourceData's aborting data = 2\n",
      "window shape is (63682, 16, 1)\n",
      "hiden node = 4\n",
      "Train on 63682 samples, validate on 63682 samples\n",
      "Epoch 1/50\n",
      "63682/63682 [==============================] - 26s - loss: 0.0080 - val_loss: 0.0013\n",
      "Epoch 2/50\n",
      "63682/63682 [==============================] - 25s - loss: 7.0663e-04 - val_loss: 4.5598e-04\n",
      "Epoch 3/50\n",
      "63682/63682 [==============================] - 24s - loss: 3.7785e-04 - val_loss: 3.4955e-04\n",
      "Epoch 4/50\n",
      "63682/63682 [==============================] - 18s - loss: 3.1666e-04 - val_loss: 2.8024e-04\n",
      "Epoch 5/50\n",
      "63682/63682 [==============================] - 14s - loss: 2.6368e-04 - val_loss: 2.2270e-04\n",
      "Epoch 6/50\n",
      "63682/63682 [==============================] - 13s - loss: 2.2210e-04 - val_loss: 1.8998e-04\n",
      "Epoch 7/50\n",
      "63682/63682 [==============================] - 14s - loss: 1.9168e-04 - val_loss: 1.8757e-04\n",
      "Epoch 8/50\n",
      "63682/63682 [==============================] - 14s - loss: 1.7378e-04 - val_loss: 1.9755e-04\n",
      "Epoch 9/50\n",
      "63682/63682 [==============================] - 16s - loss: 1.6329e-04 - val_loss: 1.4167e-04\n",
      "Epoch 10/50\n",
      "63682/63682 [==============================] - 15s - loss: 1.5509e-04 - val_loss: 1.6392e-04\n",
      "Epoch 11/50\n",
      "63682/63682 [==============================] - 15s - loss: 1.4913e-04 - val_loss: 1.4301e-04\n",
      "Epoch 12/50\n",
      "63682/63682 [==============================] - 17s - loss: 1.4456e-04 - val_loss: 1.2450e-04\n",
      "Epoch 13/50\n",
      "63682/63682 [==============================] - 23s - loss: 1.3948e-04 - val_loss: 1.2792e-04\n",
      "Epoch 14/50\n",
      "63682/63682 [==============================] - 24s - loss: 1.3502e-04 - val_loss: 3.0344e-04\n",
      "Epoch 15/50\n",
      "63682/63682 [==============================] - 24s - loss: 1.3252e-04 - val_loss: 4.8487e-04\n",
      "Epoch 16/50\n",
      "63682/63682 [==============================] - 24s - loss: 1.2856e-04 - val_loss: 1.4802e-04\n",
      "Epoch 17/50\n",
      "63682/63682 [==============================] - 23s - loss: 1.2579e-04 - val_loss: 1.2255e-04\n",
      "Epoch 18/50\n",
      "63682/63682 [==============================] - 24s - loss: 1.2294e-04 - val_loss: 1.0959e-04\n",
      "Epoch 19/50\n",
      "63682/63682 [==============================] - 24s - loss: 1.2132e-04 - val_loss: 1.1667e-04\n",
      "Epoch 20/50\n",
      "63682/63682 [==============================] - 24s - loss: 1.1831e-04 - val_loss: 1.0481e-04\n",
      "Epoch 21/50\n",
      "63682/63682 [==============================] - 26s - loss: 1.1643e-04 - val_loss: 9.7982e-05\n",
      "Epoch 22/50\n",
      "63682/63682 [==============================] - 25s - loss: 1.1441e-04 - val_loss: 9.5181e-05\n",
      "Epoch 23/50\n",
      "63682/63682 [==============================] - 33s - loss: 1.1296e-04 - val_loss: 1.0359e-04\n",
      "Epoch 24/50\n",
      "63682/63682 [==============================] - 37s - loss: 1.1111e-04 - val_loss: 9.8987e-05\n",
      "Epoch 25/50\n",
      "63682/63682 [==============================] - 36s - loss: 1.0926e-04 - val_loss: 9.6705e-05\n",
      "Epoch 26/50\n",
      "63682/63682 [==============================] - 37s - loss: 1.0654e-04 - val_loss: 1.0407e-04\n",
      "Epoch 27/50\n",
      "63682/63682 [==============================] - 37s - loss: 1.0491e-04 - val_loss: 8.7448e-05\n",
      "Epoch 28/50\n",
      "63682/63682 [==============================] - 37s - loss: 1.0403e-04 - val_loss: 9.5464e-05\n",
      "Epoch 29/50\n",
      "63682/63682 [==============================] - 37s - loss: 1.0246e-04 - val_loss: 1.0257e-04\n",
      "Epoch 30/50\n",
      "63682/63682 [==============================] - 37s - loss: 1.0057e-04 - val_loss: 8.2209e-05\n",
      "Epoch 31/50\n",
      "63682/63682 [==============================] - 37s - loss: 9.9823e-05 - val_loss: 8.7175e-05\n",
      "Epoch 32/50\n",
      "63682/63682 [==============================] - 37s - loss: 9.8357e-05 - val_loss: 8.5570e-05\n",
      "Epoch 33/50\n",
      "63682/63682 [==============================] - 37s - loss: 9.7312e-05 - val_loss: 8.3441e-05\n",
      "Epoch 34/50\n",
      "63682/63682 [==============================] - 36s - loss: 9.5740e-05 - val_loss: 1.0544e-04\n",
      "Epoch 35/50\n",
      "63682/63682 [==============================] - 37s - loss: 9.4432e-05 - val_loss: 7.8493e-05\n",
      "Epoch 36/50\n",
      "63682/63682 [==============================] - 37s - loss: 9.4205e-05 - val_loss: 7.8247e-05\n",
      "Epoch 37/50\n",
      "63682/63682 [==============================] - 37s - loss: 9.2613e-05 - val_loss: 8.8272e-05\n",
      "Epoch 38/50\n",
      "63682/63682 [==============================] - 37s - loss: 9.0796e-05 - val_loss: 7.2287e-05\n",
      "Epoch 39/50\n",
      "63682/63682 [==============================] - 36s - loss: 8.9871e-05 - val_loss: 7.7928e-05\n",
      "Epoch 40/50\n",
      "63682/63682 [==============================] - 37s - loss: 8.8905e-05 - val_loss: 7.6149e-05\n",
      "Epoch 41/50\n",
      "44448/63682 [===================>..........] - ETA: 6s - loss: 8.8286e-05\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-3f3ceef736b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m                         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m                         callbacks=[early_stopping])\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mencoded_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/takeyama/.pyenv/versions/2.7.11/envs/takeyama/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight)\u001b[0m\n\u001b[1;32m   1106\u001b[0m                               \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1108\u001b[0;31m                               callback_metrics=callback_metrics)\n\u001b[0m\u001b[1;32m   1109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/takeyama/.pyenv/versions/2.7.11/envs/takeyama/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics)\u001b[0m\n\u001b[1;32m    830\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# last batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/takeyama/.pyenv/versions/2.7.11/envs/takeyama/lib/python2.7/site-packages/keras/callbacks.pyc\u001b[0m in \u001b[0;36mon_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mt_before_callbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mdelta_t_median\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/takeyama/.pyenv/versions/2.7.11/envs/takeyama/lib/python2.7/site-packages/keras/callbacks.pyc\u001b[0m in \u001b[0;36mon_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;31m# will be handled by on_epoch_end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nb_sample'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/takeyama/.pyenv/versions/2.7.11/envs/takeyama/lib/python2.7/site-packages/keras/utils/generic_utils.pyc\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, current, values, force)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mprev_total_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_width\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\b\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mprev_total_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mnumdigits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/takeyama/.pyenv/versions/2.7.11/envs/takeyama/lib/python2.7/site-packages/ipykernel/iostream.pyc\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0mis_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_master_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_child\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                 \u001b[0;31m# newlines imply flush in subprocesses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: I/O operation on closed file"
     ]
    }
   ],
   "source": [
    "# loop windowWidth\n",
    "for SampleNum,Overlap in zip(WindowWidth,OverlapArray):\n",
    "    w=window.Window()\n",
    "    w.SetData(Axis,dic[Axis])\n",
    "    wind=w.Compile(windowWidth=SampleNum,overlapNum=Overlap)\n",
    "    windoW=wind.reshape((len(wind),np.prod(wind.shape[1:])))\n",
    "    \n",
    "    # define SaveFileName\n",
    "    for encoding_dim in EncodingDim:\n",
    "        print \"hiden node = \"+str(encoding_dim)\n",
    "        SaveFileNameEncord=DataName+'_encoded'+'_edim='+str(encoding_dim)+'-Window='+str(SampleNum)+'-Overlap='+str(Overlap*100)\n",
    "        SaveFileNameDecord=DataName+'_decoded'+'_edim='+str(encoding_dim)+'-Window='+str(SampleNum)+'-Overlap='+str(Overlap*100)\n",
    "        SaveFileNameNet=DataName+'_net'+'_edim='+str(encoding_dim)+'-Window='+str(SampleNum)+'-Overlap='+str(Overlap*100)\n",
    "        SaveFileNameTrain=DataName+'_train'+'_edim='+str(encoding_dim)+'-Window='+str(SampleNum)+'-Overlap='+str(Overlap*100)\n",
    "        SaveFileNameTest=DataName+'_test'+'_edim='+str(encoding_dim)+'-Window='+str(SampleNum)+'-Overlap='+str(Overlap*100)\n",
    "        SaveFileNameGlaph=GlaphDataPath+DataName+'_edim='+str(encoding_dim)+'-Window='+str(SampleNum)+'-Overlap='+str(Overlap*100)+'_loss_val_loss.png'\n",
    "\n",
    "        window_test=windoW\n",
    "        window_train=windoW\n",
    "        processing.SaveDicDataFromFileNPZ(WindowDataPath,SaveFileNameTrain,window_test)\n",
    "        processing.SaveDicDataFromFileNPZ(WindowDataPath,SaveFileNameTest,window_test)\n",
    "        shapeNum=windoW.shape[1]\n",
    "\n",
    "        # this is our input placeholder\n",
    "        input_img = Input(shape=(shapeNum,))\n",
    "        # \"encoded\" is the encoded representation of the input\n",
    "        encoded = Dense(encoding_dim, activation='tanh')(input_img)\n",
    "        # \"decoded\" is the lossy reconstruction of the input\n",
    "        decoded = Dense(shapeNum, activation='linear')(encoded)\n",
    "\n",
    "        # this model maps an input to its reconstruction\n",
    "        autoencoder = Model(input=input_img, output=decoded)\n",
    "\n",
    "        # this model maps an input to its encoded representation\n",
    "        encoder = Model(input=input_img, output=encoded)\n",
    "\n",
    "        # create a placeholder for an encoded (32-dimensional) input\n",
    "        encoded_input = Input(shape=(encoding_dim,))\n",
    "        # retrieve the last layer of the autoencoder model\n",
    "        decoder_layer = autoencoder.layers[-1]\n",
    "        # create the decoder model\n",
    "        decoder = Model(input=encoded_input, output=decoder_layer(encoded_input))\n",
    "\n",
    "        autoencoder.compile(optimizer='adadelta', loss='mse')\n",
    "        plot(autoencoder,  to_file=StudyDataModelPicPath+SaveFileNameNet+'.png')\n",
    "\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "        hist = autoencoder.fit(window_train, window_train,\n",
    "                        nb_epoch=50,\n",
    "                        batch_size=shapeNum/4,\n",
    "                        shuffle=True,\n",
    "                        validation_data=(window_test, window_test),\n",
    "                        callbacks=[early_stopping])\n",
    "        time.sleep(0.1)\n",
    "        encoded_imgs = encoder.predict(window_test)\n",
    "        decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "        processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameEncord,encoded_imgs)\n",
    "        processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameDecord,decoded_imgs)\n",
    "\n",
    "        # save model and wights\n",
    "        json_string = encoder.to_json()\n",
    "        open(StudyDataPath+SaveFileNameEncord+'.json', 'w').write(json_string)\n",
    "        encoder.save_weights(StudyDataPath+SaveFileNameEncord+'_weights.h5',overwrite=True)\n",
    "\n",
    "        json_string = decoder.to_json()\n",
    "        open(StudyDataPath+SaveFileNameDecord+'.json', 'w').write(json_string)\n",
    "        decoder.save_weights(StudyDataPath+SaveFileNameDecord+'_weights.h5',overwrite=True)\n",
    "\n",
    "        json_string = autoencoder.to_json()\n",
    "        open(StudyDataPath+SaveFileNameNet+'.json', 'w').write(json_string)\n",
    "        autoencoder.save_weights(StudyDataPath+SaveFileNameNet+'_weights.h5',overwrite=True)\n",
    "\n",
    "        # plot loss\n",
    "        loss = hist.history['loss']\n",
    "        val_loss = hist.history['val_loss']\n",
    "\n",
    "        nb_epoch = len(loss)\n",
    "        plt.plot(range(nb_epoch), loss, marker='.', label='loss')\n",
    "        plt.plot(range(nb_epoch), val_loss, marker='.', label='val_loss')\n",
    "        plt.legend(loc='best', fontsize=10)\n",
    "        plt.grid()\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('loss')\n",
    "        plt.savefig(SaveFileNameGlaph)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
