{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import fftpack\n",
    "from scipy import signal\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import pickle\n",
    "import copy\n",
    "import processing\n",
    "import matplotlib.animation as animation\n",
    "import datetime\n",
    "import window\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 970 (CNMeM is disabled, cuDNN 4007)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.datasets import cifar10\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.utils.visualize_util import model_to_dot, plot\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import matplotlib.image as mpimg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "共通変数をここに定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DataName='sensor4_AccXYZ'\n",
    "SensorName='sensor4'\n",
    "width=3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "WORKSPACE_PATH = '/home/takeyama/pywork/ipython/2016-07-04'\n",
    "\n",
    "    \n",
    "if not os.path.exists(WORKSPACE_PATH+'/'+DataName+'/study/'): os.makedirs(WORKSPACE_PATH+'/'+DataName+'/study/')\n",
    "StudyDataPath=WORKSPACE_PATH+'/'+DataName+'/study/'\n",
    "\n",
    "if not os.path.exists(WORKSPACE_PATH+'/'+DataName+'/glaph/'): os.makedirs(WORKSPACE_PATH+'/'+DataName+'/glaph/')\n",
    "GlaphDataPath=WORKSPACE_PATH+'/'+DataName+'/glaph/'\n",
    "\n",
    "if not os.path.exists(WORKSPACE_PATH+'/'+DataName+'/modelPic/'): os.makedirs(WORKSPACE_PATH+'/'+DataName+'/modelPic/')\n",
    "StudyDataModelPicPath=WORKSPACE_PATH+'/'+DataName+'/modelPic/'\n",
    "\n",
    "WindowDataPath=WORKSPACE_PATH+'/window/'\n",
    "RawDataPath=WORKSPACE_PATH+'/raw/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    encordData,decordData\n",
    "    firstNum:\n",
    "    goalNum:\n",
    "    commonLabel:共通名前\n",
    "\"\"\"\n",
    "def MakeGlaph(encordData,decordData,firstNum,goalNum,commonLabel):\n",
    "    eRow, eCol=encordData.shape\n",
    "    dRow, dCol=decordData.shape\n",
    "    if (eRow!=dRow) | (eCol!=dCol):\n",
    "        print 'check encordData & decordData'\n",
    "        return -1\n",
    "        \n",
    "    start = firstNum\n",
    "    goal=goalNum\n",
    "    print str(start)+' is start '+str(goal)+' is goal'\n",
    "    dataE = encordData.reshape(eRow*eCol,1)[start:goal]\n",
    "    dataD = decordData.reshape(dRow*dCol,1)[start:goal]\n",
    "    plt.figure(figsize=(100,50))\n",
    "    plt.plot(range(0,len(dataE)),dataE,'--r',label=\"Encoded\")\n",
    "    plt.plot(range(0,len(dataD)),dataD,'b',label=\"Decoded\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.title(str(start)+\"-\"+str(goal))\n",
    "    plt.savefig(commonLabel+'-'+str(start)+\"-\"+str(goal)+'-'+'glaph')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Phase1 計測データの取得**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dic1=processing.LoadDicDataFromFileNPZ(RawDataPath+\"MemSensor1\")\n",
    "dic2=processing.LoadDicDataFromFileNPZ(RawDataPath+\"MemSensor2\")\n",
    "dic3=processing.LoadDicDataFromFileNPZ(RawDataPath+\"MemSensor3\")\n",
    "dic4=processing.LoadDicDataFromFileNPZ(RawDataPath+\"MemSensor4\")\n",
    "dic5=processing.LoadDicDataFromFileNPZ(RawDataPath+\"MemSensor5\")\n",
    "dic6=processing.LoadDicDataFromFileNPZ(RawDataPath+\"MemSensor6\")\n",
    "dic7=processing.LoadDicDataFromFileNPZ(RawDataPath+\"MemSensor7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Phase2 window flame 作成**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = window.Window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AccX is registed now\n",
      "AccY is registed now\n",
      "AccZ is registed now\n"
     ]
    }
   ],
   "source": [
    "w.SetData('AccX',dic4['AccX'])\n",
    "w.SetData('AccY',dic4['AccY'])\n",
    "w.SetData('AccZ',dic4['AccZ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build Complete\n",
      "(254742, 3)\n"
     ]
    }
   ],
   "source": [
    "wind=w.Compile(windowWidth=16,overlap=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15921, 16, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wind.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "windoW=wind.reshape((len(wind),np.prod(wind.shape[1:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**前回やった学習をもう１度やってみる**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15921 samples, validate on 15921 samples\n",
      "Epoch 1/50\n",
      "15921/15921 [==============================] - 5s - loss: 0.0718 - val_loss: 0.0159\n",
      "Epoch 2/50\n",
      "15921/15921 [==============================] - 5s - loss: 0.0098 - val_loss: 0.0067\n",
      "Epoch 3/50\n",
      "15921/15921 [==============================] - 5s - loss: 0.0055 - val_loss: 0.0046\n",
      "Epoch 4/50\n",
      "15921/15921 [==============================] - 5s - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 5/50\n",
      "15921/15921 [==============================] - 5s - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 6/50\n",
      "15921/15921 [==============================] - 5s - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 7/50\n",
      "15921/15921 [==============================] - 5s - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 8/50\n",
      "15921/15921 [==============================] - 5s - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 9/50\n",
      "15921/15921 [==============================] - 5s - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 10/50\n",
      "15921/15921 [==============================] - 5s - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 11/50\n",
      "15921/15921 [==============================] - 5s - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 12/50\n",
      "15921/15921 [==============================] - 5s - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 13/50\n",
      "15921/15921 [==============================] - 5s - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 14/50\n",
      "15921/15921 [==============================] - 5s - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 15/50\n",
      "15921/15921 [==============================] - 5s - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 16/50\n",
      "15921/15921 [==============================] - 5s - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 17/50\n",
      "15921/15921 [==============================] - 5s - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 18/50\n",
      "15921/15921 [==============================] - 5s - loss: 0.0010 - val_loss: 9.5902e-04\n",
      "Epoch 19/50\n",
      "15921/15921 [==============================] - 4s - loss: 9.5584e-04 - val_loss: 9.7227e-04\n",
      "Epoch 20/50\n",
      "15921/15921 [==============================] - 5s - loss: 9.1010e-04 - val_loss: 9.0118e-04\n",
      "Epoch 21/50\n",
      "15921/15921 [==============================] - 5s - loss: 8.7007e-04 - val_loss: 8.9956e-04\n",
      "Epoch 22/50\n",
      "15921/15921 [==============================] - 5s - loss: 8.2826e-04 - val_loss: 8.0599e-04\n",
      "Epoch 23/50\n",
      "15921/15921 [==============================] - 5s - loss: 7.9904e-04 - val_loss: 7.5760e-04\n",
      "Epoch 24/50\n",
      "15921/15921 [==============================] - 5s - loss: 7.5588e-04 - val_loss: 7.2555e-04\n",
      "Epoch 25/50\n",
      "15921/15921 [==============================] - 5s - loss: 7.3234e-04 - val_loss: 6.7953e-04\n",
      "Epoch 26/50\n",
      "15921/15921 [==============================] - 5s - loss: 7.0941e-04 - val_loss: 6.9439e-04\n",
      "Epoch 27/50\n",
      "15921/15921 [==============================] - 5s - loss: 6.8234e-04 - val_loss: 6.5616e-04\n",
      "Epoch 28/50\n",
      "15921/15921 [==============================] - 5s - loss: 6.6398e-04 - val_loss: 6.2079e-04\n",
      "Epoch 29/50\n",
      "15921/15921 [==============================] - 5s - loss: 6.5515e-04 - val_loss: 6.1041e-04\n",
      "Epoch 30/50\n",
      "15921/15921 [==============================] - 5s - loss: 6.3419e-04 - val_loss: 6.2258e-04\n",
      "Epoch 31/50\n",
      "15921/15921 [==============================] - 5s - loss: 6.2187e-04 - val_loss: 5.6402e-04\n",
      "Epoch 32/50\n",
      "15921/15921 [==============================] - 4s - loss: 6.0758e-04 - val_loss: 5.5243e-04\n",
      "Epoch 33/50\n",
      "15921/15921 [==============================] - 3s - loss: 5.9509e-04 - val_loss: 5.4863e-04\n",
      "Epoch 34/50\n",
      "15921/15921 [==============================] - 3s - loss: 5.8691e-04 - val_loss: 5.5624e-04\n",
      "Epoch 35/50\n",
      "15921/15921 [==============================] - 4s - loss: 5.7153e-04 - val_loss: 5.7056e-04\n",
      "Epoch 36/50\n",
      "15921/15921 [==============================] - 4s - loss: 5.6701e-04 - val_loss: 5.4448e-04\n",
      "Epoch 37/50\n",
      "15921/15921 [==============================] - 4s - loss: 5.5415e-04 - val_loss: 5.7605e-04\n",
      "Epoch 38/50\n",
      "15921/15921 [==============================] - 2s - loss: 5.5673e-04 - val_loss: 5.2320e-04\n",
      "Epoch 39/50\n",
      "15921/15921 [==============================] - 2s - loss: 5.4073e-04 - val_loss: 4.9550e-04\n",
      "Epoch 40/50\n",
      "15921/15921 [==============================] - 2s - loss: 5.3940e-04 - val_loss: 4.9171e-04\n",
      "Epoch 41/50\n",
      "15921/15921 [==============================] - 2s - loss: 5.3329e-04 - val_loss: 4.8601e-04\n",
      "Epoch 42/50\n",
      "15921/15921 [==============================] - 2s - loss: 5.2801e-04 - val_loss: 4.6601e-04\n",
      "Epoch 43/50\n",
      "15921/15921 [==============================] - 2s - loss: 5.1303e-04 - val_loss: 4.7625e-04\n",
      "Epoch 44/50\n",
      "15921/15921 [==============================] - 2s - loss: 5.0919e-04 - val_loss: 4.9336e-04\n",
      "Epoch 45/50\n",
      "15921/15921 [==============================] - 2s - loss: 5.0688e-04 - val_loss: 4.5533e-04\n",
      "Epoch 46/50\n",
      "15921/15921 [==============================] - 2s - loss: 5.0453e-04 - val_loss: 5.1847e-04\n",
      "Epoch 47/50\n",
      "15921/15921 [==============================] - 2s - loss: 5.0022e-04 - val_loss: 4.6231e-04\n",
      "Epoch 48/50\n",
      "15921/15921 [==============================] - 2s - loss: 5.0226e-04 - val_loss: 4.4045e-04\n",
      "Epoch 49/50\n",
      "15921/15921 [==============================] - 2s - loss: 4.7974e-04 - val_loss: 4.8689e-04\n",
      "Epoch 50/50\n",
      "15921/15921 [==============================] - 2s - loss: 4.7916e-04 - val_loss: 4.3792e-04\n",
      "[WARNING] /home/takeyama/pywork/ipython/2016-07-04/sensor4_AccXYZ/study/sensor4_AccXYZ_encoded_edim=8_weights.h5 already exists - overwrite? [y/n]y\n",
      "[TIP] Next time specify overwrite=True in save_weights!\n",
      "[WARNING] /home/takeyama/pywork/ipython/2016-07-04/sensor4_AccXYZ/study/sensor4_AccXYZ_decoded_edim=8_weights.h5 already exists - overwrite? [y/n]y\n",
      "[TIP] Next time specify overwrite=True in save_weights!\n",
      "[WARNING] /home/takeyama/pywork/ipython/2016-07-04/sensor4_AccXYZ/study/sensor4_AccXYZ_net_edim=8_weights.h5 already exists - overwrite? [y/n]y\n",
      "[TIP] Next time specify overwrite=True in save_weights!\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEPCAYAAABRHfM8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f38e4ae2310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define SaveFileName\n",
    "encoding_dim = 8  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "SaveFileNameEncord=DataName+'_encoded'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameDecord=DataName+'_decoded'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameNet=DataName+'_net'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameTrain=DataName+'_train'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameTest=DataName+'_test'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameGlaph=GlaphDataPath+DataName+'_edim='+str(encoding_dim)+'_loss_val_loss.png'\n",
    "\n",
    "window_test=windoW\n",
    "window_train=windoW\n",
    "\n",
    "shapeNum=windoW.shape[1]\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(shapeNum,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='tanh')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(shapeNum, activation='linear')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input=input_img, output=decoded)\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input=input_img, output=encoded)\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(input=encoded_input, output=decoder_layer(encoded_input))\n",
    "\n",
    "autoencoder.compile(optimizer='adadelta', loss='mse')\n",
    "plot(autoencoder,  to_file=StudyDataModelPicPath+SaveFileNameNet+'.png')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "hist = autoencoder.fit(window_train, window_train,\n",
    "                nb_epoch=50,\n",
    "                batch_size=shapeNum/4,\n",
    "                shuffle=True,\n",
    "                validation_data=(window_test, window_test),\n",
    "                callbacks=[early_stopping])\n",
    "\n",
    "encoded_imgs = encoder.predict(window_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameEncord,encoded_imgs)\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameDecord,decoded_imgs)\n",
    "\n",
    "# save model and wights\n",
    "json_string = encoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameEncord+'.json', 'w').write(json_string)\n",
    "encoder.save_weights(StudyDataPath+SaveFileNameEncord+'_weights.h5')\n",
    "\n",
    "json_string = decoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameDecord+'.json', 'w').write(json_string)\n",
    "decoder.save_weights(StudyDataPath+SaveFileNameDecord+'_weights.h5')\n",
    "\n",
    "json_string = autoencoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameNet+'.json', 'w').write(json_string)\n",
    "autoencoder.save_weights(StudyDataPath+SaveFileNameNet+'_weights.h5')\n",
    "\n",
    "# plot loss\n",
    "loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "nb_epoch = len(loss)\n",
    "plt.plot(range(nb_epoch), loss, marker='.', label='loss')\n",
    "plt.plot(range(nb_epoch), val_loss, marker='.', label='val_loss')\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.savefig(SaveFileNameGlaph)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次元数を減らしてみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15921 samples, validate on 15921 samples\n",
      "Epoch 1/50\n",
      "15921/15921 [==============================] - 36s - loss: 0.0670 - val_loss: 0.0226\n",
      "Epoch 2/50\n",
      " 4152/15921 [======>.......................] - ETA: 13s - loss: 0.0192"
     ]
    }
   ],
   "source": [
    "# define SaveFileName\n",
    "encoding_dim = 4  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "SaveFileNameEncord=DataName+'_encoded'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameDecord=DataName+'_decoded'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameNet=DataName+'_net'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameTrain=DataName+'_train'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameTest=DataName+'_test'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameGlaph=GlaphDataPath+DataName+'_edim='+str(encoding_dim)+'_loss_val_loss.png'\n",
    "\n",
    "window_test=windoW\n",
    "window_train=windoW\n",
    "\n",
    "shapeNum=windoW.shape[1]\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(shapeNum,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='tanh')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(shapeNum, activation='linear')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input=input_img, output=decoded)\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input=input_img, output=encoded)\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(input=encoded_input, output=decoder_layer(encoded_input))\n",
    "autoencoder.compile(optimizer='adadelta', loss='mse')\n",
    "plot(autoencoder,  to_file=StudyDataModelPicPath+SaveFileNameNet+'.png')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "hist = autoencoder.fit(window_train, window_train,\n",
    "                nb_epoch=50,\n",
    "                batch_size=shapeNum/4,\n",
    "                shuffle=True,\n",
    "                validation_data=(window_test, window_test),\n",
    "                callbacks=[early_stopping])\n",
    "\n",
    "encoded_imgs = encoder.predict(window_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameEncord,encoded_imgs)\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameDecord,decoded_imgs)\n",
    "\n",
    "# save model and wights\n",
    "json_string = encoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameEncord+'.json', 'w').write(json_string)\n",
    "encoder.save_weights(StudyDataPath+SaveFileNameEncord+'_weights.h5')\n",
    "\n",
    "json_string = decoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameDecord+'.json', 'w').write(json_string)\n",
    "decoder.save_weights(StudyDataPath+SaveFileNameDecord+'_weights.h5')\n",
    "\n",
    "json_string = autoencoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameNet+'.json', 'w').write(json_string)\n",
    "autoencoder.save_weights(StudyDataPath+SaveFileNameNet+'_weights.h5')\n",
    "\n",
    "# plot loss\n",
    "loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "nb_epoch = len(loss)\n",
    "plt.plot(range(nb_epoch), loss, marker='.', label='loss')\n",
    "plt.plot(range(nb_epoch), val_loss, marker='.', label='val_loss')\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.savefig(SaveFileNameGlaph)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次元数を増やしてみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define SaveFileName\n",
    "encoding_dim = 12  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "SaveFileNameEncord=DataName+'_encoded'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameDecord=DataName+'_decoded'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameNet=DataName+'_net'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameTrain=DataName+'_train'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameTest=DataName+'_test'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameGlaph=GlaphDataPath+DataName+'_edim='+str(encoding_dim)+'_loss_val_loss.png'\n",
    "\n",
    "window_test=windoW\n",
    "window_train=windoW\n",
    "\n",
    "shapeNum=windoW.shape[1]\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(shapeNum,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='tanh')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(shapeNum, activation='linear')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input=input_img, output=decoded)\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input=input_img, output=encoded)\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(input=encoded_input, output=decoder_layer(encoded_input))\n",
    "\n",
    "autoencoder.compile(optimizer='adadelta', loss='mse')\n",
    "plot(autoencoder,  to_file=StudyDataModelPicPath+SaveFileNameNet+'.png')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "hist = autoencoder.fit(window_train, window_train,\n",
    "                nb_epoch=50,\n",
    "                batch_size=shapeNum/4,\n",
    "                shuffle=True,\n",
    "                validation_data=(window_test, window_test),\n",
    "                callbacks=[early_stopping])\n",
    "\n",
    "encoded_imgs = encoder.predict(window_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameEncord,encoded_imgs)\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameDecord,decoded_imgs)\n",
    "\n",
    "# save model and wights\n",
    "json_string = encoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameEncord+'.json', 'w').write(json_string)\n",
    "encoder.save_weights(StudyDataPath+SaveFileNameEncord+'_weights.h5')\n",
    "\n",
    "json_string = decoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameDecord+'.json', 'w').write(json_string)\n",
    "decoder.save_weights(StudyDataPath+SaveFileNameDecord+'_weights.h5')\n",
    "\n",
    "json_string = autoencoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameNet+'.json', 'w').write(json_string)\n",
    "autoencoder.save_weights(StudyDataPath+SaveFileNameNet+'_weights.h5')\n",
    "\n",
    "# plot loss\n",
    "loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "nb_epoch = len(loss)\n",
    "plt.plot(range(nb_epoch), loss, marker='.', label='loss')\n",
    "plt.plot(range(nb_epoch), val_loss, marker='.', label='val_loss')\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.savefig(SaveFileNameGlaph)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"rawAccX=wind[:wind.shape[0], :wind.shape[1], 0]\n",
    "rawAccY=wind[:wind.shape[0], :wind.shape[1], 1]\n",
    "rawAccZ=wind[:wind.shape[0], :wind.shape[1], 2]\n",
    "\n",
    "reconstructed = decoded_imgs.reshape(wind.shape)\n",
    "\n",
    "decordAccX=reconstructed[:reconstructed.shape[0], :reconstructed.shape[1], 0]\n",
    "decordAccY=reconstructed[:reconstructed.shape[0], :reconstructed.shape[1], 1]\n",
    "decordAccZ=reconstructed[:reconstructed.shape[0], :reconstructed.shape[1], 2]\n",
    "\n",
    "for n in range(0,rawAccX.size,width):\n",
    "    print 'number='+str(n)\n",
    "    MakeGlaph(rawAccX, decordAccX, n, n+width,\n",
    "              GlaphDataPath+DataName+'_edim='+str(encoding_dim)+'_AccX')\n",
    "\n",
    "for n in range(0,rawAccY.size,width):\n",
    "    print 'number='+str(n)\n",
    "    MakeGlaph(rawAccY, decordAccY, n, n+width,\n",
    "              GlaphDataPath+DataName+'_edim='+str(encoding_dim)+'_AccY')\n",
    "\n",
    "for n in range(0,rawAccZ.size,width):\n",
    "    print 'number='+str(n)\n",
    "    MakeGlaph(rawAccZ, decordAccZ, n, n+width,\n",
    "              GlaphDataPath+DataName+'_edim='+str(encoding_dim)+'_AccZ')\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次元数を入力創と同じ大きさにしてみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define SaveFileName\n",
    "encoding_dim = 16  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "SaveFileNameEncord=DataName+'_encoded'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameDecord=DataName+'_decoded'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameNet=DataName+'_net'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameTrain=DataName+'_train'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameTest=DataName+'_test'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameGlaph=GlaphDataPath+DataName+'_edim='+str(encoding_dim)+'_loss_val_loss.png'\n",
    "\n",
    "window_test=windoW\n",
    "window_train=windoW\n",
    "\n",
    "shapeNum=windoW.shape[1]\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(shapeNum,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='tanh')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(shapeNum, activation='linear')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input=input_img, output=decoded)\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input=input_img, output=encoded)\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(input=encoded_input, output=decoder_layer(encoded_input))\n",
    "\n",
    "autoencoder.compile(optimizer='adadelta', loss='mse')\n",
    "plot(autoencoder,  to_file=StudyDataModelPicPath+SaveFileNameNet+'.png')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "hist = autoencoder.fit(window_train, window_train,\n",
    "                nb_epoch=50,\n",
    "                batch_size=shapeNum/4,\n",
    "                shuffle=True,\n",
    "                validation_data=(window_test, window_test),\n",
    "                callbacks=[early_stopping])\n",
    "\n",
    "encoded_imgs = encoder.predict(window_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameEncord,encoded_imgs)\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameDecord,decoded_imgs)\n",
    "\n",
    "# save model and wights\n",
    "json_string = encoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameEncord+'.json', 'w').write(json_string)\n",
    "encoder.save_weights(StudyDataPath+SaveFileNameEncord+'_weights.h5')\n",
    "\n",
    "json_string = decoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameDecord+'.json', 'w').write(json_string)\n",
    "decoder.save_weights(StudyDataPath+SaveFileNameDecord+'_weights.h5')\n",
    "\n",
    "json_string = autoencoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameNet+'.json', 'w').write(json_string)\n",
    "autoencoder.save_weights(StudyDataPath+SaveFileNameNet+'_weights.h5')\n",
    "\n",
    "# plot loss\n",
    "loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "nb_epoch = len(loss)\n",
    "plt.plot(range(nb_epoch), loss, marker='.', label='loss')\n",
    "plt.plot(range(nb_epoch), val_loss, marker='.', label='val_loss')\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.savefig(SaveFileNameGlaph)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "入力層の大きさの２倍のノード数を隠れそうにする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define SaveFileName\n",
    "encoding_dim = 32  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "SaveFileNameEncord=DataName+'_encoded'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameDecord=DataName+'_decoded'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameNet=DataName+'_net'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameTrain=DataName+'_train'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameTest=DataName+'_test'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameGlaph=GlaphDataPath+DataName+'_edim='+str(encoding_dim)+'_loss_val_loss.png'\n",
    "\n",
    "window_test=windoW\n",
    "window_train=windoW\n",
    "\n",
    "shapeNum=windoW.shape[1]\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(shapeNum,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='tanh')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(shapeNum, activation='linear')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input=input_img, output=decoded)\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input=input_img, output=encoded)\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(input=encoded_input, output=decoder_layer(encoded_input))\n",
    "\n",
    "autoencoder.compile(optimizer='adadelta', loss='mse')\n",
    "plot(autoencoder,  to_file=StudyDataModelPicPath+SaveFileNameNet+'.png')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "hist = autoencoder.fit(window_train, window_train,\n",
    "                nb_epoch=50,\n",
    "                batch_size=shapeNum/4,\n",
    "                shuffle=True,\n",
    "                validation_data=(window_test, window_test),\n",
    "                callbacks=[early_stopping])\n",
    "\n",
    "encoded_imgs = encoder.predict(window_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameEncord,encoded_imgs)\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameDecord,decoded_imgs)\n",
    "\n",
    "# save model and wights\n",
    "json_string = encoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameEncord+'.json', 'w').write(json_string)\n",
    "encoder.save_weights(StudyDataPath+SaveFileNameEncord+'_weights.h5')\n",
    "\n",
    "json_string = decoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameDecord+'.json', 'w').write(json_string)\n",
    "decoder.save_weights(StudyDataPath+SaveFileNameDecord+'_weights.h5')\n",
    "\n",
    "json_string = autoencoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameNet+'.json', 'w').write(json_string)\n",
    "autoencoder.save_weights(StudyDataPath+SaveFileNameNet+'_weights.h5')\n",
    "\n",
    "# plot loss\n",
    "loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "nb_epoch = len(loss)\n",
    "plt.plot(range(nb_epoch), loss, marker='.', label='loss')\n",
    "plt.plot(range(nb_epoch), val_loss, marker='.', label='val_loss')\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.savefig(SaveFileNameGlaph)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "入力層の大きさの4倍のノード数を隠れそうにする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define SaveFileName\n",
    "encoding_dim = 64  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "SaveFileNameEncord=DataName+'_encoded'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameDecord=DataName+'_decoded'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameNet=DataName+'_net'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameTrain=DataName+'_train'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameTest=DataName+'_test'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameGlaph=GlaphDataPath+DataName+'_edim='+str(encoding_dim)+'_loss_val_loss.png'\n",
    "\n",
    "window_test=windoW\n",
    "window_train=windoW\n",
    "\n",
    "shapeNum=windoW.shape[1]\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(shapeNum,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='tanh')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(shapeNum, activation='linear')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input=input_img, output=decoded)\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input=input_img, output=encoded)\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(input=encoded_input, output=decoder_layer(encoded_input))\n",
    "\n",
    "autoencoder.compile(optimizer='adadelta', loss='mse')\n",
    "plot(autoencoder,  to_file=StudyDataModelPicPath+SaveFileNameNet+'.png')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "hist = autoencoder.fit(window_train, window_train,\n",
    "                nb_epoch=50,\n",
    "                batch_size=shapeNum/4,\n",
    "                shuffle=True,\n",
    "                validation_data=(window_test, window_test),\n",
    "                callbacks=[early_stopping])\n",
    "\n",
    "encoded_imgs = encoder.predict(window_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameEncord,encoded_imgs)\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameDecord,decoded_imgs)\n",
    "\n",
    "# save model and wights\n",
    "json_string = encoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameEncord+'.json', 'w').write(json_string)\n",
    "encoder.save_weights(StudyDataPath+SaveFileNameEncord+'_weights.h5')\n",
    "\n",
    "json_string = decoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameDecord+'.json', 'w').write(json_string)\n",
    "decoder.save_weights(StudyDataPath+SaveFileNameDecord+'_weights.h5')\n",
    "\n",
    "json_string = autoencoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameNet+'.json', 'w').write(json_string)\n",
    "autoencoder.save_weights(StudyDataPath+SaveFileNameNet+'_weights.h5')\n",
    "\n",
    "# plot loss\n",
    "loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "nb_epoch = len(loss)\n",
    "plt.plot(range(nb_epoch), loss, marker='.', label='loss')\n",
    "plt.plot(range(nb_epoch), val_loss, marker='.', label='val_loss')\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.savefig(SaveFileNameGlaph)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
