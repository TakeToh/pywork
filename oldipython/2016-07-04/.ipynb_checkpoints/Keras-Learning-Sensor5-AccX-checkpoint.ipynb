{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import fftpack\n",
    "from scipy import signal\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import pickle\n",
    "import copy\n",
    "import processing\n",
    "import matplotlib.animation as animation\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 970 (CNMeM is disabled, cuDNN 4007)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.datasets import cifar10\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.utils.visualize_util import model_to_dot, plot\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import matplotlib.image as mpimg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "共通変数をここに定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DataName='sensor3_AccX'\n",
    "SensorName='sensor3'\n",
    "width=3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "WORKSPACE_PATH = '/home/takeyama/pywork/ipython/2016-07-04'\n",
    "\n",
    "    \n",
    "if not os.path.exists(WORKSPACE_PATH+'/'+DataName+'/study/'): os.makedirs(WORKSPACE_PATH+'/'+DataName+'/study/')\n",
    "StudyDataPath=WORKSPACE_PATH+'/'+DataName+'/study/'\n",
    "\n",
    "if not os.path.exists(WORKSPACE_PATH+'/'+DataName+'/glaph/'): os.makedirs(WORKSPACE_PATH+'/'+DataName+'/glaph/')\n",
    "GlaphDataPath=WORKSPACE_PATH+'/'+DataName+'/glaph/'\n",
    "\n",
    "if not os.path.exists(WORKSPACE_PATH+'/'+DataName+'/modelPic/'): os.makedirs(WORKSPACE_PATH+'/'+DataName+'/modelPic/')\n",
    "StudyDataModelPicPath=WORKSPACE_PATH+'/'+DataName+'/modelPic/'\n",
    "\n",
    "WindowDataPath=WORKSPACE_PATH+'/window/'\n",
    "RawDataPath=WORKSPACE_PATH+'/raw/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    encordData,decordData\n",
    "    firstNum:\n",
    "    goalNum:\n",
    "    commonLabel:共通名前\n",
    "\"\"\"\n",
    "def MakeGlaph(encordData,decordData,firstNum,goalNum,commonLabel):\n",
    "    eRow, eCol=encordData.shape\n",
    "    dRow, dCol=decordData.shape\n",
    "    if (eRow!=dRow) | (eCol!=dCol):\n",
    "        print 'check encordData & decordData'\n",
    "        return -1\n",
    "        \n",
    "    start = firstNum\n",
    "    goal=goalNum\n",
    "    print str(start)+' is start '+str(goal)+' is goal'\n",
    "    dataE = encordData.reshape(eRow*eCol,1)[start:goal]\n",
    "    dataD = decordData.reshape(dRow*dCol,1)[start:goal]\n",
    "    plt.figure(figsize=(160,90))\n",
    "    plt.plot(range(0,len(dataE)),dataE,'--r',label=\"Encoded\")\n",
    "    plt.plot(range(0,len(dataD)),dataD,'b',label=\"Decoded\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.title(str(start)+\"-\"+str(goal))\n",
    "    plt.savefig(commonLabel+'-'+str(start)+\"-\"+str(goal)+'-'+'glaph')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Phase1 計測データの取得**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dic1=processing.LoadDicDataFromFileNPZ(RawDataPath+\"MemSensor1\")\n",
    "dic2=processing.LoadDicDataFromFileNPZ(RawDataPath+\"MemSensor2\")\n",
    "dic3=processing.LoadDicDataFromFileNPZ(RawDataPath+\"MemSensor3\")\n",
    "dic4=processing.LoadDicDataFromFileNPZ(RawDataPath+\"MemSensor4\")\n",
    "dic5=processing.LoadDicDataFromFileNPZ(RawDataPath+\"MemSensor5\")\n",
    "dic6=processing.LoadDicDataFromFileNPZ(RawDataPath+\"MemSensor6\")\n",
    "dic7=processing.LoadDicDataFromFileNPZ(RawDataPath+\"MemSensor7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Phase2 window flame 作成**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "windoW = processing.LoadDicDataFromFileNPZ(\"window/\"+str(SensorName)+\"_AccX_test.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15921, 16)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "windoW.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**前回やった学習をもう１度やってみる**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15921 samples, validate on 15921 samples\n",
      "Epoch 1/50\n",
      "15921/15921 [==============================] - 91s - loss: 0.0381 - val_loss: 0.0045\n",
      "Epoch 2/50\n",
      "15921/15921 [==============================] - 119s - loss: 0.0032 - val_loss: 0.0023\n",
      "Epoch 3/50\n",
      "15921/15921 [==============================] - 129s - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 4/50\n",
      "15921/15921 [==============================] - 129s - loss: 0.0011 - val_loss: 9.5017e-04\n",
      "Epoch 5/50\n",
      "15921/15921 [==============================] - 128s - loss: 8.7789e-04 - val_loss: 7.3466e-04\n",
      "Epoch 6/50\n",
      "15921/15921 [==============================] - 128s - loss: 7.3276e-04 - val_loss: 6.7192e-04\n",
      "Epoch 7/50\n",
      "15921/15921 [==============================] - 128s - loss: 6.5028e-04 - val_loss: 9.6802e-04\n",
      "Epoch 8/50\n",
      "15921/15921 [==============================] - 129s - loss: 5.7596e-04 - val_loss: 5.2527e-04\n",
      "Epoch 9/50\n",
      "15921/15921 [==============================] - 129s - loss: 5.2733e-04 - val_loss: 4.9869e-04\n",
      "Epoch 10/50\n",
      "15921/15921 [==============================] - 127s - loss: 4.8294e-04 - val_loss: 4.4025e-04\n",
      "Epoch 11/50\n",
      "15921/15921 [==============================] - 129s - loss: 4.4236e-04 - val_loss: 3.9220e-04\n",
      "Epoch 12/50\n",
      "15921/15921 [==============================] - 128s - loss: 4.1057e-04 - val_loss: 3.5443e-04\n",
      "Epoch 13/50\n",
      "15921/15921 [==============================] - 129s - loss: 3.8468e-04 - val_loss: 3.6183e-04\n",
      "Epoch 14/50\n",
      "15921/15921 [==============================] - 129s - loss: 3.6649e-04 - val_loss: 4.5419e-04\n",
      "Epoch 15/50\n",
      "15921/15921 [==============================] - 123s - loss: 3.4874e-04 - val_loss: 4.0196e-04\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEPCAYAAACHuClZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3b0aa3b890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define SaveFileName\n",
    "encoding_dim = 8  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "SaveFileNameEncord=DataName+'_encoded'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameDecord=DataName+'_decoded'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameNet=DataName+'_net'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameTrain=DataName+'_train'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameTest=DataName+'_test'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameGlaph=GlaphDataPath+DataName+'_edim='+str(encoding_dim)+'_loss_val_loss.png'\n",
    "\n",
    "window_test=windoW\n",
    "window_train=windoW\n",
    "\n",
    "shapeNum=windoW.shape[1]\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(shapeNum,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='tanh')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(shapeNum, activation='linear')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input=input_img, output=decoded)\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input=input_img, output=encoded)\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(input=encoded_input, output=decoder_layer(encoded_input))\n",
    "\n",
    "autoencoder.compile(optimizer='adadelta', loss='mse')\n",
    "plot(autoencoder,  to_file=StudyDataModelPicPath+SaveFileNameNet+'.png')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "hist = autoencoder.fit(window_train, window_train,\n",
    "                nb_epoch=50,\n",
    "                batch_size=shapeNum/4,\n",
    "                shuffle=True,\n",
    "                validation_data=(window_test, window_test),\n",
    "                callbacks=[early_stopping])\n",
    "\n",
    "encoded_imgs = encoder.predict(window_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameEncord,encoded_imgs)\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameDecord,decoded_imgs)\n",
    "\n",
    "# save model and wights\n",
    "json_string = encoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameEncord+'.json', 'w').write(json_string)\n",
    "encoder.save_weights(StudyDataPath+SaveFileNameEncord+'_weights.h5')\n",
    "\n",
    "json_string = decoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameDecord+'.json', 'w').write(json_string)\n",
    "decoder.save_weights(StudyDataPath+SaveFileNameDecord+'_weights.h5')\n",
    "\n",
    "json_string = autoencoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameNet+'.json', 'w').write(json_string)\n",
    "autoencoder.save_weights(StudyDataPath+SaveFileNameNet+'_weights.h5')\n",
    "\n",
    "# plot loss\n",
    "loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "nb_epoch = len(loss)\n",
    "plt.plot(range(nb_epoch), loss, marker='.', label='loss')\n",
    "plt.plot(range(nb_epoch), val_loss, marker='.', label='val_loss')\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.savefig(SaveFileNameGlaph)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number=0\n",
      "0 is start 3000 is goal\n",
      "number=3000\n",
      "3000 is start 6000 is goal\n",
      "number=6000\n",
      "6000 is start 9000 is goal\n",
      "number=9000\n",
      "9000 is start 12000 is goal\n",
      "number=12000\n",
      "12000 is start 15000 is goal\n",
      "number=15000\n",
      "15000 is start 18000 is goal\n",
      "number=18000\n",
      "18000 is start 21000 is goal\n",
      "number=21000\n",
      "21000 is start 24000 is goal\n",
      "number=24000\n",
      "24000 is start 27000 is goal\n"
     ]
    }
   ],
   "source": [
    "rawData = windoW.reshape(windoW.size,1)\n",
    "reconstructed = decoded_imgs.reshape(decoded_imgs.size,1)\n",
    "for n in range(0,rawData.size,width):\n",
    "    print 'number='+str(n)\n",
    "    MakeGlaph(rawData, reconstructed, n, n+width,\n",
    "              GlaphDataPath+DataName+'_edim='+str(encoding_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次元数を減らしてみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define SaveFileName\n",
    "encoding_dim = 4  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "SaveFileNameEncord=DataName+'_encoded'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameDecord=DataName+'_decoded'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameNet=DataName+'_net'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameTrain=DataName+'_train'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameTest=DataName+'_test'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameGlaph=GlaphDataPath+DataName+'_edim='+str(encoding_dim)+'_loss_val_loss.png'\n",
    "\n",
    "window_test=windoW\n",
    "window_train=windoW\n",
    "\n",
    "shapeNum=windoW.shape[1]\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(shapeNum,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='tanh')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(shapeNum, activation='linear')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input=input_img, output=decoded)\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input=input_img, output=encoded)\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(input=encoded_input, output=decoder_layer(encoded_input))\n",
    "autoencoder.compile(optimizer='adadelta', loss='mse')\n",
    "plot(autoencoder,  to_file=StudyDataModelPicPath+SaveFileNameNet+'.png')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "hist = autoencoder.fit(window_train, window_train,\n",
    "                nb_epoch=50,\n",
    "                batch_size=shapeNum/4,\n",
    "                shuffle=True,\n",
    "                validation_data=(window_test, window_test),\n",
    "                callbacks=[early_stopping])\n",
    "\n",
    "encoded_imgs = encoder.predict(window_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameEncord,encoded_imgs)\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameDecord,decoded_imgs)\n",
    "\n",
    "# save model and wights\n",
    "json_string = encoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameEncord+'.json', 'w').write(json_string)\n",
    "encoder.save_weights(StudyDataPath+SaveFileNameEncord+'_weights.h5')\n",
    "\n",
    "json_string = decoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameDecord+'.json', 'w').write(json_string)\n",
    "decoder.save_weights(StudyDataPath+SaveFileNameDecord+'_weights.h5')\n",
    "\n",
    "json_string = autoencoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameNet+'.json', 'w').write(json_string)\n",
    "autoencoder.save_weights(StudyDataPath+SaveFileNameNet+'_weights.h5')\n",
    "\n",
    "# plot loss\n",
    "loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "nb_epoch = len(loss)\n",
    "plt.plot(range(nb_epoch), loss, marker='.', label='loss')\n",
    "plt.plot(range(nb_epoch), val_loss, marker='.', label='val_loss')\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.savefig(SaveFileNameGlaph)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rawData = windoW.reshape(windoW.size,1)\n",
    "reconstructed = decoded_imgs.reshape(decoded_imgs.size,1)\n",
    "for n in range(0,rawData.size,width):\n",
    "    print 'number='+str(n)\n",
    "    MakeGlaph(rawData, reconstructed, n, n+width,\n",
    "              GlaphDataPath+DataName+'_edim='+str(encoding_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次元数を増やしてみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define SaveFileName\n",
    "encoding_dim = 12  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "SaveFileNameEncord=DataName+'_encoded'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameDecord=DataName+'_decoded'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameNet=DataName+'_net'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameTrain=DataName+'_train'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameTest=DataName+'_test'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameGlaph=GlaphDataPath+DataName+'_edim='+str(encoding_dim)+'_loss_val_loss.png'\n",
    "\n",
    "window_test=windoW\n",
    "window_train=windoW\n",
    "\n",
    "shapeNum=windoW.shape[1]\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(shapeNum,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='tanh')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(shapeNum, activation='linear')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input=input_img, output=decoded)\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input=input_img, output=encoded)\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(input=encoded_input, output=decoder_layer(encoded_input))\n",
    "\n",
    "autoencoder.compile(optimizer='adadelta', loss='mse')\n",
    "plot(autoencoder,  to_file=StudyDataModelPicPath+SaveFileNameNet+'.png')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "hist = autoencoder.fit(window_train, window_train,\n",
    "                nb_epoch=50,\n",
    "                batch_size=shapeNum/4,\n",
    "                shuffle=True,\n",
    "                validation_data=(window_test, window_test),\n",
    "                callbacks=[early_stopping])\n",
    "\n",
    "encoded_imgs = encoder.predict(window_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameEncord,encoded_imgs)\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameDecord,decoded_imgs)\n",
    "\n",
    "# save model and wights\n",
    "json_string = encoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameEncord+'.json', 'w').write(json_string)\n",
    "encoder.save_weights(StudyDataPath+SaveFileNameEncord+'_weights.h5')\n",
    "\n",
    "json_string = decoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameDecord+'.json', 'w').write(json_string)\n",
    "decoder.save_weights(StudyDataPath+SaveFileNameDecord+'_weights.h5')\n",
    "\n",
    "json_string = autoencoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameNet+'.json', 'w').write(json_string)\n",
    "autoencoder.save_weights(StudyDataPath+SaveFileNameNet+'_weights.h5')\n",
    "\n",
    "# plot loss\n",
    "loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "nb_epoch = len(loss)\n",
    "plt.plot(range(nb_epoch), loss, marker='.', label='loss')\n",
    "plt.plot(range(nb_epoch), val_loss, marker='.', label='val_loss')\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.savefig(SaveFileNameGlaph)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rawData = windoW.reshape(windoW.size,1)\n",
    "reconstructed = decoded_imgs.reshape(decoded_imgs.size,1)\n",
    "for n in range(0,rawData.size,width):\n",
    "    print 'number='+str(n)\n",
    "    MakeGlaph(rawData, reconstructed, n, n+width,\n",
    "              GlaphDataPath+DataName+'_edim='+str(encoding_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次元数を入力創と同じ大きさにしてみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define SaveFileName\n",
    "encoding_dim = 16  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "SaveFileNameEncord=DataName+'_encoded'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameDecord=DataName+'_decoded'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameNet=DataName+'_net'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameTrain=DataName+'_train'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameTest=DataName+'_test'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameGlaph=GlaphDataPath+DataName+'_edim='+str(encoding_dim)+'_loss_val_loss.png'\n",
    "\n",
    "window_test=windoW\n",
    "window_train=windoW\n",
    "\n",
    "shapeNum=windoW.shape[1]\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(shapeNum,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='tanh')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(shapeNum, activation='linear')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input=input_img, output=decoded)\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input=input_img, output=encoded)\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(input=encoded_input, output=decoder_layer(encoded_input))\n",
    "\n",
    "autoencoder.compile(optimizer='adadelta', loss='mse')\n",
    "plot(autoencoder,  to_file=StudyDataModelPicPath+SaveFileNameNet+'.png')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "hist = autoencoder.fit(window_train, window_train,\n",
    "                nb_epoch=50,\n",
    "                batch_size=shapeNum/4,\n",
    "                shuffle=True,\n",
    "                validation_data=(window_test, window_test),\n",
    "                callbacks=[early_stopping])\n",
    "\n",
    "encoded_imgs = encoder.predict(window_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameEncord,encoded_imgs)\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameDecord,decoded_imgs)\n",
    "\n",
    "# save model and wights\n",
    "json_string = encoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameEncord+'.json', 'w').write(json_string)\n",
    "encoder.save_weights(StudyDataPath+SaveFileNameEncord+'_weights.h5')\n",
    "\n",
    "json_string = decoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameDecord+'.json', 'w').write(json_string)\n",
    "decoder.save_weights(StudyDataPath+SaveFileNameDecord+'_weights.h5')\n",
    "\n",
    "json_string = autoencoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameNet+'.json', 'w').write(json_string)\n",
    "autoencoder.save_weights(StudyDataPath+SaveFileNameNet+'_weights.h5')\n",
    "\n",
    "# plot loss\n",
    "loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "nb_epoch = len(loss)\n",
    "plt.plot(range(nb_epoch), loss, marker='.', label='loss')\n",
    "plt.plot(range(nb_epoch), val_loss, marker='.', label='val_loss')\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.savefig(SaveFileNameGlaph)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rawData = windoW.reshape(windoW.size,1)\n",
    "reconstructed = decoded_imgs.reshape(decoded_imgs.size,1)\n",
    "for n in range(0,rawData.size,width):\n",
    "    print 'number='+str(n)\n",
    "    MakeGlaph(rawData, reconstructed, n, n+width,\n",
    "              GlaphDataPath+DataName+'_edim='+str(encoding_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "入力層の大きさの２倍のノード数を隠れそうにする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define SaveFileName\n",
    "encoding_dim = 32  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "SaveFileNameEncord=DataName+'_encoded'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameDecord=DataName+'_decoded'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameNet=DataName+'_net'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameTrain=DataName+'_train'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameTest=DataName+'_test'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameGlaph=GlaphDataPath+DataName+'_edim='+str(encoding_dim)+'_loss_val_loss.png'\n",
    "\n",
    "window_test=windoW\n",
    "window_train=windoW\n",
    "\n",
    "shapeNum=windoW.shape[1]\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(shapeNum,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='tanh')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(shapeNum, activation='linear')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input=input_img, output=decoded)\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input=input_img, output=encoded)\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(input=encoded_input, output=decoder_layer(encoded_input))\n",
    "\n",
    "autoencoder.compile(optimizer='adadelta', loss='mse')\n",
    "plot(autoencoder,  to_file=StudyDataModelPicPath+SaveFileNameNet+'.png')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "hist = autoencoder.fit(window_train, window_train,\n",
    "                nb_epoch=50,\n",
    "                batch_size=shapeNum/4,\n",
    "                shuffle=True,\n",
    "                validation_data=(window_test, window_test),\n",
    "                callbacks=[early_stopping])\n",
    "\n",
    "encoded_imgs = encoder.predict(window_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameEncord,encoded_imgs)\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameDecord,decoded_imgs)\n",
    "\n",
    "# save model and wights\n",
    "json_string = encoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameEncord+'.json', 'w').write(json_string)\n",
    "encoder.save_weights(StudyDataPath+SaveFileNameEncord+'_weights.h5')\n",
    "\n",
    "json_string = decoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameDecord+'.json', 'w').write(json_string)\n",
    "decoder.save_weights(StudyDataPath+SaveFileNameDecord+'_weights.h5')\n",
    "\n",
    "json_string = autoencoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameNet+'.json', 'w').write(json_string)\n",
    "autoencoder.save_weights(StudyDataPath+SaveFileNameNet+'_weights.h5')\n",
    "\n",
    "# plot loss\n",
    "loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "nb_epoch = len(loss)\n",
    "plt.plot(range(nb_epoch), loss, marker='.', label='loss')\n",
    "plt.plot(range(nb_epoch), val_loss, marker='.', label='val_loss')\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.savefig(SaveFileNameGlaph)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rawData = windoW.reshape(windoW.size,1)\n",
    "reconstructed = decoded_imgs.reshape(decoded_imgs.size,1)\n",
    "for n in range(0,rawData.size,width):\n",
    "    print 'number='+str(n)\n",
    "    MakeGlaph(rawData, reconstructed, n, n+width,\n",
    "              GlaphDataPath+DataName+'_edim='+str(encoding_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "入力層の大きさの4倍のノード数を隠れそうにする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define SaveFileName\n",
    "encoding_dim = 64  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "SaveFileNameEncord=DataName+'_encoded'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameDecord=DataName+'_decoded'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameNet=DataName+'_net'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameTrain=DataName+'_train'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameTest=DataName+'_test'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameGlaph=GlaphDataPath+DataName+'_edim='+str(encoding_dim)+'_loss_val_loss.png'\n",
    "\n",
    "window_test=windoW\n",
    "window_train=windoW\n",
    "\n",
    "shapeNum=windoW.shape[1]\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(shapeNum,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='tanh')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(shapeNum, activation='linear')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input=input_img, output=decoded)\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input=input_img, output=encoded)\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(input=encoded_input, output=decoder_layer(encoded_input))\n",
    "\n",
    "autoencoder.compile(optimizer='adadelta', loss='mse')\n",
    "plot(autoencoder,  to_file=StudyDataModelPicPath+SaveFileNameNet+'.png')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "hist = autoencoder.fit(window_train, window_train,\n",
    "                nb_epoch=50,\n",
    "                batch_size=shapeNum/4,\n",
    "                shuffle=True,\n",
    "                validation_data=(window_test, window_test),\n",
    "                callbacks=[early_stopping])\n",
    "\n",
    "encoded_imgs = encoder.predict(window_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameEncord,encoded_imgs)\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameDecord,decoded_imgs)\n",
    "\n",
    "# save model and wights\n",
    "json_string = encoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameEncord+'.json', 'w').write(json_string)\n",
    "encoder.save_weights(StudyDataPath+SaveFileNameEncord+'_weights.h5')\n",
    "\n",
    "json_string = decoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameDecord+'.json', 'w').write(json_string)\n",
    "decoder.save_weights(StudyDataPath+SaveFileNameDecord+'_weights.h5')\n",
    "\n",
    "json_string = autoencoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameNet+'.json', 'w').write(json_string)\n",
    "autoencoder.save_weights(StudyDataPath+SaveFileNameNet+'_weights.h5')\n",
    "\n",
    "# plot loss\n",
    "loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "nb_epoch = len(loss)\n",
    "plt.plot(range(nb_epoch), loss, marker='.', label='loss')\n",
    "plt.plot(range(nb_epoch), val_loss, marker='.', label='val_loss')\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.savefig(SaveFileNameGlaph)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
