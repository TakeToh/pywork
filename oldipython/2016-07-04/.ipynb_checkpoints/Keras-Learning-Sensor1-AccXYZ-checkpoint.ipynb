{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import fftpack\n",
    "from scipy import signal\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import pickle\n",
    "import copy\n",
    "import processing\n",
    "import matplotlib.animation as animation\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 970 (CNMeM is disabled, cuDNN 4007)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.datasets import cifar10\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.utils.visualize_util import model_to_dot, plot\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import matplotlib.image as mpimg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "共通変数をここに定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DataName='sensor1_AccX'\n",
    "SensorName='sensor1'\n",
    "width=3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "WORKSPACE_PATH = '/home/takeyama/pywork/ipython/2016-07-04'\n",
    "\n",
    "    \n",
    "if not os.path.exists(WORKSPACE_PATH+'/'+DataName+'/study/'): os.makedirs(WORKSPACE_PATH+'/'+DataName+'/study/')\n",
    "StudyDataPath=WORKSPACE_PATH+'/'+DataName+'/study/'\n",
    "\n",
    "if not os.path.exists(WORKSPACE_PATH+'/'+DataName+'/glaph/'): os.makedirs(WORKSPACE_PATH+'/'+DataName+'/glaph/')\n",
    "GlaphDataPath=WORKSPACE_PATH+'/'+DataName+'/glaph/'\n",
    "\n",
    "if not os.path.exists(WORKSPACE_PATH+'/'+DataName+'/modelPic/'): os.makedirs(WORKSPACE_PATH+'/'+DataName+'/modelPic/')\n",
    "StudyDataModelPicPath=WORKSPACE_PATH+'/'+DataName+'/modelPic/'\n",
    "\n",
    "WindowDataPath=WORKSPACE_PATH+'/window/'\n",
    "RawDataPath=WORKSPACE_PATH+'/raw/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    encordData,decordData\n",
    "    firstNum:\n",
    "    goalNum:\n",
    "    commonLabel:共通名前\n",
    "\"\"\"\n",
    "def MakeGlaph(encordData,decordData,firstNum,goalNum,commonLabel):\n",
    "    eRow, eCol=encordData.shape\n",
    "    dRow, dCol=decordData.shape\n",
    "    if (eRow!=dRow) | (eCol!=dCol):\n",
    "        print 'check encordData & decordData'\n",
    "        return -1\n",
    "        \n",
    "    start = firstNum\n",
    "    goal=goalNum\n",
    "    print str(start)+' is start '+str(goal)+' is goal'\n",
    "    dataE = encordData.reshape(eRow*eCol,1)[start:goal]\n",
    "    dataD = decordData.reshape(dRow*dCol,1)[start:goal]\n",
    "    plt.figure(figsize=(100,50))\n",
    "    plt.plot(range(0,len(dataE)),dataE,'--r',label=\"Encoded\")\n",
    "    plt.plot(range(0,len(dataD)),dataD,'b',label=\"Decoded\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.title(str(start)+\"-\"+str(goal))\n",
    "    plt.savefig(commonLabel+'-'+str(start)+\"-\"+str(goal)+'-'+'glaph')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Phase1 計測データの取得**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dic1=processing.LoadDicDataFromFileNPZ(RawDataPath+\"MemSensor1\")\n",
    "dic2=processing.LoadDicDataFromFileNPZ(RawDataPath+\"MemSensor2\")\n",
    "dic3=processing.LoadDicDataFromFileNPZ(RawDataPath+\"MemSensor3\")\n",
    "dic4=processing.LoadDicDataFromFileNPZ(RawDataPath+\"MemSensor4\")\n",
    "dic5=processing.LoadDicDataFromFileNPZ(RawDataPath+\"MemSensor5\")\n",
    "dic6=processing.LoadDicDataFromFileNPZ(RawDataPath+\"MemSensor6\")\n",
    "dic7=processing.LoadDicDataFromFileNPZ(RawDataPath+\"MemSensor7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Phase2 window flame 作成**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "windoW = processing.LoadDicDataFromFileNPZ(\"window/\"+str(SensorName)+\"_AccX_test.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15921, 16)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "windoW.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**前回やった学習をもう１度やってみる**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15921 samples, validate on 15921 samples\n",
      "Epoch 1/50\n",
      "15921/15921 [==============================] - 29s - loss: 0.0310 - val_loss: 0.0032\n",
      "Epoch 2/50\n",
      "15921/15921 [==============================] - 33s - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 3/50\n",
      "15921/15921 [==============================] - 35s - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 4/50\n",
      "15921/15921 [==============================] - 36s - loss: 0.0012 - val_loss: 9.3704e-04\n",
      "Epoch 5/50\n",
      "15921/15921 [==============================] - 81s - loss: 8.2452e-04 - val_loss: 0.0015\n",
      "Epoch 6/50\n",
      "15921/15921 [==============================] - 99s - loss: 6.1158e-04 - val_loss: 4.9905e-04\n",
      "Epoch 7/50\n",
      "15920/15921 [============================>.] - ETA: 0s - loss: 5.0170e-04"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-948d149ed877>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     43\u001b[0m                 \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m                 \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwindow_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m                 callbacks=[early_stopping])\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[0mencoded_imgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwindow_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/takeyama/.pyenv/versions/takeyama/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight)\u001b[0m\n\u001b[0;32m   1051\u001b[0m                               \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1053\u001b[1;33m                               callback_metrics=callback_metrics)\n\u001b[0m\u001b[0;32m   1054\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1055\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/takeyama/.pyenv/versions/takeyama/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics)\u001b[0m\n\u001b[0;32m    804\u001b[0m                         val_outs = self._test_loop(val_f, val_ins,\n\u001b[0;32m    805\u001b[0m                                                    \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 806\u001b[1;33m                                                    verbose=0)\n\u001b[0m\u001b[0;32m    807\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    808\u001b[0m                             \u001b[0mval_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/takeyama/.pyenv/versions/takeyama/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_test_loop\u001b[1;34m(self, f, ins, batch_size, verbose)\u001b[0m\n\u001b[0;32m    889\u001b[0m                 \u001b[0mins_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslice_X\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/takeyama/.pyenv/versions/takeyama/lib/python2.7/site-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    516\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 518\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    519\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/takeyama/.pyenv/versions/takeyama/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# define SaveFileName\n",
    "encoding_dim = 8  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "SaveFileNameEncord=DataName+'_encoded'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameDecord=DataName+'_decoded'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameNet=DataName+'_net'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameTrain=DataName+'_train'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameTest=DataName+'_test'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameGlaph=GlaphDataPath+DataName+'_edim='+str(encoding_dim)+'_loss_val_loss.png'\n",
    "\n",
    "window_test=windoW\n",
    "window_train=windoW\n",
    "\n",
    "shapeNum=windoW.shape[1]\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(shapeNum,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='tanh')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(shapeNum, activation='linear')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input=input_img, output=decoded)\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input=input_img, output=encoded)\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(input=encoded_input, output=decoder_layer(encoded_input))\n",
    "\n",
    "autoencoder.compile(optimizer='adadelta', loss='mse')\n",
    "plot(autoencoder,  to_file=StudyDataModelPicPath+SaveFileNameNet+'.png')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "hist = autoencoder.fit(window_train, window_train,\n",
    "                nb_epoch=50,\n",
    "                batch_size=shapeNum/4,\n",
    "                shuffle=True,\n",
    "                validation_data=(window_test, window_test),\n",
    "                callbacks=[early_stopping])\n",
    "\n",
    "encoded_imgs = encoder.predict(window_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameEncord,encoded_imgs)\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameDecord,decoded_imgs)\n",
    "\n",
    "# save model and wights\n",
    "json_string = encoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameEncord+'.json', 'w').write(json_string)\n",
    "encoder.save_weights(StudyDataPath+SaveFileNameEncord+'_weights.h5')\n",
    "\n",
    "json_string = decoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameDecord+'.json', 'w').write(json_string)\n",
    "decoder.save_weights(StudyDataPath+SaveFileNameDecord+'_weights.h5')\n",
    "\n",
    "json_string = autoencoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameNet+'.json', 'w').write(json_string)\n",
    "autoencoder.save_weights(StudyDataPath+SaveFileNameNet+'_weights.h5')\n",
    "\n",
    "# plot loss\n",
    "loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "nb_epoch = len(loss)\n",
    "plt.plot(range(nb_epoch), loss, marker='.', label='loss')\n",
    "plt.plot(range(nb_epoch), val_loss, marker='.', label='val_loss')\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.savefig(SaveFileNameGlaph)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rawData = windoW.reshape(windoW.size,1)\n",
    "reconstructed = decoded_imgs.reshape(decoded_imgs.size,1)\n",
    "for n in range(0,rawData.size,width):\n",
    "    print 'number='+str(n)\n",
    "    MakeGlaph(rawData, reconstructed, n, n+width,\n",
    "              GlaphDataPath+DataName+'_edim='+str(encoding_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次元数を減らしてみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define SaveFileName\n",
    "encoding_dim = 4  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "SaveFileNameEncord=DataName+'_encoded'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameDecord=DataName+'_decoded'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameNet=DataName+'_net'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameTrain=DataName+'_train'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameTest=DataName+'_test'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameGlaph=GlaphDataPath+DataName+'_edim='+str(encoding_dim)+'_loss_val_loss.png'\n",
    "\n",
    "window_test=windoW\n",
    "window_train=windoW\n",
    "\n",
    "shapeNum=windoW.shape[1]\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(shapeNum,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='tanh')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(shapeNum, activation='linear')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input=input_img, output=decoded)\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input=input_img, output=encoded)\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(input=encoded_input, output=decoder_layer(encoded_input))\n",
    "autoencoder.compile(optimizer='adadelta', loss='mse')\n",
    "plot(autoencoder,  to_file=StudyDataModelPicPath+SaveFileNameNet+'.png')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "hist = autoencoder.fit(window_train, window_train,\n",
    "                nb_epoch=50,\n",
    "                batch_size=shapeNum/4,\n",
    "                shuffle=True,\n",
    "                validation_data=(window_test, window_test),\n",
    "                callbacks=[early_stopping])\n",
    "\n",
    "encoded_imgs = encoder.predict(window_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameEncord,encoded_imgs)\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameDecord,decoded_imgs)\n",
    "\n",
    "# save model and wights\n",
    "json_string = encoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameEncord+'.json', 'w').write(json_string)\n",
    "encoder.save_weights(StudyDataPath+SaveFileNameEncord+'_weights.h5')\n",
    "\n",
    "json_string = decoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameDecord+'.json', 'w').write(json_string)\n",
    "decoder.save_weights(StudyDataPath+SaveFileNameDecord+'_weights.h5')\n",
    "\n",
    "json_string = autoencoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameNet+'.json', 'w').write(json_string)\n",
    "autoencoder.save_weights(StudyDataPath+SaveFileNameNet+'_weights.h5')\n",
    "\n",
    "# plot loss\n",
    "loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "nb_epoch = len(loss)\n",
    "plt.plot(range(nb_epoch), loss, marker='.', label='loss')\n",
    "plt.plot(range(nb_epoch), val_loss, marker='.', label='val_loss')\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.savefig(SaveFileNameGlaph)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rawData = windoW.reshape(windoW.size,1)\n",
    "reconstructed = decoded_imgs.reshape(decoded_imgs.size,1)\n",
    "for n in range(0,rawData.size,width):\n",
    "    print 'number='+str(n)\n",
    "    MakeGlaph(rawData, reconstructed, n, n+width,\n",
    "              GlaphDataPath+DataName+'_edim='+str(encoding_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次元数を増やしてみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define SaveFileName\n",
    "encoding_dim = 12  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "SaveFileNameEncord=DataName+'_encoded'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameDecord=DataName+'_decoded'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameNet=DataName+'_net'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameTrain=DataName+'_train'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameTest=DataName+'_test'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameGlaph=GlaphDataPath+DataName+'_edim='+str(encoding_dim)+'_loss_val_loss.png'\n",
    "\n",
    "window_test=windoW\n",
    "window_train=windoW\n",
    "\n",
    "shapeNum=windoW.shape[1]\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(shapeNum,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='tanh')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(shapeNum, activation='linear')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input=input_img, output=decoded)\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input=input_img, output=encoded)\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(input=encoded_input, output=decoder_layer(encoded_input))\n",
    "\n",
    "autoencoder.compile(optimizer='adadelta', loss='mse')\n",
    "plot(autoencoder,  to_file=StudyDataModelPicPath+SaveFileNameNet+'.png')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "hist = autoencoder.fit(window_train, window_train,\n",
    "                nb_epoch=50,\n",
    "                batch_size=shapeNum/4,\n",
    "                shuffle=True,\n",
    "                validation_data=(window_test, window_test),\n",
    "                callbacks=[early_stopping])\n",
    "\n",
    "encoded_imgs = encoder.predict(window_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameEncord,encoded_imgs)\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameDecord,decoded_imgs)\n",
    "\n",
    "# save model and wights\n",
    "json_string = encoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameEncord+'.json', 'w').write(json_string)\n",
    "encoder.save_weights(StudyDataPath+SaveFileNameEncord+'_weights.h5')\n",
    "\n",
    "json_string = decoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameDecord+'.json', 'w').write(json_string)\n",
    "decoder.save_weights(StudyDataPath+SaveFileNameDecord+'_weights.h5')\n",
    "\n",
    "json_string = autoencoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameNet+'.json', 'w').write(json_string)\n",
    "autoencoder.save_weights(StudyDataPath+SaveFileNameNet+'_weights.h5')\n",
    "\n",
    "# plot loss\n",
    "loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "nb_epoch = len(loss)\n",
    "plt.plot(range(nb_epoch), loss, marker='.', label='loss')\n",
    "plt.plot(range(nb_epoch), val_loss, marker='.', label='val_loss')\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.savefig(SaveFileNameGlaph)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rawData = windoW.reshape(windoW.size,1)\n",
    "reconstructed = decoded_imgs.reshape(decoded_imgs.size,1)\n",
    "for n in range(0,rawData.size,width):\n",
    "    print 'number='+str(n)\n",
    "    MakeGlaph(rawData, reconstructed, n, n+width,\n",
    "              GlaphDataPath+DataName+'_edim='+str(encoding_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次元数を入力創と同じ大きさにしてみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define SaveFileName\n",
    "encoding_dim = 16  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "SaveFileNameEncord=DataName+'_encoded'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameDecord=DataName+'_decoded'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameNet=DataName+'_net'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameTrain=DataName+'_train'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameTest=DataName+'_test'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameGlaph=GlaphDataPath+DataName+'_edim='+str(encoding_dim)+'_loss_val_loss.png'\n",
    "\n",
    "window_test=windoW\n",
    "window_train=windoW\n",
    "\n",
    "shapeNum=windoW.shape[1]\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(shapeNum,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='tanh')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(shapeNum, activation='linear')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input=input_img, output=decoded)\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input=input_img, output=encoded)\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(input=encoded_input, output=decoder_layer(encoded_input))\n",
    "\n",
    "autoencoder.compile(optimizer='adadelta', loss='mse')\n",
    "plot(autoencoder,  to_file=StudyDataModelPicPath+SaveFileNameNet+'.png')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "hist = autoencoder.fit(window_train, window_train,\n",
    "                nb_epoch=50,\n",
    "                batch_size=shapeNum/4,\n",
    "                shuffle=True,\n",
    "                validation_data=(window_test, window_test),\n",
    "                callbacks=[early_stopping])\n",
    "\n",
    "encoded_imgs = encoder.predict(window_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameEncord,encoded_imgs)\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameDecord,decoded_imgs)\n",
    "\n",
    "# save model and wights\n",
    "json_string = encoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameEncord+'.json', 'w').write(json_string)\n",
    "encoder.save_weights(StudyDataPath+SaveFileNameEncord+'_weights.h5')\n",
    "\n",
    "json_string = decoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameDecord+'.json', 'w').write(json_string)\n",
    "decoder.save_weights(StudyDataPath+SaveFileNameDecord+'_weights.h5')\n",
    "\n",
    "json_string = autoencoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameNet+'.json', 'w').write(json_string)\n",
    "autoencoder.save_weights(StudyDataPath+SaveFileNameNet+'_weights.h5')\n",
    "\n",
    "# plot loss\n",
    "loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "nb_epoch = len(loss)\n",
    "plt.plot(range(nb_epoch), loss, marker='.', label='loss')\n",
    "plt.plot(range(nb_epoch), val_loss, marker='.', label='val_loss')\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.savefig(SaveFileNameGlaph)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rawData = windoW.reshape(windoW.size,1)\n",
    "reconstructed = decoded_imgs.reshape(decoded_imgs.size,1)\n",
    "for n in range(0,rawData.size,width):\n",
    "    print 'number='+str(n)\n",
    "    MakeGlaph(rawData, reconstructed, n, n+width,\n",
    "              GlaphDataPath+DataName+'_edim='+str(encoding_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "入力層の大きさの２倍のノード数を隠れそうにする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define SaveFileName\n",
    "encoding_dim = 32  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "SaveFileNameEncord=DataName+'_encoded'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameDecord=DataName+'_decoded'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameNet=DataName+'_net'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameTrain=DataName+'_train'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameTest=DataName+'_test'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameGlaph=GlaphDataPath+DataName+'_edim='+str(encoding_dim)+'_loss_val_loss.png'\n",
    "\n",
    "window_test=windoW\n",
    "window_train=windoW\n",
    "\n",
    "shapeNum=windoW.shape[1]\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(shapeNum,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='tanh')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(shapeNum, activation='linear')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input=input_img, output=decoded)\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input=input_img, output=encoded)\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(input=encoded_input, output=decoder_layer(encoded_input))\n",
    "\n",
    "autoencoder.compile(optimizer='adadelta', loss='mse')\n",
    "plot(autoencoder,  to_file=StudyDataModelPicPath+SaveFileNameNet+'.png')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "hist = autoencoder.fit(window_train, window_train,\n",
    "                nb_epoch=50,\n",
    "                batch_size=shapeNum/4,\n",
    "                shuffle=True,\n",
    "                validation_data=(window_test, window_test),\n",
    "                callbacks=[early_stopping])\n",
    "\n",
    "encoded_imgs = encoder.predict(window_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameEncord,encoded_imgs)\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameDecord,decoded_imgs)\n",
    "\n",
    "# save model and wights\n",
    "json_string = encoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameEncord+'.json', 'w').write(json_string)\n",
    "encoder.save_weights(StudyDataPath+SaveFileNameEncord+'_weights.h5')\n",
    "\n",
    "json_string = decoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameDecord+'.json', 'w').write(json_string)\n",
    "decoder.save_weights(StudyDataPath+SaveFileNameDecord+'_weights.h5')\n",
    "\n",
    "json_string = autoencoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameNet+'.json', 'w').write(json_string)\n",
    "autoencoder.save_weights(StudyDataPath+SaveFileNameNet+'_weights.h5')\n",
    "\n",
    "# plot loss\n",
    "loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "nb_epoch = len(loss)\n",
    "plt.plot(range(nb_epoch), loss, marker='.', label='loss')\n",
    "plt.plot(range(nb_epoch), val_loss, marker='.', label='val_loss')\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.savefig(SaveFileNameGlaph)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rawData = windoW.reshape(windoW.size,1)\n",
    "reconstructed = decoded_imgs.reshape(decoded_imgs.size,1)\n",
    "for n in range(0,rawData.size,width):\n",
    "    print 'number='+str(n)\n",
    "    MakeGlaph(rawData, reconstructed, n, n+width,\n",
    "              GlaphDataPath+DataName+'_edim='+str(encoding_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "入力層の大きさの4倍のノード数を隠れそうにする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define SaveFileName\n",
    "encoding_dim = 64  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "SaveFileNameEncord=DataName+'_encoded'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameDecord=DataName+'_decoded'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameNet=DataName+'_net'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameTrain=DataName+'_train'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameTest=DataName+'_test'+'_edim='+str(encoding_dim)\n",
    "SaveFileNameGlaph=GlaphDataPath+DataName+'_edim='+str(encoding_dim)+'_loss_val_loss.png'\n",
    "\n",
    "window_test=windoW\n",
    "window_train=windoW\n",
    "\n",
    "shapeNum=windoW.shape[1]\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(shapeNum,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='tanh')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(shapeNum, activation='linear')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input=input_img, output=decoded)\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input=input_img, output=encoded)\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(input=encoded_input, output=decoder_layer(encoded_input))\n",
    "\n",
    "autoencoder.compile(optimizer='adadelta', loss='mse')\n",
    "plot(autoencoder,  to_file=StudyDataModelPicPath+SaveFileNameNet+'.png')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "hist = autoencoder.fit(window_train, window_train,\n",
    "                nb_epoch=50,\n",
    "                batch_size=shapeNum/4,\n",
    "                shuffle=True,\n",
    "                validation_data=(window_test, window_test),\n",
    "                callbacks=[early_stopping])\n",
    "\n",
    "encoded_imgs = encoder.predict(window_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameEncord,encoded_imgs)\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameDecord,decoded_imgs)\n",
    "\n",
    "# save model and wights\n",
    "json_string = encoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameEncord+'.json', 'w').write(json_string)\n",
    "encoder.save_weights(StudyDataPath+SaveFileNameEncord+'_weights.h5')\n",
    "\n",
    "json_string = decoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameDecord+'.json', 'w').write(json_string)\n",
    "decoder.save_weights(StudyDataPath+SaveFileNameDecord+'_weights.h5')\n",
    "\n",
    "json_string = autoencoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameNet+'.json', 'w').write(json_string)\n",
    "autoencoder.save_weights(StudyDataPath+SaveFileNameNet+'_weights.h5')\n",
    "\n",
    "# plot loss\n",
    "loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "nb_epoch = len(loss)\n",
    "plt.plot(range(nb_epoch), loss, marker='.', label='loss')\n",
    "plt.plot(range(nb_epoch), val_loss, marker='.', label='val_loss')\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.savefig(SaveFileNameGlaph)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rawData = windoW.reshape(windoW.size,1)\n",
    "reconstructed = decoded_imgs.reshape(decoded_imgs.size,1)\n",
    "for n in range(0,rawData.size,width):\n",
    "    print 'number='+str(n)\n",
    "    MakeGlaph(rawData, reconstructed, n, n+width,\n",
    "              GlaphDataPath+DataName+'_edim='+str(encoding_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
