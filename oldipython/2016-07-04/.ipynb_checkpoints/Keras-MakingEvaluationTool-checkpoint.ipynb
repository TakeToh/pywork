{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import fftpack\n",
    "from scipy import signal\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import copy\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 970 (CNMeM is disabled, cuDNN 4007)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.datasets import cifar10\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.utils.visualize_util import model_to_dot, plot\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WORKSPACE_PATH = '/home/takeyama/pywork/ipython/2016-06-27'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RawDataPath=WORKSPACE_PATH+'/raw/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "StudyDataPath=WORKSPACE_PATH+'/study/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "WindowDataPath=WORKSPACE_PATH+'/window/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "センサデータを読み込む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dic1=processing.LoadDicDataFromFileNPZ(RawDataPath+\"MemSensor1\")\n",
    "dic2=processing.LoadDicDataFromFileNPZ(RawDataPath+\"MemSensor2\")\n",
    "dic3=processing.LoadDicDataFromFileNPZ(RawDataPath+\"MemSensor3\")\n",
    "dic4=processing.LoadDicDataFromFileNPZ(RawDataPath+\"MemSensor4\")\n",
    "dic5=processing.LoadDicDataFromFileNPZ(RawDataPath+\"MemSensor5\")\n",
    "dic6=processing.LoadDicDataFromFileNPZ(RawDataPath+\"MemSensor6\")\n",
    "dic7=processing.LoadDicDataFromFileNPZ(RawDataPath+\"MemSensor7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "windows関数を作成する。\n",
    "要求仕様\n",
    "* 入力データは2次元配列　raw 時間、colm　データの種類（加速度X,加速度Y,・・・）\n",
    "* 出力データは4次元配列　numberOfWindow * windowWidth * kindOfData * \n",
    "# how to use\n",
    "1. Set Data(1darray)\n",
    "case 1  \n",
    "    seed.append(AccX)  \n",
    "    seed.append(AccY)  \n",
    "    seed.append(AccZ)  \n",
    "2. Making window\n",
    "w = build(seed)  \n",
    "w -> [ [AccX],[AccY],[AccZ] ]  \n",
    "window = compile(w)  \n",
    "window -> \n",
    "          [ [[AccX],[AccY],[AccZ]],  \n",
    "            [[AccX],[AccY],[AccZ]],  \n",
    "            [[AccX],[AccY],[AccZ]], ....]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Window:\n",
    "    \"\"\"Input dictionary\n",
    "       Ouput Windows\n",
    "    \"\"\"         \n",
    "    def __init__(self):                  \n",
    "        self.seed ={}\n",
    "    \n",
    "    def SetData(self, RegistDataName, RegistData):\n",
    "        if RegistDataName in self.seed:\n",
    "            print RegistDataName+' has been registed before'\n",
    "            return -1\n",
    "        \n",
    "        self.seed[RegistDataName] = RegistData\n",
    "        print RegistDataName+' is registed now'\n",
    "    \n",
    "    def _Build(self):\n",
    "        keys = self.seed.keys()\n",
    "        array = self.seed[keys[0]]\n",
    "        \n",
    "        for k in keys[1:]:\n",
    "            array = np.vstack( (array,self.seed[k]))\n",
    "        print 'Build Complete'\n",
    "        return array.T\n",
    "    \n",
    "    def Compile(self,windowWidth,overlap):\n",
    "        source = self._Build()\n",
    "        print source.shape\n",
    "       \n",
    "        sourceRows = source.ndim\n",
    "        sourceColum = source.size\n",
    "        offset = len(source)%windowWidth\n",
    "        if offset % 2 == 1:\n",
    "            offset=offset/2 +1\n",
    "        else:\n",
    "            offset=offset/2\n",
    "        # first array\n",
    "        start = offset\n",
    "        goal = start+windowWidth\n",
    "        window = source[start:goal].T\n",
    "        \n",
    "        for i in range(1,len(source)/windowWidth):\n",
    "            start = start+ int(windowWidth*overlap)\n",
    "            goal = start+windowWidth\n",
    "            adding = source[start:goal].T\n",
    "            window = np.dstack((window,adding))\n",
    "        return window.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = Window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dic1-AccX is registed now\n",
      "dic1-AccY is registed now\n",
      "dic1-AccZ is registed now\n"
     ]
    }
   ],
   "source": [
    "w.SetData('dic1-AccX',dic1['AccX'])\n",
    "w.SetData('dic1-AccY',dic1['AccY'])\n",
    "w.SetData('dic1-AccZ',dic1['AccZ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dic2-AccX is registed now\n",
      "dic2-AccY is registed now\n",
      "dic2-AccZ is registed now\n"
     ]
    }
   ],
   "source": [
    "w.SetData('dic2-AccX',dic2['AccX'])\n",
    "w.SetData('dic2-AccY',dic2['AccY'])\n",
    "w.SetData('dic2-AccZ',dic2['AccZ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dic3-AccX is registed now\n",
      "dic3-AccY is registed now\n",
      "dic3-AccZ is registed now\n"
     ]
    }
   ],
   "source": [
    "w.SetData('dic3-AccX',dic3['AccX'])\n",
    "w.SetData('dic3-AccY',dic3['AccY'])\n",
    "w.SetData('dic3-AccZ',dic3['AccZ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dic4-AccX is registed now\n",
      "dic4-AccY is registed now\n",
      "dic4-AccZ is registed now\n"
     ]
    }
   ],
   "source": [
    "w.SetData('dic4-AccX',dic4['AccX'])\n",
    "w.SetData('dic4-AccY',dic4['AccY'])\n",
    "w.SetData('dic4-AccZ',dic4['AccZ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dic5-AccX is registed now\n",
      "dic5-AccY is registed now\n",
      "dic5-AccZ is registed now\n"
     ]
    }
   ],
   "source": [
    "w.SetData('dic5-AccX',dic5['AccX'])\n",
    "w.SetData('dic5-AccY',dic5['AccY'])\n",
    "w.SetData('dic5-AccZ',dic5['AccZ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dic6-AccX is registed now\n",
      "dic6-AccY is registed now\n",
      "dic6-AccZ is registed now\n"
     ]
    }
   ],
   "source": [
    "w.SetData('dic6-AccX',dic6['AccX'])\n",
    "w.SetData('dic6-AccY',dic6['AccY'])\n",
    "w.SetData('dic6-AccZ',dic6['AccZ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dic7-AccX is registed now\n",
      "dic7-AccY is registed now\n",
      "dic7-AccZ is registed now\n"
     ]
    }
   ],
   "source": [
    "w.SetData('dic7-AccX',dic7['AccX'])\n",
    "w.SetData('dic7-AccY',dic7['AccY'])\n",
    "w.SetData('dic7-AccZ',dic7['AccZ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build Complete\n",
      "(254742, 21)\n"
     ]
    }
   ],
   "source": [
    "window = w.Compile(windowWidth=16,overlap=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "出来上がったwindowの形をみれば、Mnistを模倣したほうがいいかもしれない  \n",
    "というのは、windowの集合を見るとMnistに近いものになっていた  \n",
    "Mnistの訓練データは[sample, 28,28]  \n",
    "一方、出来上がったwindowは[sample,windowWidth,data]  \n",
    "また、cifar10は[sample,32,32,3]  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kerasとMnistに関して、入力層をどのようにやっているのかわからないので実際にデータをダウンロードしてどのような構造でダウンロードして、入力層に与えるときに何をしているかをはっきりさせる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Convert3dto2d(window):\n",
    "    output = window.reshape((len(window),np.prod(window.shape[1:])))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "window_train = window.reshape((len(window),np.prod(window.shape[1:])))\n",
    "#window_train = window_train[:12000]\n",
    "window_test = window.reshape((len(window),np.prod(window.shape[1:])))\n",
    "#window_test = window_test[12001:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "すべてのセンサデータの加速度データ、角速度データを食わせる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15921 samples, validate on 15921 samples\n",
      "Epoch 1/50\n",
      "15921/15921 [==============================] - 0s - loss: 0.1911 - val_loss: 0.0836\n",
      "Epoch 2/50\n",
      "15921/15921 [==============================] - 0s - loss: 0.0749 - val_loss: 0.0699\n",
      "Epoch 3/50\n",
      "15921/15921 [==============================] - 0s - loss: 0.0641 - val_loss: 0.0581\n",
      "Epoch 4/50\n",
      "15921/15921 [==============================] - 0s - loss: 0.0530 - val_loss: 0.0484\n",
      "Epoch 5/50\n",
      "15921/15921 [==============================] - 0s - loss: 0.0455 - val_loss: 0.0430\n",
      "Epoch 6/50\n",
      "15921/15921 [==============================] - 0s - loss: 0.0414 - val_loss: 0.0401\n",
      "Epoch 7/50\n",
      "15921/15921 [==============================] - 0s - loss: 0.0391 - val_loss: 0.0382\n",
      "Epoch 8/50\n",
      "15921/15921 [==============================] - 0s - loss: 0.0374 - val_loss: 0.0368\n",
      "Epoch 9/50\n",
      "15921/15921 [==============================] - 0s - loss: 0.0359 - val_loss: 0.0350\n",
      "Epoch 10/50\n",
      "15921/15921 [==============================] - 0s - loss: 0.0342 - val_loss: 0.0335\n",
      "Epoch 11/50\n",
      "15921/15921 [==============================] - 0s - loss: 0.0324 - val_loss: 0.0315\n",
      "Epoch 12/50\n",
      "15921/15921 [==============================] - 0s - loss: 0.0307 - val_loss: 0.0299\n",
      "Epoch 13/50\n",
      "15921/15921 [==============================] - 0s - loss: 0.0292 - val_loss: 0.0285\n",
      "Epoch 14/50\n",
      "15921/15921 [==============================] - 0s - loss: 0.0278 - val_loss: 0.0271\n",
      "Epoch 15/50\n",
      "15921/15921 [==============================] - 0s - loss: 0.0266 - val_loss: 0.0258\n",
      "Epoch 16/50\n",
      "15921/15921 [==============================] - 0s - loss: 0.0255 - val_loss: 0.0249\n",
      "Epoch 17/50\n",
      "15921/15921 [==============================] - 0s - loss: 0.0247 - val_loss: 0.0242\n",
      "Epoch 18/50\n",
      "15921/15921 [==============================] - 0s - loss: 0.0241 - val_loss: 0.0237\n",
      "Epoch 19/50\n",
      "15921/15921 [==============================] - 0s - loss: 0.0237 - val_loss: 0.0233\n",
      "Epoch 20/50\n",
      "15921/15921 [==============================] - 0s - loss: 0.0232 - val_loss: 0.0226\n",
      "Epoch 21/50\n",
      "15921/15921 [==============================] - 0s - loss: 0.0226 - val_loss: 0.0222\n",
      "Epoch 22/50\n",
      "15921/15921 [==============================] - 0s - loss: 0.0224 - val_loss: 0.0216\n",
      "Epoch 23/50\n",
      "15921/15921 [==============================] - 0s - loss: 0.0218 - val_loss: 0.0230\n",
      "Epoch 24/50\n",
      "15921/15921 [==============================] - 0s - loss: 0.0215 - val_loss: 0.0214\n",
      "Epoch 25/50\n",
      "15921/15921 [==============================] - 0s - loss: 0.0212 - val_loss: 0.0205\n",
      "Epoch 26/50\n",
      "15921/15921 [==============================] - 0s - loss: 0.0211 - val_loss: 0.0207\n",
      "Epoch 27/50\n",
      "15921/15921 [==============================] - 0s - loss: 0.0207 - val_loss: 0.0202\n",
      "Epoch 28/50\n",
      "15921/15921 [==============================] - 0s - loss: 0.0203 - val_loss: 0.0199\n",
      "Epoch 29/50\n",
      "15921/15921 [==============================] - 0s - loss: 0.0203 - val_loss: 0.0199\n",
      "Epoch 30/50\n",
      "15921/15921 [==============================] - 0s - loss: 0.0199 - val_loss: 0.0204\n",
      "Epoch 31/50\n",
      "15921/15921 [==============================] - 0s - loss: 0.0198 - val_loss: 0.0208\n",
      "Epoch 32/50\n",
      "15921/15921 [==============================] - 0s - loss: 0.0197 - val_loss: 0.0210\n",
      "Epoch 33/50\n",
      "15921/15921 [==============================] - 0s - loss: 0.0196 - val_loss: 0.0190\n",
      "Epoch 34/50\n",
      "15921/15921 [==============================] - 0s - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 35/50\n",
      "15921/15921 [==============================] - 0s - loss: 0.0197 - val_loss: 0.0189\n",
      "Epoch 36/50\n",
      "15921/15921 [==============================] - 0s - loss: 0.0196 - val_loss: 0.0197\n",
      "Epoch 37/50\n",
      "15921/15921 [==============================] - 0s - loss: 0.0195 - val_loss: 0.0201\n",
      "Epoch 38/50\n",
      "15921/15921 [==============================] - 0s - loss: 0.0191 - val_loss: 0.0199\n",
      "Epoch 39/50\n",
      "15921/15921 [==============================] - 0s - loss: 0.0188 - val_loss: 0.0181\n",
      "Epoch 40/50\n",
      "15921/15921 [==============================] - 0s - loss: 0.0190 - val_loss: 0.0196\n",
      "Epoch 41/50\n",
      "15921/15921 [==============================] - 0s - loss: 0.0190 - val_loss: 0.0187\n",
      "Epoch 42/50\n",
      "15921/15921 [==============================] - 0s - loss: 0.0189 - val_loss: 0.0185\n",
      "Epoch 43/50\n",
      "15921/15921 [==============================] - 0s - loss: 0.0189 - val_loss: 0.0180\n",
      "Epoch 44/50\n",
      "15921/15921 [==============================] - 0s - loss: 0.0188 - val_loss: 0.0185\n",
      "Epoch 45/50\n",
      "15921/15921 [==============================] - 0s - loss: 0.0188 - val_loss: 0.0178\n",
      "Epoch 46/50\n",
      "15921/15921 [==============================] - 0s - loss: 0.0184 - val_loss: 0.0186\n",
      "Epoch 47/50\n",
      "15921/15921 [==============================] - 0s - loss: 0.0182 - val_loss: 0.0176\n",
      "Epoch 48/50\n",
      "15921/15921 [==============================] - 0s - loss: 0.0183 - val_loss: 0.0177\n",
      "Epoch 49/50\n",
      "15921/15921 [==============================] - 0s - loss: 0.0184 - val_loss: 0.0185\n",
      "Epoch 50/50\n",
      "15921/15921 [==============================] - 0s - loss: 0.0180 - val_loss: 0.0178\n",
      "[WARNING] /home/takeyama/pywork/ipython/2016-06-27/study/All_encoded_weights.h5 already exists - overwrite? [y/n]y\n",
      "[TIP] Next time specify overwrite=True in save_weights!\n",
      "[WARNING] /home/takeyama/pywork/ipython/2016-06-27/study/All_encoded_weights.h5 already exists - overwrite? [y/n]y\n",
      "[TIP] Next time specify overwrite=True in save_weights!\n",
      "[WARNING] /home/takeyama/pywork/ipython/2016-06-27/study/All_net_weights.h5 already exists - overwrite? [y/n]y\n",
      "[TIP] Next time specify overwrite=True in save_weights!\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEPCAYAAABRHfM8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyv8H+3tP3R/iLnkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f37f72cc850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f38093c3c10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "windoW = window\n",
    "col = windoW.shape[1]\n",
    "row = windoW.shape[2]\n",
    "shapeNum=col*row\n",
    "\n",
    "SaveFileNameEncord='All_encoded'\n",
    "SaveFileNameDecord='All_decoded'\n",
    "SaveFileNameNet='All_net'\n",
    "\n",
    "SaveFileNameTrain='All_train'\n",
    "SaveFileNameTest='All_test'\n",
    "\n",
    "window_train=Convert3dto2d(windoW)\n",
    "window_test=Convert3dto2d(windoW)\n",
    "\n",
    "processing.SaveDicDataFromFileNPZ(WindowDataPath,SaveFileNameTrain,window_test)\n",
    "processing.SaveDicDataFromFileNPZ(WindowDataPath,SaveFileNameTest,window_test)\n",
    "# this is the size of our encoded representations\n",
    "encoding_dim = 8  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "shapeNum=window_train.shape[1]\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(shapeNum,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='tanh')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(shapeNum, activation='linear')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input=input_img, output=decoded)\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoderALL = Model(input=input_img, output=encoded)\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoderALL = Model(input=encoded_input, output=decoder_layer(encoded_input))\n",
    "\n",
    "autoencoder.compile(optimizer='adadelta', loss='mse')\n",
    "\n",
    "hist=autoencoder.fit(window_train, window_train,\n",
    "                nb_epoch=50,\n",
    "                batch_size=shapeNum/4,\n",
    "                shuffle=True,\n",
    "                validation_data=(window_test, window_test))\n",
    "\n",
    "encoded_imgs = encoderALL.predict(window_test)\n",
    "decoded_imgs = decoderALL.predict(encoded_imgs)\n",
    "\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameEncord,encoded_imgs)\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameDecord,decoded_imgs)\n",
    "\n",
    "json_string = encoderALL.to_json()\n",
    "open(StudyDataPath+SaveFileNameEncord+'.json', 'w').write(json_string)\n",
    "encoderALL.save_weights(StudyDataPath+SaveFileNameEncord+'_weights.h5')\n",
    "\n",
    "json_string = decoderALL.to_json()\n",
    "open(StudyDataPath+SaveFileNameDecord+'.json', 'w').write(json_string)\n",
    "decoderALL.save_weights(StudyDataPath+SaveFileNameEncord+'_weights.h5')\n",
    "\n",
    "json_string = autoencoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameNet+'.json', 'w').write(json_string)\n",
    "autoencoder.save_weights(StudyDataPath+SaveFileNameNet+'_weights.h5')\n",
    "\n",
    "# plot loss\n",
    "loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "nb_epoch = len(loss)\n",
    "plt.plot(range(nb_epoch), loss, marker='.', label='loss')\n",
    "plt.plot(range(nb_epoch), val_loss, marker='.', label='val_loss')\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()\n",
    "plt.savefig('All_sensors_loss_val_loss.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "あるセンサの一次元のみでやってみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "w1 = Window()\n",
    "w1.SetData('AccX', dic1['AccX'])\n",
    "window1 = w1.Compile(windowWidth=16,overlap=0.5)\n",
    "\n",
    "windoW = window1\n",
    "\n",
    "col = windoW.shape[1]\n",
    "row = windoW.shape[2]\n",
    "shapeNum=col*row\n",
    "\n",
    "SaveFileNameEncord='sensor1_AccX_encoded'\n",
    "SaveFileNameDecord='sensor1_AccX_decoded'\n",
    "SaveFileNameNet='sensor1_AccX_net'\n",
    "window_train=Convert3dto2d(windoW)\n",
    "window_test=Convert3dto2d(windoW)\n",
    "\n",
    "SaveFileNameTrain='sensor1_AccX_train'\n",
    "SaveFileNameTest='sensor1_AccX_test'\n",
    "processing.SaveDicDataFromFileNPZ(WindowDataPath,SaveFileNameTrain,window_test)\n",
    "processing.SaveDicDataFromFileNPZ(WindowDataPath,SaveFileNameTest,window_test)\n",
    "encoding_dim = 8  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(shapeNum,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='tanh')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(shapeNum, activation='linear')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder1 = Model(input=input_img, output=decoded)\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoder1 = Model(input=input_img, output=encoded)\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder1 = Model(input=encoded_input, output=decoder_layer(encoded_input))\n",
    "\n",
    "autoencoder1.compile(optimizer='adadelta', loss='mse')\n",
    "\n",
    "autoencoder1.fit(window_train, window_train,\n",
    "                nb_epoch=50,\n",
    "                batch_size=shapeNum/4,\n",
    "                shuffle=True,\n",
    "                validation_data=(window_test, window_test))\n",
    "\n",
    "encoded_imgs = encoder1.predict(window_test)\n",
    "decoded_imgs = decoder1.predict(encoded_imgs)\n",
    "\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameEncord,encoded_imgs)\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameDecord,decoded_imgs)\n",
    "\n",
    "json_string = encoderALL.to_json()\n",
    "open(StudyDataPath+SaveFileNameEncord+'.json', 'w').write(json_string)\n",
    "model.save_weights(StudyDataPath+SaveFileNameEncord+'_weights.h5')\n",
    "\n",
    "json_string = decoderALL.to_json()\n",
    "open(StudyDataPath+SaveFileNameDecord+'.json', 'w').write(json_string)\n",
    "model.save_weights(StudyDataPath+SaveFileNameEncord+'_weights.h5')\n",
    "\n",
    "json_string = decoderALL.to_json()\n",
    "open(StudyDataPath+SaveFileNameNet+'.json', 'w').write(json_string)\n",
    "model.save_weights(StudyDataPath+SaveFileNameNet+'_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2つ目のセンサーで同じようにやってみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2 = Window()\n",
    "w2.SetData('AccX', dic2['AccX'])\n",
    "window2 = w2.Compile(windowWidth=16,overlap=0.5)\n",
    "\n",
    "windoW = window2\n",
    "col = windoW.shape[1]\n",
    "row = windoW.shape[2]\n",
    "shapeNum=col*row\n",
    "\n",
    "SaveFileNameEncord='sensor2_AccX_encoded'\n",
    "SaveFileNameDecord='sensor2_AccX_decoded'\n",
    "SaveFileNameNet='sensor2_AccX_net'\n",
    "\n",
    "window_train=Convert3dto2d(windoW)\n",
    "window_test=Convert3dto2d(windoW)\n",
    "\n",
    "SaveFileNameTrain='sensor2_AccX_train'\n",
    "SaveFileNameTest='sensor2_AccX_test'\n",
    "processing.SaveDicDataFromFileNPZ(WindowDataPath,SaveFileNameTrain,window_test)\n",
    "processing.SaveDicDataFromFileNPZ(WindowDataPath,SaveFileNameTest,window_test)\n",
    "\n",
    "encoding_dim = 8  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(shapeNum,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='tanh')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(shapeNum, activation='linear')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input=input_img, output=decoded)\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input=input_img, output=encoded)\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(input=encoded_input, output=decoder_layer(encoded_input))\n",
    "\n",
    "autoencoder.compile(optimizer='adadelta', loss='mse')\n",
    "\n",
    "autoencoder.fit(window_train, window_train,\n",
    "                nb_epoch=50,\n",
    "                batch_size=shapeNum/4,\n",
    "                shuffle=True,\n",
    "                validation_data=(window_test, window_test))\n",
    "\n",
    "encoded_imgs = encoder.predict(window_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameEncord,encoded_imgs)\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameDecord,decoded_imgs)\n",
    "\n",
    "json_string = encoderALL.to_json()\n",
    "open(StudyDataPath+SaveFileNameEncord+'.json', 'w').write(json_string)\n",
    "model.save_weights(StudyDataPath+SaveFileNameEncord+'_weights.h5')\n",
    "\n",
    "json_string = decoderALL.to_json()\n",
    "open(StudyDataPath+SaveFileNameDecord+'.json', 'w').write(json_string)\n",
    "model.save_weights(StudyDataPath+SaveFileNameEncord+'_weights.h5')\n",
    "\n",
    "json_string = decoderALL.to_json()\n",
    "open(StudyDataPath+SaveFileNameNet+'.json', 'w').write(json_string)\n",
    "model.save_weights(StudyDataPath+SaveFileNameNet+'_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "３つ目のデータ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w3 = Window()\n",
    "w3.SetData('AccX', dic3['AccX'])\n",
    "window3 = w3.Compile(windowWidth=16,overlap=0.5)\n",
    "\n",
    "windoW = window3\n",
    "col = windoW.shape[1]\n",
    "row = windoW.shape[2]\n",
    "shapeNum=col*row\n",
    "\n",
    "SaveFileNameEncord='sensor3_AccX_encoded'\n",
    "SaveFileNameDecord='sensor3_AccX_decoded'\n",
    "SaveFileNameNet='sensor3_AccX_net'\n",
    "\n",
    "window_train=Convert3dto2d(windoW)\n",
    "window_test=Convert3dto2d(windoW)\n",
    "\n",
    "SaveFileNameTrain='sensor3_AccX_train'\n",
    "SaveFileNameTest='sensor3_AccX_test'\n",
    "processing.SaveDicDataFromFileNPZ(WindowDataPath,SaveFileNameTrain,window_test)\n",
    "processing.SaveDicDataFromFileNPZ(WindowDataPath,SaveFileNameTest,window_test)\n",
    "\n",
    "encoding_dim = 8  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(shapeNum,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='tanh')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(shapeNum, activation='linear')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input=input_img, output=decoded)\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input=input_img, output=encoded)\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(input=encoded_input, output=decoder_layer(encoded_input))\n",
    "\n",
    "autoencoder.compile(optimizer='adadelta', loss='mse')\n",
    "\n",
    "autoencoder.fit(window_train, window_train,\n",
    "                nb_epoch=50,\n",
    "                batch_size=shapeNum/4,\n",
    "                shuffle=True,\n",
    "                validation_data=(window_test, window_test))\n",
    "\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameEncord,encoded_imgs)\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameDecord,decoded_imgs)\n",
    "\n",
    "json_string = encoderALL.to_json()\n",
    "open(StudyDataPath+SaveFileNameEncord+'.json', 'w').write(json_string)\n",
    "model.save_weights(StudyDataPath+SaveFileNameEncord+'_weights.h5')\n",
    "\n",
    "json_string = decoderALL.to_json()\n",
    "open(StudyDataPath+SaveFileNameDecord+'.json', 'w').write(json_string)\n",
    "model.save_weights(StudyDataPath+SaveFileNameEncord+'_weights.h5')\n",
    "\n",
    "json_string = decoderALL.to_json()\n",
    "open(StudyDataPath+SaveFileNameNet+'.json', 'w').write(json_string)\n",
    "model.save_weights(StudyDataPath+SaveFileNameNet+'_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4つ目のセンサデータ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w4 = Window()\n",
    "w4.SetData('AccX', dic4['AccX'])\n",
    "window4 = w4.Compile(windowWidth=16,overlap=0.5)\n",
    "\n",
    "windoW = window4\n",
    "col = windoW.shape[1]\n",
    "row = windoW.shape[2]\n",
    "shapeNum=col*row\n",
    "\n",
    "SaveFileNameEncord='sensor4_AccX_encoded'\n",
    "SaveFileNameDecord='sensor4_AccX_decoded'\n",
    "SaveFileNameNet='sensor4_AccX_net'\n",
    "\n",
    "window_train=Convert3dto2d(windoW)\n",
    "window_test=Convert3dto2d(windoW)\n",
    "\n",
    "SaveFileNameTrain='sensor4_AccX_train'\n",
    "SaveFileNameTest='sensor4_AccX_test'\n",
    "processing.SaveDicDataFromFileNPZ(WindowDataPath,SaveFileNameTrain,window_test)\n",
    "processing.SaveDicDataFromFileNPZ(WindowDataPath,SaveFileNameTest,window_test)\n",
    "\n",
    "encoding_dim = 8  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(shapeNum,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='tanh')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(shapeNum, activation='linear')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input=input_img, output=decoded)\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input=input_img, output=encoded)\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(input=encoded_input, output=decoder_layer(encoded_input))\n",
    "\n",
    "autoencoder.compile(optimizer='adadelta', loss='mse')\n",
    "\n",
    "autoencoder.fit(window_train, window_train,\n",
    "                nb_epoch=50,\n",
    "                batch_size=shapeNum/4,\n",
    "                shuffle=True,\n",
    "                validation_data=(window_test, window_test))\n",
    "\n",
    "encoded_imgs = encoder.predict(window_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameEncord,encoded_imgs)\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameDecord,decoded_imgs)\n",
    "\n",
    "json_string = encoderALL.to_json()\n",
    "open(StudyDataPath+SaveFileNameEncord+'.json', 'w').write(json_string)\n",
    "model.save_weights(StudyDataPath+SaveFileNameEncord+'_weights.h5')\n",
    "\n",
    "json_string = decoderALL.to_json()\n",
    "open(StudyDataPath+SaveFileNameDecord+'.json', 'w').write(json_string)\n",
    "model.save_weights(StudyDataPath+SaveFileNameEncord+'_weights.h5')\n",
    "\n",
    "json_string = decoderALL.to_json()\n",
    "open(StudyDataPath+SaveFileNameNet+'.json', 'w').write(json_string)\n",
    "model.save_weights(StudyDataPath+SaveFileNameNet+'_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "５つ目のセンサデータ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w5 = Window()\n",
    "w5.SetData('AccX', dic5['AccX'])\n",
    "window5 = w5.Compile(windowWidth=16,overlap=0.5)\n",
    "\n",
    "windoW = window5\n",
    "col = windoW.shape[1]\n",
    "row = windoW.shape[2]\n",
    "shapeNum=col*row\n",
    "\n",
    "SaveFileNameEncord='sensor5_AccX_encoded'\n",
    "SaveFileNameDecord='sensor5_AccX_decoded'\n",
    "SaveFileNameNet='sensor5_AccX_net'\n",
    "\n",
    "window_train=Convert3dto2d(windoW)\n",
    "window_test=Convert3dto2d(windoW)\n",
    "\n",
    "SaveFileNameTrain='sensor5_AccX_train'\n",
    "SaveFileNameTest='sensor5_AccX_test'\n",
    "processing.SaveDicDataFromFileNPZ(WindowDataPath,SaveFileNameTrain,window_test)\n",
    "processing.SaveDicDataFromFileNPZ(WindowDataPath,SaveFileNameTest,window_test)\n",
    "\n",
    "encoding_dim = 8  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(shapeNum,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='tanh')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(shapeNum, activation='linear')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input=input_img, output=decoded)\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input=input_img, output=encoded)\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(input=encoded_input, output=decoder_layer(encoded_input))\n",
    "\n",
    "autoencoder.compile(optimizer='adadelta', loss='mse')\n",
    "\n",
    "autoencoder.fit(window_train, window_train,\n",
    "                nb_epoch=50,\n",
    "                batch_size=shapeNum/4,\n",
    "                shuffle=True,\n",
    "                validation_data=(window_test, window_test))\n",
    "\n",
    "encoded_imgs = encoder.predict(window_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameEncord,encoded_imgs)\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameDecord,decoded_imgs)\n",
    "\n",
    "json_string = encoderALL.to_json()\n",
    "open(StudyDataPath+SaveFileNameEncord+'.json', 'w').write(json_string)\n",
    "model.save_weights(StudyDataPath+SaveFileNameEncord+'_weights.h5')\n",
    "\n",
    "json_string = decoderALL.to_json()\n",
    "open(StudyDataPath+SaveFileNameDecord+'.json', 'w').write(json_string)\n",
    "model.save_weights(StudyDataPath+SaveFileNameEncord+'_weights.h5')\n",
    "\n",
    "json_string = decoderALL.to_json()\n",
    "open(StudyDataPath+SaveFileNameNet+'.json', 'w').write(json_string)\n",
    "model.save_weights(StudyDataPath+SaveFileNameNet+'_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "６つ目のセンサでやってみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w6 = Window()\n",
    "w6.SetData('AccX', dic6['AccX'])\n",
    "window6 = w6.Compile(windowWidth=16,overlap=0.5)\n",
    "\n",
    "windoW = window6\n",
    "col = windoW.shape[1]\n",
    "row = windoW.shape[2]\n",
    "shapeNum=col*row\n",
    "\n",
    "SaveFileNameEncord='sensor6_AccX_encoded'\n",
    "SaveFileNameDecord='sensor6_AccX_decoded'\n",
    "SaveFileNameNet='sensor6_AccX_net'\n",
    "\n",
    "window_train=Convert3dto2d(windoW)\n",
    "window_test=Convert3dto2d(windoW)\n",
    "\n",
    "SaveFileNameTrain='sensor6_AccX_train'\n",
    "SaveFileNameTest='sensor6_AccX_test'\n",
    "processing.SaveDicDataFromFileNPZ(WindowDataPath,SaveFileNameTrain,window_test)\n",
    "processing.SaveDicDataFromFileNPZ(WindowDataPath,SaveFileNameTest,window_test)\n",
    "\n",
    "encoding_dim = 8  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(shapeNum,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='tanh')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(shapeNum, activation='linear')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input=input_img, output=decoded)\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input=input_img, output=encoded)\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(input=encoded_input, output=decoder_layer(encoded_input))\n",
    "\n",
    "autoencoder.compile(optimizer='adadelta', loss='mse')\n",
    "\n",
    "autoencoder.fit(window_train, window_train,\n",
    "                nb_epoch=50,\n",
    "                batch_size=shapeNum/4,\n",
    "                shuffle=True,\n",
    "                validation_data=(window_test, window_test))\n",
    "\n",
    "encoded_imgs = encoder.predict(window_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameEncord,encoded_imgs)\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameDecord,decoded_imgs)\n",
    "\n",
    "json_string = encoderALL.to_json()\n",
    "open(StudyDataPath+SaveFileNameEncord+'.json', 'w').write(json_string)\n",
    "model.save_weights(StudyDataPath+SaveFileNameEncord+'_weights.h5')\n",
    "\n",
    "json_string = decoderALL.to_json()\n",
    "open(StudyDataPath+SaveFileNameDecord+'.json', 'w').write(json_string)\n",
    "model.save_weights(StudyDataPath+SaveFileNameEncord+'_weights.h5')\n",
    "\n",
    "json_string = decoderALL.to_json()\n",
    "open(StudyDataPath+SaveFileNameNet+'.json', 'w').write(json_string)\n",
    "model.save_weights(StudyDataPath+SaveFileNameNet+'_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "７つ目のセンサーでやってみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w7 = Window()\n",
    "w7.SetData('AccX', dic6['AccX'])\n",
    "window7 = w7.Compile(windowWidth=16,overlap=0.5)\n",
    "\n",
    "windoW = window7\n",
    "col = windoW.shape[1]\n",
    "row = windoW.shape[2]\n",
    "shapeNum=col*row\n",
    "\n",
    "SaveFileNameEncord='sensor7_AccX_encoded'\n",
    "SaveFileNameDecord='sensor7_AccX_decoded'\n",
    "SaveFileNameNet='sensor7_AccX_net'\n",
    "\n",
    "window_train=Convert3dto2d(windoW)\n",
    "window_test=Convert3dto2d(windoW)\n",
    "\n",
    "SaveFileNameTrain='sensor7_AccX_train'\n",
    "SaveFileNameTest='sensor7_AccX_test'\n",
    "processing.SaveDicDataFromFileNPZ(WindowDataPath,SaveFileNameTrain,window_test)\n",
    "processing.SaveDicDataFromFileNPZ(WindowDataPath,SaveFileNameTest,window_test)\n",
    "\n",
    "encoding_dim = 8  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(shapeNum,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='tanh')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(shapeNum, activation='linear')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input=input_img, output=decoded)\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input=input_img, output=encoded)\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(input=encoded_input, output=decoder_layer(encoded_input))\n",
    "\n",
    "autoencoder.compile(optimizer='adadelta', loss='mse')\n",
    "\n",
    "autoencoder.fit(window_train, window_train,\n",
    "                nb_epoch=50,\n",
    "                batch_size=shapeNum/4,\n",
    "                shuffle=True,\n",
    "                validation_data=(window_test, window_test))\n",
    "\n",
    "encoded_imgs = encoder.predict(window_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameEncord,encoded_imgs)\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameDecord,decoded_imgs)\n",
    "\n",
    "json_string = encoderALL.to_json()\n",
    "open(StudyDataPath+SaveFileNameEncord+'.json', 'w').write(json_string)\n",
    "model.save_weights(StudyDataPath+SaveFileNameEncord+'_weights.h5')\n",
    "\n",
    "json_string = decoderALL.to_json()\n",
    "open(StudyDataPath+SaveFileNameDecord+'.json', 'w').write(json_string)\n",
    "model.save_weights(StudyDataPath+SaveFileNameEncord+'_weights.h5')\n",
    "\n",
    "json_string = decoderALL.to_json()\n",
    "open(StudyDataPath+SaveFileNameNet+'.json', 'w').write(json_string)\n",
    "model.save_weights(StudyDataPath+SaveFileNameNet+'_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
