{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import fftpack\n",
    "from scipy import signal\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import pickle\n",
    "import copy\n",
    "import processing\n",
    "import matplotlib.animation as animation\n",
    "import datetime\n",
    "import window\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "today=datetime.date.today()\n",
    "\n",
    "WORKSPACE_PATH = '/home/takeyama/pywork/ipython/2016-07-04'\n",
    "RawDataPath=WORKSPACE_PATH+'/raw/'\n",
    "StudyDataPath=WORKSPACE_PATH+'/study/'+str(today)+'/'\n",
    "GlaphDataPath=WORKSPACE_PATH+'/glaph/'+str(today)+'/'\n",
    "GlaphDataFftPath=WORKSPACE_PATH+'/fft/'+str(today)+'/'\n",
    "WindowDataPath=WORKSPACE_PATH+'/window/'+str(today)+'/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 970 (CNMeM is disabled, cuDNN 4007)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.datasets import cifar10\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.utils.visualize_util import model_to_dot, plot\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "import matplotlib.image as mpimg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "WORKSPACE_PATH = '/home/takeyama/pywork/ipython/2016-07-04'\n",
    "\n",
    "if not os.path.exists(WORKSPACE_PATH+'/raw/'):os.makedirs(WORKSPACE_PATH+'/raw/')\n",
    "RawDataPath=WORKSPACE_PATH+'/raw/'\n",
    "    \n",
    "if not os.path.exists(WORKSPACE_PATH+'/study/'):os.makedirs(WORKSPACE_PATH+'/study/')\n",
    "StudyDataPath=WORKSPACE_PATH+'/study/'\n",
    "\n",
    "if not os.path.exists(WORKSPACE_PATH+'/study/'):os.makedirs(WORKSPACE_PATH+'/study/')\n",
    "StudyDataPath=WORKSPACE_PATH+'/study/'\n",
    "    \n",
    "if not os.path.exists(WORKSPACE_PATH+'/glaph/'):os.makedirs(WORKSPACE_PATH+'/glaph/')\n",
    "GlaphDataPath=WORKSPACE_PATH+'/glaph/'\n",
    "\n",
    "if not os.path.exists(WORKSPACE_PATH+'/window/'):os.makedirs(WORKSPACE_PATH+'/window/')\n",
    "WindowDataPath=WORKSPACE_PATH+'/window/'\n",
    "\n",
    "if not os.path.exists(StudyDataPath+'modelPic/'):os.makedirs(StudyDataPath+'modelPic/')\n",
    "StudyDataModelPicPath=StudyDataPath+'modelPic/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    encordData,decordData\n",
    "    firstNum:\n",
    "    goalNum:\n",
    "    commonLabel:共通名前\n",
    "\"\"\"\n",
    "def MakeGlaph(encordData,decordData,firstNum,goalNum,commonLabel):\n",
    "    eRow, eCol=encordData.shape\n",
    "    dRow, dCol=decordData.shape\n",
    "    if (eRow!=dRow) | (eCol!=dCol):\n",
    "        print 'check encordData & decordData'\n",
    "        return -1\n",
    "        \n",
    "    start = firstNum\n",
    "    goal=goalNum\n",
    "    print str(start)+' is start '+str(goal)+' is goal'\n",
    "    dataE = encordData.reshape(eRow*eCol,1)[start:goal]\n",
    "    dataD = decordData.reshape(dRow*dCol,1)[start:goal]\n",
    "    plt.plot(range(0,len(dataE)),dataE,'--r',label=\"Encoded\")\n",
    "    plt.plot(range(0,len(dataD)),dataD,'b',label=\"Decoded\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.title(str(start)+\"-\"+str(goal))\n",
    "    plt.savefig(commonLabel+'-'+str(start)+\"-\"+str(goal)+'-'+'glaph')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Phase1 計測データの取得**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dic1=processing.LoadDicDataFromFileNPZ(RawDataPath+\"MemSensor1\")\n",
    "dic2=processing.LoadDicDataFromFileNPZ(RawDataPath+\"MemSensor2\")\n",
    "dic3=processing.LoadDicDataFromFileNPZ(RawDataPath+\"MemSensor3\")\n",
    "dic4=processing.LoadDicDataFromFileNPZ(RawDataPath+\"MemSensor4\")\n",
    "dic5=processing.LoadDicDataFromFileNPZ(RawDataPath+\"MemSensor5\")\n",
    "dic6=processing.LoadDicDataFromFileNPZ(RawDataPath+\"MemSensor6\")\n",
    "dic7=processing.LoadDicDataFromFileNPZ(RawDataPath+\"MemSensor7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Phase2 window flame 作成**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w=window.Window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AccX is registed now\n",
      "AccY is registed now\n",
      "AccZ is registed now\n"
     ]
    }
   ],
   "source": [
    "w.SetData('AccX',dic1['AccX'])\n",
    "w.SetData('AccY',dic1['AccY'])\n",
    "w.SetData('AccZ',dic1['AccZ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build Complete\n",
      "(254742, 3)\n"
     ]
    }
   ],
   "source": [
    "windoW=w.Compile(windowWidth=16,overlap=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "windoW= windoW.reshape((len(windoW),np.prod(windoW.shape[1:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15921, 48)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "windoW.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**前回やった学習をもう１度やってみる**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15921 samples, validate on 15921 samples\n",
      "Epoch 1/50\n",
      "15921/15921 [==============================] - 1s - loss: 0.0564 - val_loss: 0.0061\n",
      "Epoch 2/50\n",
      "15921/15921 [==============================] - 1s - loss: 0.0039 - val_loss: 0.0028\n",
      "Epoch 3/50\n",
      "15921/15921 [==============================] - 1s - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 4/50\n",
      "15921/15921 [==============================] - 1s - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 5/50\n",
      "15921/15921 [==============================] - 1s - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 6/50\n",
      "15921/15921 [==============================] - 1s - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 7/50\n",
      "15921/15921 [==============================] - 1s - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 8/50\n",
      "15921/15921 [==============================] - 1s - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 9/50\n",
      "15921/15921 [==============================] - 1s - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 10/50\n",
      "15921/15921 [==============================] - 1s - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 11/50\n",
      "15921/15921 [==============================] - 1s - loss: 9.9009e-04 - val_loss: 9.6560e-04\n",
      "Epoch 12/50\n",
      "15921/15921 [==============================] - 1s - loss: 9.3327e-04 - val_loss: 8.9059e-04\n",
      "Epoch 13/50\n",
      "15921/15921 [==============================] - 1s - loss: 8.8590e-04 - val_loss: 8.7218e-04\n",
      "Epoch 14/50\n",
      "15921/15921 [==============================] - 1s - loss: 8.3777e-04 - val_loss: 8.0695e-04\n",
      "Epoch 15/50\n",
      "15921/15921 [==============================] - 1s - loss: 7.9531e-04 - val_loss: 0.0010\n",
      "Epoch 16/50\n",
      "15921/15921 [==============================] - 1s - loss: 7.5623e-04 - val_loss: 7.7107e-04\n",
      "Epoch 17/50\n",
      "15921/15921 [==============================] - 1s - loss: 7.1519e-04 - val_loss: 8.7284e-04\n",
      "Epoch 18/50\n",
      "15921/15921 [==============================] - 1s - loss: 6.7837e-04 - val_loss: 6.5045e-04\n",
      "Epoch 19/50\n",
      "15921/15921 [==============================] - 1s - loss: 6.4313e-04 - val_loss: 7.2149e-04\n",
      "Epoch 20/50\n",
      "15921/15921 [==============================] - 1s - loss: 6.0890e-04 - val_loss: 5.7504e-04\n",
      "Epoch 21/50\n",
      "15921/15921 [==============================] - 1s - loss: 5.8173e-04 - val_loss: 5.4710e-04\n",
      "Epoch 22/50\n",
      "15921/15921 [==============================] - 1s - loss: 5.5491e-04 - val_loss: 5.3644e-04\n",
      "Epoch 23/50\n",
      "15921/15921 [==============================] - 1s - loss: 5.3198e-04 - val_loss: 4.8798e-04\n",
      "Epoch 24/50\n",
      "15921/15921 [==============================] - 1s - loss: 5.0815e-04 - val_loss: 5.8193e-04\n",
      "Epoch 25/50\n",
      "15921/15921 [==============================] - 1s - loss: 4.8711e-04 - val_loss: 4.5777e-04\n",
      "Epoch 26/50\n",
      "15921/15921 [==============================] - 1s - loss: 4.7027e-04 - val_loss: 4.4840e-04\n",
      "Epoch 27/50\n",
      "15921/15921 [==============================] - 1s - loss: 4.5453e-04 - val_loss: 4.1766e-04\n",
      "Epoch 28/50\n",
      "15921/15921 [==============================] - 1s - loss: 4.4205e-04 - val_loss: 4.0819e-04\n",
      "Epoch 29/50\n",
      "15921/15921 [==============================] - 1s - loss: 4.2633e-04 - val_loss: 8.0250e-04\n",
      "Epoch 30/50\n",
      "15921/15921 [==============================] - 1s - loss: 4.1422e-04 - val_loss: 3.7948e-04\n",
      "Epoch 31/50\n",
      "15921/15921 [==============================] - 1s - loss: 3.9986e-04 - val_loss: 3.9947e-04\n",
      "Epoch 32/50\n",
      "15921/15921 [==============================] - 1s - loss: 3.9264e-04 - val_loss: 3.6712e-04\n",
      "Epoch 33/50\n",
      "15921/15921 [==============================] - 1s - loss: 3.8272e-04 - val_loss: 3.8934e-04\n",
      "Epoch 34/50\n",
      "15921/15921 [==============================] - 1s - loss: 3.7171e-04 - val_loss: 3.9781e-04\n",
      "Epoch 35/50\n",
      "15921/15921 [==============================] - 1s - loss: 3.6422e-04 - val_loss: 3.8989e-04\n",
      "Epoch 36/50\n",
      "15921/15921 [==============================] - 1s - loss: 3.5946e-04 - val_loss: 3.5407e-04\n",
      "Epoch 37/50\n",
      "15921/15921 [==============================] - 1s - loss: 3.4978e-04 - val_loss: 3.2056e-04\n",
      "Epoch 38/50\n",
      "15921/15921 [==============================] - 1s - loss: 3.4401e-04 - val_loss: 4.4505e-04\n",
      "Epoch 39/50\n",
      "15921/15921 [==============================] - 1s - loss: 3.3931e-04 - val_loss: 3.3425e-04\n",
      "Epoch 40/50\n",
      "15921/15921 [==============================] - 1s - loss: 3.3041e-04 - val_loss: 2.9476e-04\n",
      "Epoch 41/50\n",
      "15921/15921 [==============================] - 1s - loss: 3.2308e-04 - val_loss: 3.0071e-04\n",
      "Epoch 42/50\n",
      "15921/15921 [==============================] - 1s - loss: 3.2035e-04 - val_loss: 2.9481e-04\n",
      "Epoch 43/50\n",
      "15921/15921 [==============================] - 1s - loss: 3.1362e-04 - val_loss: 3.0177e-04\n",
      "Epoch 44/50\n",
      "15921/15921 [==============================] - 1s - loss: 3.0993e-04 - val_loss: 2.7404e-04\n",
      "Epoch 45/50\n",
      "15921/15921 [==============================] - 1s - loss: 3.0415e-04 - val_loss: 2.9129e-04\n",
      "Epoch 46/50\n",
      "15921/15921 [==============================] - 1s - loss: 2.9990e-04 - val_loss: 2.7863e-04\n",
      "Epoch 47/50\n",
      "15921/15921 [==============================] - 1s - loss: 2.9828e-04 - val_loss: 2.7322e-04\n",
      "Epoch 48/50\n",
      "15921/15921 [==============================] - 1s - loss: 2.9216e-04 - val_loss: 2.5823e-04\n",
      "Epoch 49/50\n",
      "15921/15921 [==============================] - 1s - loss: 2.8628e-04 - val_loss: 3.4361e-04\n",
      "Epoch 50/50\n",
      "15921/15921 [==============================] - 1s - loss: 2.8377e-04 - val_loss: 2.9346e-04\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEPCAYAAABRHfM8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJQwREYmJEoaIiMRECUNERGLy/wG1QxbTVTcv7AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efcb3d94e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define SaveFileName\n",
    "dim=8\n",
    "\n",
    "SensorName='sensor1_dim='+str(dim)\n",
    "SaveFileNameEncord=SensorName+'_AccX_encoded'\n",
    "SaveFileNameDecord=SensorName+'_AccX_decoded'\n",
    "SaveFileNameNet=SensorName+'_AccX_net'\n",
    "SaveFileNameTrain=SensorName+'_AccX_train'\n",
    "SaveFileNameTest=SensorName+'_AccX_test'\n",
    "SaveFileNameGlaph=GlaphDataPath+SensorName+'_AccX_loss_val_loss.png'\n",
    "\n",
    "window_test=windoW\n",
    "window_train=windoW\n",
    "\n",
    "encoding_dim = dim  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "shapeNum=windoW.shape[1]\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(shapeNum,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='tanh')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(shapeNum, activation='linear')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input=input_img, output=decoded)\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input=input_img, output=encoded)\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(input=encoded_input, output=decoder_layer(encoded_input))\n",
    "\n",
    "autoencoder.compile(optimizer='adadelta', loss='mse')\n",
    "plot(autoencoder,  to_file=StudyDataModelPicPath+SaveFileNameNet+'.png')\n",
    "\n",
    "hist = autoencoder.fit(window_train, window_train,\n",
    "                nb_epoch=50,\n",
    "                batch_size=shapeNum/4,\n",
    "                shuffle=True,\n",
    "                validation_data=(window_test, window_test))\n",
    "\n",
    "encoded_imgs = encoder.predict(window_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameEncord,encoded_imgs)\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameDecord,decoded_imgs)\n",
    "\n",
    "# save model and wights\n",
    "json_string = encoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameEncord+'.json', 'w').write(json_string)\n",
    "encoder.save_weights(StudyDataPath+SaveFileNameEncord+'_weights.h5')\n",
    "\n",
    "json_string = decoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameDecord+'.json', 'w').write(json_string)\n",
    "decoder.save_weights(StudyDataPath+SaveFileNameDecord+'_weights.h5')\n",
    "\n",
    "json_string = autoencoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameNet+'.json', 'w').write(json_string)\n",
    "autoencoder.save_weights(StudyDataPath+SaveFileNameNet+'_weights.h5')\n",
    "\n",
    "# plot loss\n",
    "loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "nb_epoch = len(loss)\n",
    "plt.plot(range(nb_epoch), loss, marker='.', label='loss')\n",
    "plt.plot(range(nb_epoch), val_loss, marker='.', label='val_loss')\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.savefig(SaveFileNameGlaph)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "少しパラメータを変えてみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15921 samples, validate on 15921 samples\n",
      "Epoch 1/50\n",
      "15921/15921 [==============================] - 1s - loss: 0.0399 - val_loss: 0.0015\n",
      "Epoch 2/50\n",
      "15921/15921 [==============================] - 1s - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 3/50\n",
      "15921/15921 [==============================] - 1s - loss: 0.0010 - val_loss: 9.6554e-04\n",
      "Epoch 4/50\n",
      "15921/15921 [==============================] - 1s - loss: 9.0998e-04 - val_loss: 8.4893e-04\n",
      "Epoch 5/50\n",
      "15921/15921 [==============================] - 1s - loss: 8.0354e-04 - val_loss: 7.5370e-04\n",
      "Epoch 6/50\n",
      "15921/15921 [==============================] - 1s - loss: 7.1405e-04 - val_loss: 6.7269e-04\n",
      "Epoch 7/50\n",
      "15921/15921 [==============================] - 1s - loss: 6.4333e-04 - val_loss: 6.2020e-04\n",
      "Epoch 8/50\n",
      "15921/15921 [==============================] - 1s - loss: 5.8771e-04 - val_loss: 5.5835e-04\n",
      "Epoch 9/50\n",
      "15921/15921 [==============================] - 1s - loss: 5.3992e-04 - val_loss: 5.1699e-04\n",
      "Epoch 10/50\n",
      "15921/15921 [==============================] - 1s - loss: 5.0064e-04 - val_loss: 4.8349e-04\n",
      "Epoch 11/50\n",
      "15921/15921 [==============================] - 1s - loss: 4.6746e-04 - val_loss: 4.5185e-04\n",
      "Epoch 12/50\n",
      "15921/15921 [==============================] - 1s - loss: 4.3807e-04 - val_loss: 4.4065e-04\n",
      "Epoch 13/50\n",
      "15921/15921 [==============================] - 1s - loss: 4.1318e-04 - val_loss: 3.9776e-04\n",
      "Epoch 14/50\n",
      "15921/15921 [==============================] - 1s - loss: 3.9235e-04 - val_loss: 3.8393e-04\n",
      "Epoch 15/50\n",
      "15921/15921 [==============================] - 1s - loss: 3.7507e-04 - val_loss: 3.7026e-04\n",
      "Epoch 16/50\n",
      "15921/15921 [==============================] - 1s - loss: 3.5964e-04 - val_loss: 3.4856e-04\n",
      "Epoch 17/50\n",
      "15921/15921 [==============================] - 1s - loss: 3.4646e-04 - val_loss: 3.3870e-04\n",
      "Epoch 18/50\n",
      "15921/15921 [==============================] - 1s - loss: 3.3500e-04 - val_loss: 3.4364e-04\n",
      "Epoch 19/50\n",
      "15921/15921 [==============================] - 1s - loss: 3.2353e-04 - val_loss: 3.2279e-04\n",
      "Epoch 20/50\n",
      "15921/15921 [==============================] - 1s - loss: 3.1342e-04 - val_loss: 3.0427e-04\n",
      "Epoch 21/50\n",
      "15921/15921 [==============================] - 1s - loss: 3.0258e-04 - val_loss: 2.9771e-04\n",
      "Epoch 22/50\n",
      "15921/15921 [==============================] - 1s - loss: 2.9156e-04 - val_loss: 2.8698e-04\n",
      "Epoch 23/50\n",
      "15921/15921 [==============================] - 1s - loss: 2.8055e-04 - val_loss: 2.7442e-04\n",
      "Epoch 24/50\n",
      "15921/15921 [==============================] - 1s - loss: 2.6867e-04 - val_loss: 2.6289e-04\n",
      "Epoch 25/50\n",
      "15921/15921 [==============================] - 1s - loss: 2.5680e-04 - val_loss: 2.4699e-04\n",
      "Epoch 26/50\n",
      "15921/15921 [==============================] - 1s - loss: 2.4407e-04 - val_loss: 2.4656e-04\n",
      "Epoch 27/50\n",
      "15921/15921 [==============================] - 1s - loss: 2.3215e-04 - val_loss: 2.2348e-04\n",
      "Epoch 28/50\n",
      "15921/15921 [==============================] - 1s - loss: 2.1982e-04 - val_loss: 2.1161e-04\n",
      "Epoch 29/50\n",
      "15921/15921 [==============================] - 1s - loss: 2.0868e-04 - val_loss: 2.0801e-04\n",
      "Epoch 30/50\n",
      "15921/15921 [==============================] - 1s - loss: 1.9829e-04 - val_loss: 1.9174e-04\n",
      "Epoch 31/50\n",
      "15921/15921 [==============================] - 1s - loss: 1.8883e-04 - val_loss: 1.8910e-04\n",
      "Epoch 32/50\n",
      "15921/15921 [==============================] - 1s - loss: 1.8046e-04 - val_loss: 1.7933e-04\n",
      "Epoch 33/50\n",
      "15921/15921 [==============================] - 1s - loss: 1.7336e-04 - val_loss: 1.6710e-04\n",
      "Epoch 34/50\n",
      "15921/15921 [==============================] - 1s - loss: 1.6695e-04 - val_loss: 1.6796e-04\n",
      "Epoch 35/50\n",
      "15921/15921 [==============================] - 1s - loss: 1.6196e-04 - val_loss: 1.5973e-04\n",
      "Epoch 36/50\n",
      "15921/15921 [==============================] - 1s - loss: 1.5729e-04 - val_loss: 1.5487e-04\n",
      "Epoch 37/50\n",
      "15921/15921 [==============================] - 1s - loss: 1.5348e-04 - val_loss: 1.4977e-04\n",
      "Epoch 38/50\n",
      "15921/15921 [==============================] - 1s - loss: 1.4993e-04 - val_loss: 1.5044e-04\n",
      "Epoch 39/50\n",
      "15921/15921 [==============================] - 1s - loss: 1.4719e-04 - val_loss: 1.4634e-04\n",
      "Epoch 40/50\n",
      "15921/15921 [==============================] - 1s - loss: 1.4455e-04 - val_loss: 1.4453e-04\n",
      "Epoch 41/50\n",
      "15921/15921 [==============================] - 1s - loss: 1.4227e-04 - val_loss: 1.4102e-04\n",
      "Epoch 42/50\n",
      "15921/15921 [==============================] - 1s - loss: 1.4001e-04 - val_loss: 1.3737e-04\n",
      "Epoch 43/50\n",
      "15921/15921 [==============================] - 1s - loss: 1.3799e-04 - val_loss: 1.3667e-04\n",
      "Epoch 44/50\n",
      "15921/15921 [==============================] - 1s - loss: 1.3613e-04 - val_loss: 1.3834e-04\n",
      "Epoch 45/50\n",
      "15921/15921 [==============================] - 1s - loss: 1.3440e-04 - val_loss: 1.3179e-04\n",
      "Epoch 46/50\n",
      "15921/15921 [==============================] - 1s - loss: 1.3244e-04 - val_loss: 1.3062e-04\n",
      "Epoch 47/50\n",
      "15921/15921 [==============================] - 1s - loss: 1.3100e-04 - val_loss: 1.2775e-04\n",
      "Epoch 48/50\n",
      "15921/15921 [==============================] - 1s - loss: 1.2916e-04 - val_loss: 1.2791e-04\n",
      "Epoch 49/50\n",
      "15921/15921 [==============================] - 1s - loss: 1.2737e-04 - val_loss: 1.3287e-04\n",
      "Epoch 50/50\n",
      "15921/15921 [==============================] - 1s - loss: 1.2582e-04 - val_loss: 1.2922e-04\n"
     ]
    }
   ],
   "source": [
    "# define SaveFileName\n",
    "dim=8\n",
    "\n",
    "SensorName='sensor1_dim='+str(dim)\n",
    "SaveFileNameEncord=SensorName+'_AccX_encoded'\n",
    "SaveFileNameDecord=SensorName+'_AccX_decoded'\n",
    "SaveFileNameNet=SensorName+'_AccX_net'\n",
    "SaveFileNameTrain=SensorName+'_AccX_train'\n",
    "SaveFileNameTest=SensorName+'_AccX_test'\n",
    "SaveFileNameGlaph=GlaphDataPath+SensorName+'_AccX_loss_val_loss.png'\n",
    "\n",
    "window_test=windoW\n",
    "window_train=windoW\n",
    "\n",
    "encoding_dim = dim  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "shapeNum=windoW.shape[1]\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(shapeNum,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='linear')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(shapeNum, activation='linear')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input=input_img, output=decoded)\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input=input_img, output=encoded)\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(input=encoded_input, output=decoder_layer(encoded_input))\n",
    "\n",
    "autoencoder.compile(optimizer='adadelta', loss='mse')\n",
    "plot(autoencoder,  to_file=StudyDataModelPicPath+SaveFileNameNet+'.png')\n",
    "\n",
    "hist = autoencoder.fit(window_train, window_train,\n",
    "                nb_epoch=50,\n",
    "                batch_size=shapeNum/4,\n",
    "                shuffle=True,\n",
    "                validation_data=(window_test, window_test))\n",
    "\n",
    "encoded_imgs = encoder.predict(window_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameEncord,encoded_imgs)\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameDecord,decoded_imgs)\n",
    "\n",
    "# save model and wights\n",
    "json_string = encoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameEncord+'.json', 'w').write(json_string)\n",
    "encoder.save_weights(StudyDataPath+SaveFileNameEncord+'_weights.h5')\n",
    "\n",
    "json_string = decoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameDecord+'.json', 'w').write(json_string)\n",
    "decoder.save_weights(StudyDataPath+SaveFileNameDecord+'_weights.h5')\n",
    "\n",
    "json_string = autoencoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameNet+'.json', 'w').write(json_string)\n",
    "autoencoder.save_weights(StudyDataPath+SaveFileNameNet+'_weights.h5')\n",
    "\n",
    "# plot loss\n",
    "loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "nb_epoch = len(loss)\n",
    "plt.plot(range(nb_epoch), loss, marker='.', label='loss')\n",
    "plt.plot(range(nb_epoch), val_loss, marker='.', label='val_loss')\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.savefig(SaveFileNameGlaph)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次元数を減らしてみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define SaveFileName\n",
    "dim=4\n",
    "\n",
    "SensorName='sensor1_dim='+str(dim)\n",
    "SaveFileNameEncord=SensorName+'_AccX_encoded'\n",
    "SaveFileNameDecord=SensorName+'_AccX_decoded'\n",
    "SaveFileNameNet=SensorName+'_AccX_net'\n",
    "SaveFileNameTrain=SensorName+'_AccX_train'\n",
    "SaveFileNameTest=SensorName+'_AccX_test'\n",
    "SaveFileNameGlaph=GlaphDataPath+SensorName+'_AccX_loss_val_loss.png'\n",
    "\n",
    "window_test=windoW\n",
    "window_train=windoW\n",
    "\n",
    "encoding_dim = dim  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "shapeNum=windoW.shape[1]\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(shapeNum,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='tanh')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(shapeNum, activation='linear')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input=input_img, output=decoded)\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input=input_img, output=encoded)\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(input=encoded_input, output=decoder_layer(encoded_input))\n",
    "\n",
    "autoencoder.compile(optimizer='adadelta', loss='mse')\n",
    "plot(autoencoder,  to_file=StudyDataModelPicPath+SaveFileNameNet+'.png')\n",
    "\n",
    "hist = autoencoder.fit(window_train, window_train,\n",
    "                nb_epoch=50,\n",
    "                batch_size=shapeNum/4,\n",
    "                shuffle=True,\n",
    "                validation_data=(window_test, window_test))\n",
    "\n",
    "encoded_imgs = encoder.predict(window_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameEncord,encoded_imgs)\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameDecord,decoded_imgs)\n",
    "\n",
    "# save model and wights\n",
    "json_string = encoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameEncord+'.json', 'w').write(json_string)\n",
    "encoder.save_weights(StudyDataPath+SaveFileNameEncord+'_weights.h5')\n",
    "\n",
    "json_string = decoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameDecord+'.json', 'w').write(json_string)\n",
    "decoder.save_weights(StudyDataPath+SaveFileNameDecord+'_weights.h5')\n",
    "\n",
    "json_string = autoencoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameNet+'.json', 'w').write(json_string)\n",
    "autoencoder.save_weights(StudyDataPath+SaveFileNameNet+'_weights.h5')\n",
    "\n",
    "# plot loss\n",
    "loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "nb_epoch = len(loss)\n",
    "plt.plot(range(nb_epoch), loss, marker='.', label='loss')\n",
    "plt.plot(range(nb_epoch), val_loss, marker='.', label='val_loss')\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.savefig(SaveFileNameGlaph)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次元数を増やしてみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define SaveFileName\n",
    "dim=12\n",
    "\n",
    "SensorName='sensor1_dim='+str(dim)\n",
    "SaveFileNameEncord=SensorName+'_AccX_encoded'\n",
    "SaveFileNameDecord=SensorName+'_AccX_decoded'\n",
    "SaveFileNameNet=SensorName+'_AccX_net'\n",
    "SaveFileNameTrain=SensorName+'_AccX_train'\n",
    "SaveFileNameTest=SensorName+'_AccX_test'\n",
    "SaveFileNameGlaph=GlaphDataPath+SensorName+'_AccX_loss_val_loss.png'\n",
    "\n",
    "window_test=windoW\n",
    "window_train=windoW\n",
    "\n",
    "encoding_dim = dim  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "shapeNum=windoW.shape[1]\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(shapeNum,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='tanh')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(shapeNum, activation='linear')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input=input_img, output=decoded)\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input=input_img, output=encoded)\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(input=encoded_input, output=decoder_layer(encoded_input))\n",
    "\n",
    "autoencoder.compile(optimizer='adadelta', loss='mse')\n",
    "plot(autoencoder,  to_file=StudyDataModelPicPath+SaveFileNameNet+'.png')\n",
    "\n",
    "hist = autoencoder.fit(window_train, window_train,\n",
    "                nb_epoch=50,\n",
    "                batch_size=shapeNum/4,\n",
    "                shuffle=True,\n",
    "                validation_data=(window_test, window_test))\n",
    "\n",
    "encoded_imgs = encoder.predict(window_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameEncord,encoded_imgs)\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameDecord,decoded_imgs)\n",
    "\n",
    "# save model and wights\n",
    "json_string = encoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameEncord+'.json', 'w').write(json_string)\n",
    "encoder.save_weights(StudyDataPath+SaveFileNameEncord+'_weights.h5')\n",
    "\n",
    "json_string = decoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameDecord+'.json', 'w').write(json_string)\n",
    "decoder.save_weights(StudyDataPath+SaveFileNameDecord+'_weights.h5')\n",
    "\n",
    "json_string = autoencoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameNet+'.json', 'w').write(json_string)\n",
    "autoencoder.save_weights(StudyDataPath+SaveFileNameNet+'_weights.h5')\n",
    "\n",
    "# plot loss\n",
    "loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "nb_epoch = len(loss)\n",
    "plt.plot(range(nb_epoch), loss, marker='.', label='loss')\n",
    "plt.plot(range(nb_epoch), val_loss, marker='.', label='val_loss')\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.savefig(SaveFileNameGlaph)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次元数を入力創と同じ大きさにしてみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define SaveFileName\n",
    "dim=16\n",
    "\n",
    "SensorName='sensor1_dim='+str(dim)\n",
    "SaveFileNameEncord=SensorName+'_AccX_encoded'\n",
    "SaveFileNameDecord=SensorName+'_AccX_decoded'\n",
    "SaveFileNameNet=SensorName+'_AccX_net'\n",
    "SaveFileNameTrain=SensorName+'_AccX_train'\n",
    "SaveFileNameTest=SensorName+'_AccX_test'\n",
    "SaveFileNameGlaph=GlaphDataPath+SensorName+'_AccX_loss_val_loss.png'\n",
    "\n",
    "window_test=windoW\n",
    "window_train=windoW\n",
    "\n",
    "encoding_dim = dim  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "shapeNum=windoW.shape[1]\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(shapeNum,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='tanh')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(shapeNum, activation='linear')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input=input_img, output=decoded)\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input=input_img, output=encoded)\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(input=encoded_input, output=decoder_layer(encoded_input))\n",
    "\n",
    "autoencoder.compile(optimizer='adadelta', loss='mse')\n",
    "plot(autoencoder,  to_file=StudyDataModelPicPath+SaveFileNameNet+'.png')\n",
    "\n",
    "hist = autoencoder.fit(window_train, window_train,\n",
    "                nb_epoch=50,\n",
    "                batch_size=shapeNum/4,\n",
    "                shuffle=True,\n",
    "                validation_data=(window_test, window_test))\n",
    "\n",
    "encoded_imgs = encoder.predict(window_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameEncord,encoded_imgs)\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameDecord,decoded_imgs)\n",
    "\n",
    "# save model and wights\n",
    "json_string = encoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameEncord+'.json', 'w').write(json_string)\n",
    "encoder.save_weights(StudyDataPath+SaveFileNameEncord+'_weights.h5')\n",
    "\n",
    "json_string = decoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameDecord+'.json', 'w').write(json_string)\n",
    "decoder.save_weights(StudyDataPath+SaveFileNameDecord+'_weights.h5')\n",
    "\n",
    "json_string = autoencoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameNet+'.json', 'w').write(json_string)\n",
    "autoencoder.save_weights(StudyDataPath+SaveFileNameNet+'_weights.h5')\n",
    "\n",
    "# plot loss\n",
    "loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "nb_epoch = len(loss)\n",
    "plt.plot(range(nb_epoch), loss, marker='.', label='loss')\n",
    "plt.plot(range(nb_epoch), val_loss, marker='.', label='val_loss')\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.savefig(SaveFileNameGlaph)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "入力層の大きさの２倍のノード数を隠れそうにする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define SaveFileName\n",
    "dim=32\n",
    "\n",
    "SensorName='sensor1_dim='+str(dim)\n",
    "SaveFileNameEncord=SensorName+'_AccX_encoded'\n",
    "SaveFileNameDecord=SensorName+'_AccX_decoded'\n",
    "SaveFileNameNet=SensorName+'_AccX_net'\n",
    "SaveFileNameTrain=SensorName+'_AccX_train'\n",
    "SaveFileNameTest=SensorName+'_AccX_test'\n",
    "SaveFileNameGlaph=GlaphDataPath+SensorName+'_AccX_loss_val_loss.png'\n",
    "\n",
    "window_test=windoW\n",
    "window_train=windoW\n",
    "\n",
    "encoding_dim = dim  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "shapeNum=windoW.shape[1]\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(shapeNum,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='tanh')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(shapeNum, activation='linear')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input=input_img, output=decoded)\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input=input_img, output=encoded)\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(input=encoded_input, output=decoder_layer(encoded_input))\n",
    "\n",
    "autoencoder.compile(optimizer='adadelta', loss='mse')\n",
    "plot(autoencoder,  to_file=StudyDataModelPicPath+SaveFileNameNet+'.png')\n",
    "\n",
    "hist = autoencoder.fit(window_train, window_train,\n",
    "                nb_epoch=50,\n",
    "                batch_size=shapeNum/4,\n",
    "                shuffle=True,\n",
    "                validation_data=(window_test, window_test))\n",
    "\n",
    "encoded_imgs = encoder.predict(window_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameEncord,encoded_imgs)\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameDecord,decoded_imgs)\n",
    "\n",
    "# save model and wights\n",
    "json_string = encoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameEncord+'.json', 'w').write(json_string)\n",
    "encoder.save_weights(StudyDataPath+SaveFileNameEncord+'_weights.h5')\n",
    "\n",
    "json_string = decoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameDecord+'.json', 'w').write(json_string)\n",
    "decoder.save_weights(StudyDataPath+SaveFileNameDecord+'_weights.h5')\n",
    "\n",
    "json_string = autoencoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameNet+'.json', 'w').write(json_string)\n",
    "autoencoder.save_weights(StudyDataPath+SaveFileNameNet+'_weights.h5')\n",
    "\n",
    "# plot loss\n",
    "loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "nb_epoch = len(loss)\n",
    "plt.plot(range(nb_epoch), loss, marker='.', label='loss')\n",
    "plt.plot(range(nb_epoch), val_loss, marker='.', label='val_loss')\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.savefig(SaveFileNameGlaph)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "次元数を48にする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define SaveFileName\n",
    "dim=48\n",
    "\n",
    "SensorName='sensor1_dim='+str(dim)\n",
    "SaveFileNameEncord=SensorName+'_AccX_encoded'\n",
    "SaveFileNameDecord=SensorName+'_AccX_decoded'\n",
    "SaveFileNameNet=SensorName+'_AccX_net'\n",
    "SaveFileNameTrain=SensorName+'_AccX_train'\n",
    "SaveFileNameTest=SensorName+'_AccX_test'\n",
    "SaveFileNameGlaph=GlaphDataPath+SensorName+'_AccX_loss_val_loss.png'\n",
    "\n",
    "window_test=windoW\n",
    "window_train=windoW\n",
    "\n",
    "encoding_dim = dim  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "shapeNum=windoW.shape[1]\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(shapeNum,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='tanh')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(shapeNum, activation='linear')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input=input_img, output=decoded)\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input=input_img, output=encoded)\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(input=encoded_input, output=decoder_layer(encoded_input))\n",
    "\n",
    "autoencoder.compile(optimizer='adadelta', loss='mse')\n",
    "plot(autoencoder,  to_file=StudyDataModelPicPath+SaveFileNameNet+'.png')\n",
    "\n",
    "hist = autoencoder.fit(window_train, window_train,\n",
    "                nb_epoch=50,\n",
    "                batch_size=shapeNum/4,\n",
    "                shuffle=True,\n",
    "                validation_data=(window_test, window_test))\n",
    "\n",
    "encoded_imgs = encoder.predict(window_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameEncord,encoded_imgs)\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameDecord,decoded_imgs)\n",
    "\n",
    "# save model and wights\n",
    "json_string = encoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameEncord+'.json', 'w').write(json_string)\n",
    "encoder.save_weights(StudyDataPath+SaveFileNameEncord+'_weights.h5')\n",
    "\n",
    "json_string = decoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameDecord+'.json', 'w').write(json_string)\n",
    "decoder.save_weights(StudyDataPath+SaveFileNameDecord+'_weights.h5')\n",
    "\n",
    "json_string = autoencoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameNet+'.json', 'w').write(json_string)\n",
    "autoencoder.save_weights(StudyDataPath+SaveFileNameNet+'_weights.h5')\n",
    "\n",
    "# plot loss\n",
    "loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "nb_epoch = len(loss)\n",
    "plt.plot(range(nb_epoch), loss, marker='.', label='loss')\n",
    "plt.plot(range(nb_epoch), val_loss, marker='.', label='val_loss')\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.savefig(SaveFileNameGlaph)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次元数を入力ノードの二倍する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define SaveFileName\n",
    "dim=96\n",
    "\n",
    "SensorName='sensor1_dim='+str(dim)\n",
    "SaveFileNameEncord=SensorName+'_AccX_encoded'\n",
    "SaveFileNameDecord=SensorName+'_AccX_decoded'\n",
    "SaveFileNameNet=SensorName+'_AccX_net'\n",
    "SaveFileNameTrain=SensorName+'_AccX_train'\n",
    "SaveFileNameTest=SensorName+'_AccX_test'\n",
    "SaveFileNameGlaph=GlaphDataPath+SensorName+'_AccX_loss_val_loss.png'\n",
    "\n",
    "window_test=windoW\n",
    "window_train=windoW\n",
    "\n",
    "encoding_dim = dim  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "shapeNum=windoW.shape[1]\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(shapeNum,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='tanh')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(shapeNum, activation='linear')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input=input_img, output=decoded)\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input=input_img, output=encoded)\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(input=encoded_input, output=decoder_layer(encoded_input))\n",
    "\n",
    "autoencoder.compile(optimizer='adadelta', loss='mse')\n",
    "plot(autoencoder,  to_file=StudyDataModelPicPath+SaveFileNameNet+'.png')\n",
    "\n",
    "hist = autoencoder.fit(window_train, window_train,\n",
    "                nb_epoch=50,\n",
    "                batch_size=shapeNum/4,\n",
    "                shuffle=True,\n",
    "                validation_data=(window_test, window_test))\n",
    "\n",
    "encoded_imgs = encoder.predict(window_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameEncord,encoded_imgs)\n",
    "processing.SaveDicDataFromFileNPZ(StudyDataPath,SaveFileNameDecord,decoded_imgs)\n",
    "\n",
    "# save model and wights\n",
    "json_string = encoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameEncord+'.json', 'w').write(json_string)\n",
    "encoder.save_weights(StudyDataPath+SaveFileNameEncord+'_weights.h5')\n",
    "\n",
    "json_string = decoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameDecord+'.json', 'w').write(json_string)\n",
    "decoder.save_weights(StudyDataPath+SaveFileNameDecord+'_weights.h5')\n",
    "\n",
    "json_string = autoencoder.to_json()\n",
    "open(StudyDataPath+SaveFileNameNet+'.json', 'w').write(json_string)\n",
    "autoencoder.save_weights(StudyDataPath+SaveFileNameNet+'_weights.h5')\n",
    "\n",
    "# plot loss\n",
    "loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "nb_epoch = len(loss)\n",
    "plt.plot(range(nb_epoch), loss, marker='.', label='loss')\n",
    "plt.plot(range(nb_epoch), val_loss, marker='.', label='val_loss')\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.savefig(SaveFileNameGlaph)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
